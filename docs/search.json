[
  {
    "objectID": "scripts/accessStormEventsData.html",
    "href": "scripts/accessStormEventsData.html",
    "title": "Storm Events Data: Access & Tidying",
    "section": "",
    "text": "Show the code\n# install package librarian if needed\nif (!(\"librarian\" %in% rownames(installed.packages()))) {\n  install.packages(\"librarian\")\n}\n\n# load required packages\nlibrarian::shelf(\n  ropensci/rnoaa,\n  openxlsx,\n  tidyverse,\n  DT,\n  usmap\n)"
  },
  {
    "objectID": "scripts/accessStormEventsData.html#download-storm-events-data",
    "href": "scripts/accessStormEventsData.html#download-storm-events-data",
    "title": "Storm Events Data: Access & Tidying",
    "section": "1.1 Download Storm Events Data",
    "text": "1.1 Download Storm Events Data\nWe will use the Storm Events Database operated by the US National Oceanic and Atmospheric Administration. Full documentation regarding this database can be found here. A detailed variable codebook is found here.\nThere is a handy R package that allows to download different NOAA data products: rnoaa. We use the functions se_files() and se_data.\nWe first want to get a feeling for all available files:\n\n\nShow the code\n# read in meta data of available files\nse_availableFiles &lt;- se_files()\n\n# get an overview of metadata\ncat(\"Structure of meta data:\\n\")\n\n\nStructure of meta data:\n\n\nShow the code\nstr(se_availableFiles)\n\n\ntibble [221 × 4] (S3: tbl_df/tbl/data.frame)\n $ type   : chr [1:221] \"details\" \"details\" \"details\" \"details\" ...\n $ year   : num [1:221] 1950 1951 1952 1953 1954 ...\n $ created: num [1:221] 20210803 20210803 20210803 20210803 20210803 ...\n $ url    : chr [1:221] \"https://www1.ncdc.noaa.gov/pub/data/swdi/stormevents/csvfiles/StormEvents_details-ftp_v1.0_d1950_c20210803.csv.gz\" \"https://www1.ncdc.noaa.gov/pub/data/swdi/stormevents/csvfiles/StormEvents_details-ftp_v1.0_d1951_c20210803.csv.gz\" \"https://www1.ncdc.noaa.gov/pub/data/swdi/stormevents/csvfiles/StormEvents_details-ftp_v1.0_d1952_c20210803.csv.gz\" \"https://www1.ncdc.noaa.gov/pub/data/swdi/stormevents/csvfiles/StormEvents_details-ftp_v1.0_d1953_c20210803.csv.gz\" ...\n\n\nShow the code\n# display unique file types\ncat(\"\\nUnique file types:\\n\")\n\n\n\nUnique file types:\n\n\nShow the code\nunique(se_availableFiles$type)\n\n\n[1] \"details\"    \"fatalities\" \"locations\"  \"legacy\"    \n\n\nWe will mostly be interested in “details”, “locations”, and (maybe) “fatalities”. What is the most recent data available for these files?\n\n\nShow the code\nse_availableFiles %&gt;% \n  filter(year &gt; 2020) %&gt;% \n  arrange(desc(year)) %&gt;% \n  select(-url) %&gt;% \n  knitr::kable()\n\n\n\n\n\ntype\nyear\ncreated\n\n\n\n\ndetails\n2024\n20240716\n\n\nfatalities\n2024\n20240716\n\n\nlocations\n2024\n20240716\n\n\ndetails\n2023\n20240716\n\n\nfatalities\n2023\n20240716\n\n\nlocations\n2023\n20240716\n\n\ndetails\n2022\n20240716\n\n\nfatalities\n2022\n20240716\n\n\nlocations\n2022\n20240716\n\n\ndetails\n2021\n20240716\n\n\nfatalities\n2021\n20240716\n\n\nlocations\n2021\n20240716\n\n\n\n\n\nNow, let’s read in “details”, “locations”, and “fatalities for the years 2013 up to 2023\n\n\nShow the code\n# define simple function (putting code in fuctions prevents workspace from being\n# clutered with variables we will not use again)\nread_in_storm_data &lt;- function(\n    years_to_read_in = seq(params$currentYear - 10, params$currentYear, 1),\n    types_to_read_in = c(\"details\", \"locations\", \"fatalities\")\n    ) {\n  \n  # initialize data_list\n  data_list &lt;- vector(\"list\", length = length(years_to_read_in))\n  names(data_list) &lt;- years_to_read_in\n  for (year in seq(1, length(years_to_read_in))) {\n    data_list[[year]] &lt;- vector(\"list\", length = length(types_to_read_in))\n    names(data_list[[year]]) &lt;- as.character(types_to_read_in)\n  }\n  \n  # read in data over nested loop\n  for (i in seq(1,length(years_to_read_in))) {\n    for (j in seq(1,length(types_to_read_in))) {\n      currentData &lt;- se_data(year = years_to_read_in[i], type = types_to_read_in[j])\n      data_list[[i]][[j]] &lt;- currentData\n    }\n  }\n  \n  # save data_list\n  time &lt;- format(Sys.time(), \"%Y%m%d\")\n  fileName &lt;- paste0(time, \"_data_list.RDS\")\n  saveRDS(data_list, file = file.path(\"../data/stormData\", fileName))\n  # to read in data, use:\n  # data_list &lt;- readRDS(\"../0_Data/data_list.RDS\")\n  \n  return(data_list)\n}\n\n# call function and store results in data_list\ndata_list &lt;- read_in_storm_data()\n\n\n\n\nShow the code\n# load most recent data_list file\nfileName &lt;- \"data_list.RDS\"\npathName &lt;- \"../data/stormData\"\nfilePath &lt;- fs::dir_ls(path = pathName, regexp = paste0(fileName, \"$\")) %&gt;% last()\ndata_list &lt;- readRDS(filePath)"
  },
  {
    "objectID": "scripts/accessStormEventsData.html#inspect-data-structures",
    "href": "scripts/accessStormEventsData.html#inspect-data-structures",
    "title": "Storm Events Data: Access & Tidying",
    "section": "1.2 Inspect Data Structures",
    "text": "1.2 Inspect Data Structures\nWhat is the structure of “details”, “locations”, and “fatalities”?\n\n1.2.1 Details\n\n\nShow the code\ndata_list[[as.character(params$currentYear)]]$details %&gt;% \n  select(-c(episode_narrative, event_narrative)) %&gt;% \n  head(.,10) %&gt;% \n  datatable(options = list(scrollY = \"300px\"), fillContainer = TRUE)\n\n\n\n\n\n\nNote: two additional variables are not included in the table above:\n\nepisode_narrative (example:) In late October, a winter storm dumped heavy snow in eastern North Dakota and northwestern Minnesota over a period of 2 days. Due to mesoscale forces at play, some areas received a foot of snow or more where the band stalled. In addition to heavy snow, there was also blowing snow, reducing visibility across the area.\nevent_narrative (example:) Public reports 7.5 inches at Black Tiger Bay Campground in Saint Michael.\n\n\n\n1.2.2 Locations\n\n\nShow the code\ndata_list[[as.character(params$currentYear)]]$locations %&gt;% \n  head(.,10) %&gt;% \n  datatable(options = list(scrollY = \"300px\"), fillContainer = TRUE)\n\n\n\n\n\n\n\n\n1.2.3 Fatalities\n\n\nShow the code\ndata_list[[as.character(params$currentYear)]]$fatalities %&gt;% \n  head(.,10) %&gt;% \n  datatable(options = list(scrollY = \"300px\"), fillContainer = TRUE)"
  },
  {
    "objectID": "scripts/accessStormEventsData.html#recency-of-data",
    "href": "scripts/accessStormEventsData.html#recency-of-data",
    "title": "Storm Events Data: Access & Tidying",
    "section": "1.3 Recency of Data",
    "text": "1.3 Recency of Data\nWhat is the most recent data available in “details” for params$currentYear?\n\n\nShow the code\ndata_list[[as.character(params$currentYear)]]$details %&gt;% \n  mutate(arrange_date = strptime(end_date_time, format = \"%d-%b-%y %H:%M:%S\") %&gt;% as_datetime()) %&gt;% \n  arrange(desc(arrange_date)) %&gt;% \n  .$end_date_time %&gt;% .[1]\n\n\n[1] \"31-DEC-23 23:59:00\""
  },
  {
    "objectID": "scripts/accessStormEventsData.html#create-combined-datasets",
    "href": "scripts/accessStormEventsData.html#create-combined-datasets",
    "title": "Storm Events Data: Access & Tidying",
    "section": "1.4 Create Combined Datasets",
    "text": "1.4 Create Combined Datasets\n\n\nShow the code\ndata_details &lt;- tibble()\nfor (i in seq(1, length(data_list))) {\n  data_details &lt;- rbind(data_details, data_list[[i]]$details)\n}\n\ndata_locations &lt;- tibble()\nfor (i in seq(1, length(data_list))) {\n  data_locations &lt;- rbind(data_locations, data_list[[i]]$locations)\n}\n\ndata_fatalities &lt;- tibble()\nfor (i in seq(1, length(data_list))) {\n  data_fatalities &lt;- rbind(data_fatalities, data_list[[i]]$fatalities)\n}\n\n# since we will mostly work with data_details, let's save this data set\ntime &lt;- format(Sys.time(), \"%Y%m%d\")\nfileName &lt;- paste0(time, \"_data_details.RDS\")\nsaveRDS(data_details, file = file.path(\"../data/stormData\", fileName))"
  },
  {
    "objectID": "scripts/accessStormEventsData.html#simple-tidying",
    "href": "scripts/accessStormEventsData.html#simple-tidying",
    "title": "Storm Events Data: Access & Tidying",
    "section": "2.1 Simple Tidying",
    "text": "2.1 Simple Tidying\nWe will mainly work with data_details. Let’s tidy up this data (convert some integers to characters, some characters to integers, and some characters to date-time format).\n\n\nShow the code\n# load most recent data_details\nfileName &lt;- \"data_details.RDS\"\npathName &lt;- \"../data/stormData\"\nfilePath &lt;- fs::dir_ls(path = pathName, regexp = paste0(fileName, \"$\")) %&gt;% last()\ndata_details &lt;- readRDS(filePath)\n\n# convert some integers to characters so that they are not mistakenly treated\n# as integers\ntoChar &lt;- c(\n  \"episode_id\", \"event_id\",\n  \"state_fips\", \"cz_fips\",\n  \"category\",\n  \"tor_other_cz_fips\"\n)\ndata_details &lt;- data_details %&gt;% \n  mutate(across(all_of(toChar), as.character))\nrm(toChar)\n\n# for damage values, we need to convert strings like\n# \"3.12M\" and \"117.00K\" to integer values. We define a function to do so:\nconvert_to_integer &lt;- function(x) {\n  multiplier &lt;- c(\"K\" = 1000, \"M\" = 1000000)\n  numeric_part &lt;- as.numeric(sub(\"[^0-9.]\", \"\", x))\n  multiplier_part &lt;- substr(x, nchar(x), nchar(x))\n  multiplier_value &lt;- multiplier[multiplier_part]\n  return(as.integer(numeric_part * multiplier_value))\n}\n# apply function to \"damage\" variables\ndata_details &lt;- data_details %&gt;% \n  mutate(across(contains(\"damage\"), convert_to_integer))\nrm(convert_to_integer)\n\n# convert some character columns to date-time format\ndata_details &lt;- data_details %&gt;% \n  mutate(across(contains(\"date_time\"), dmy_hms))\n\n# store month_name as factor with the correct order of months as levels\ndata_details &lt;- data_details %&gt;% \n  mutate(month_name = factor(month_name, levels = month.name))\n\n# state_fips need to be two digits long. If the first digit was zero, this leading\n# zero was removed during the read in process of the data. This is corrected\n# using str_pad. Similarly, cz_fips needs to be three digits long.\ndata_details &lt;- data_details %&gt;% \n  mutate(state_fips = str_pad(state_fips, width = 2, side = \"left\", pad = \"0\")) %&gt;% \n  mutate(cz_fips = str_pad(cz_fips, width = 3, side = \"left\", pad = \"0\"))"
  },
  {
    "objectID": "scripts/accessStormEventsData.html#fips-tidying",
    "href": "scripts/accessStormEventsData.html#fips-tidying",
    "title": "Storm Events Data: Access & Tidying",
    "section": "2.2 FIPS Tidying",
    "text": "2.2 FIPS Tidying\nFor various forms of analyses, we will need the Federal Information Processing System (FIPS) Codes for States and Counties. For instance, we will need this information to associate specific extreme weather events with certain geographical regions (mostly Counties). The package usmap, which we will use to display geographical distributions of extreme weather events, works with county FIPS. Therefore, we need to tidy up our data to show events that conform to such FIPS data. The FIPS information is stored in two separate variables in the data set: state_fips and cz_fips.\nNote that the storm event database assigns FIPS not only to County/Parish (cz_type == \"C\"), but also NWS Public Forecast Zone and Marine Zones (cz_type == \"Z\").\nThus, the meaning of variable cz_fips depends on cz_type. Therefore, we first need to convert Z-type FIPS to C-type FIPS. There is a mapping of Forecast Zones onto County FIPS we can use for this. In the following code block, we\n\ncreate a data set mappingData with all the information to map NWS Forecast Zones to County FIPS and\nuse this mapping information to create a variable county_fips representing the County FIPS and\nultimately create a variable state_county_fips representing the full FIPS identifying each County in each State.\n\n\n\nShow the code\nFUNConvertFips &lt;- function(myData) {\n  \n  # define vector of urls to .txt files containing the mapping information\n  urlsToFiles &lt;- c(\n    \"https://www.weather.gov/source/pimar/PubRep/PUB_AR.txt\",\n    \"https://www.weather.gov/source/pimar/PubRep/PUB_CR.txt\",\n    \"https://www.weather.gov/source/pimar/PubRep/PUB_ER.txt\",\n    \"https://www.weather.gov/source/pimar/PubRep/PUB_PR.txt\",\n    \"https://www.weather.gov/source/pimar/PubRep/PUB_SR.txt\",\n    \"https://www.weather.gov/source/pimar/PubRep/PUB_WR.txt\"\n  )\n  \n  # define the variable names of each column in these files\n  varNames &lt;- c(\n    \"state_abr\",\n    \"id_zone\",\n    \"location_descr\",\n    \"county\",\n    \"fips\",\n    \"city\",\n    \"state_city_abr\"\n  )\n  \n  # define a function to read in the files\n  FUNReadFiles &lt;- function(myURL) {\n    dataOut &lt;- read.table(\n      file = myURL,\n      sep = \"|\",\n      header = FALSE,\n      quote = \"\",\n      colClasses = \"character\",\n      fill = FALSE\n    )\n    names(dataOut) &lt;- varNames\n    return(dataOut)\n  }\n  \n  # \"loop\" over this function and continuously combine read in data into one data frame\n  mappingData &lt;- plyr::ldply(urlsToFiles, FUNReadFiles) %&gt;% \n    as_tibble()\n  \n  # create data set that maps state abbreviations to full state names\n  mapping_states_abbr &lt;- usmap::fips_info() %&gt;%\n    as_tibble() %&gt;% \n    select(abbr, full) %&gt;% \n    mutate(state = toupper(full)) %&gt;% \n    select(-full)\n  \n  # combine mappingData with mapping_states_abbr\n  mappingData &lt;- mappingData %&gt;% \n    left_join(y = mapping_states_abbr, by = c(\"state_abr\" = \"abbr\")) %&gt;% \n    relocate(state, .after = state_abr) %&gt;% \n    mutate(cz_fips = id_zone) %&gt;% \n    relocate(cz_fips, .after = id_zone) %&gt;% \n    mutate(county_fips = str_extract(fips, \".{3}$\")) %&gt;% \n    relocate(county_fips, .after = fips)\n  \n  # subset myData to myData_czTypeC and myData_czTypeZ\n  myData_czTypeC &lt;- myData %&gt;% \n    filter(cz_type == \"C\")\n  myData_czTypeZ &lt;- myData %&gt;% \n    filter(cz_type == \"Z\")\n  \n  # define county_fips in myData_czTypeC\n  myData_czTypeC &lt;- myData_czTypeC %&gt;% \n    mutate(county_fips = cz_fips)\n  \n  # define county_fips in myData_czTypeZ\n  # first, create a temporary dataset\n  tmp &lt;- left_join(\n    x = myData_czTypeZ,\n    y = mappingData %&gt;% \n      select(state, cz_fips, county_fips),\n    by = c(\"state\", \"cz_fips\"),\n    relationship = \"many-to-many\"\n  )\n  # then, create a list with meta information for myData_czTypeZ\n  myData_czTypeZ_meta &lt;- list(\n    county_fips_isNA = tmp %&gt;% filter(is.na(county_fips)),\n    event_id_isDoublicated = tmp %&gt;% filter(duplicated(event_id)),\n    myData_czTypeZ_raw = tmp,\n    myData_czTypeZ_county_fips_isNA.removed = tmp %&gt;% filter(!is.na(county_fips))\n  )\n  # define myData_czTypeZ\n  # note that we only retain events whose county_fips is not NA! To see where\n  # these NAs come from, see myData_czTypeZ_meta$county_fips_isNA\n  myData_czTypeZ &lt;- myData_czTypeZ_meta$myData_czTypeZ_county_fips_isNA.removed\n  \n  # join myData_czTypeC and myData_czTypeZ\n  if (all(names(myData_czTypeC) == names(myData_czTypeZ))) {\n    myData_fips &lt;- rbind(\n      myData_czTypeC,\n      myData_czTypeZ\n    )\n  } else {\n    stop(\"all(names(myData_czTypeC) == names(myData_czTypeZ)) != TRUE\")\n  }\n  \n  # create variable state_county_fips representing the full and correct fips for each county\n  myData_fips &lt;- myData_fips %&gt;% \n    mutate(state_county_fips = str_c(state_fips, county_fips))\n  \n  return(list(\n    myData_fips = myData_fips,\n    myData_czTypeZ_meta = myData_czTypeZ_meta\n  ))\n  \n}\n\n# call function\nout_FUNConvertFips &lt;- FUNConvertFips(data_details)\n\n# define data_details_fips\ndata_details_fips &lt;- out_FUNConvertFips$myData_fips\n\n# save data_details_fips\ntime &lt;- format(Sys.time(), \"%Y%m%d\")\nfileName &lt;- paste0(time, \"_data_details_fips_raw.RDS\")\nsaveRDS(data_details_fips, file = file.path(\"../data/stormData\", fileName))\n\n\nAfter these changes, some challenges remain, which become obvious, if we try to match the FIPS provided in the data set with current FIPS available in usmap.\n\n\nShow the code\n# load most recent data_details_fips\nfileName &lt;- \"data_details_fips_raw.RDS\"\npathName &lt;- \"../data/stormData\"\nfilePath &lt;- fs::dir_ls(path = pathName, regexp = paste0(fileName, \"$\")) %&gt;% last()\ndata_details_fips &lt;- readRDS(filePath)\n\n# capture the warning message produced if we apply usmap::fips_info to\n# all unique state_county_fips in data_details_fips\nwarning_message &lt;- tryCatch({\n  result &lt;- fips_info(fips = unique(as.character(data_details_fips$state_county_fips)))\n}, warning = function(w) {\n  return(conditionMessage(w))\n})\nunmatched_fips &lt;- str_extract_all(warning_message, \"\\\\b\\\\d{5}\\\\b\")[[1]] %&gt;% unique()\n\n# create a tibble containing all unmatched fips\nunmatched_fips &lt;- tibble(\n  state_county_fips = unmatched_fips,\n  state_fips = state_county_fips %&gt;% \n    str_extract(\"^.{2}\"),\n  county_fips = state_county_fips %&gt;% \n    str_extract(\".{3}$\")\n) %&gt;% \n  arrange(state_county_fips)\n\n# in which states do we find unmatched fips?\nunmatched_fips_states &lt;- unmatched_fips %&gt;% \n  distinct(state_fips) %&gt;% \n  left_join(\n    y = usmap::fips_info(),\n    by =c(\"state_fips\" = \"fips\")\n  )\n\n# # inspect the main land states that had unmatched fips\n# unmatched_fips_states_mainLand &lt;- unmatched_fips_states %&gt;% \n#   filter(!is.na(abbr))\n# plot_usmap(regions = \"counties\", include = unmatched_fips_states_mainLand$abbr[1], labels = TRUE)\n# plot_usmap(regions = \"counties\", include = unmatched_fips_states_mainLand$abbr[2], labels = TRUE)\n# unmatched_fips %&gt;%\n#   filter(state_fips == \"02\")\n# \n# data_details_fips %&gt;% \n#   filter(state_fips %in% (unmatched_fips_states %&gt;% \n#            filter(is.na(abbr)) %&gt;% \n#            pull(state_fips))) %&gt;% \n#   select(state, cz_name) %&gt;% \n#   distinct(state)\n\n\n\n\nShow the code\ndatatable(unmatched_fips)\n\n\n\n\nTable 1: FIPS in data_details_fips that do not match with current FIPS as provided by usmap.\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nknitr::kable(unmatched_fips_states)\n\n\n\n\nTable 2: States associated with the unmatched FIPS reported in Table 1.\n\n\n\n\n\n\nstate_fips\nabbr\nfull\n\n\n\n\n02\nAK\nAlaska\n\n\n09\nCT\nConnecticut\n\n\n96\nNA\nNA\n\n\n97\nNA\nNA\n\n\n98\nNA\nNA\n\n\n99\nNA\nNA\n\n\n\n\n\n\n\n\nWhat is the origin of these unmatched FIPS? First, as listed in Table 3, state_fips 96, 97, 98, 99 are assigned to the following states that are considered territories (and not states) of the US. We will exclude these territories in further analyses.\n\n\nShow the code\ndata_details_fips %&gt;%\n  filter(state_fips %in% (unmatched_fips_states %&gt;%\n           filter(is.na(abbr)) %&gt;%\n           pull(state_fips))) %&gt;%\n  distinct(state_fips, .keep_all = TRUE) %&gt;% \n  select(state_fips, state) %&gt;% \n  knitr::kable()\n\n\n\n\nTable 3: Terretories of the US in the data_details_fips\n\n\n\n\n\n\nstate_fips\nstate\n\n\n\n\n99\nPUERTO RICO\n\n\n96\nVIRGIN ISLANDS\n\n\n98\nGUAM\n\n\n97\nAMERICAN SAMOA\n\n\n\n\n\n\n\n\nSecond, there are many unmatched FIPS in the state of Alaska (Table 4). This is due to the fact that Alaska had substantial changes to counties and their boundaries over the years (see here). Consistent information on how to map old counties to new counties is not readily available. We will exclude Alaska from further analyses.\n\n\nShow the code\ndata_details_fips %&gt;% \n  filter(state_county_fips %in% filter(unmatched_fips, state_fips == \"02\")$state_county_fips) %&gt;% \n  select(state_county_fips, state, cz_name) %&gt;% \n  distinct() %&gt;% \n  datatable()\n# # are there unmatched FIPS for Alaska in the latest year data? - YES\n# data_details_fips %&gt;% \n#   filter(year == params$currentYear, state_fips == \"02\") %&gt;% \n#   filter(state_county_fips %in% unmatched_fips$state_county_fips) %&gt;% \n#   select(state_county_fips, state, cz_name)\n\n\n\n\nTable 4: Unmatched FIPS in the state of Alaska.\n\n\n\n\n\n\n\n\n\n\nThird, there were substantial changes in the state of Connecticut: Originally, it consisted of 8 counties. After the changes, these counties were replaced with 9 new counties (for more information, see here and here). The old counties map to the new counties according to Table 5.\n\n\nShow the code\n# read in xlsx file mapping old counties and FIPS to new counties and FIPS\nconnecticut_newPlanningRegions &lt;- openxlsx::read.xlsx(\n  xlsxFile = \"https://www2.census.gov/geo/docs/reference/ct_change/ct_cou_to_cousub_crosswalk.xlsx\"\n) %&gt;% \n  as_tibble() %&gt;% \n  select(c(1:5))\n\n# rename variable names\nnames(connecticut_newPlanningRegions) &lt;- c(\n  \"state_fips\",\n  \"old_county_fips\",\n  \"old_county_name\",\n  \"new_county_fips\",\n  \"new_county_name\"\n)\n\n# select distinct combinations of our variables of interest\nconnecticut_newPlanningRegions &lt;- connecticut_newPlanningRegions %&gt;% \n  distinct(state_fips, old_county_fips, new_county_fips, .keep_all = TRUE)\n\n# combine state and county fips\nconnecticut_newPlanningRegions &lt;- connecticut_newPlanningRegions %&gt;% \n  mutate(state_county_fips_old = paste0(state_fips, old_county_fips),\n         state_county_fips_new = paste0(state_fips, new_county_fips))\n\n# display table\ndatatable(connecticut_newPlanningRegions)\n\n\n\n\nTable 5: Connecticut exact mapping of old counties to new counties.\n\n\n\n\n\n\n\n\n\n\nHowever, this mapping is too fine grained for our purposes. A better mapping can be achieved following Figure 1, which results in the following mapping summarized in Table 6.\n\n\n\n\n\n\nFigure 1: Mapping of old to new counties in Connecticut.\n\n\n\n\n\nShow the code\n# https://www.federalregister.gov/documents/2022/06/06/2022-12063/change-to-county-equivalents-in-the-state-of-connecticut\n\nold_fips &lt;- unmatched_fips %&gt;% \n  filter(state_fips == \"09\") %&gt;% \n  arrange(state_county_fips) %&gt;% \n  pull(state_county_fips)\nold_counties &lt;- c(\n  \"Fairfield\",\n  \"Harford\",\n  \"Litchfield\",\n  \"Middlesex\",\n  \"New Haven\",\n  \"New London\",\n  \"Tolland\",\n  \"Windham\"\n)\nold &lt;- tibble(\n  old_county = old_counties,\n  old_fips = old_fips\n)\n\nnew_counties &lt;- c(\n  \"Greater Bridgeport Planning Region\",\n  \"Western Connecticut Planning Region\",\n  \"Capitol Planning Region\",\n  \"Northwest Hills Planning Region\",\n  \"Lower Connecticut River Valley Planning Region\",\n  \"Naugatuck Valley Planning Region\",\n  \"South Central Connecticut Planning Region\",\n  \"Southeastern Connecticut Planning Region\",\n  \"Northeastern Connecticut Planning Region\"\n)\nnew_fips &lt;- usmap::fips(state = \"CT\", county = new_counties)\nnew &lt;- tibble(\n  new_county = new_counties,\n  new_fips = new_fips\n)\n\nold_counties_to_new_counties &lt;- tibble(\n  old_county = c(\n    \"Fairfield\",\n    \"Fairfield\",\n    \"Harford\",\n    \"Tolland\",\n    \"Litchfield\",\n    \"Middlesex\",\n    \"New Haven\",\n    \"New Haven\",\n    \"New London\",\n    \"Windham\"\n  ),\n  new_county = c(\n    \"Greater Bridgeport Planning Region\",\n    \"Western Connecticut Planning Region\",\n    \"Capitol Planning Region\",\n    \"Capitol Planning Region\",\n    \"Northwest Hills Planning Region\",\n    \"Lower Connecticut River Valley Planning Region\",\n    \"Naugatuck Valley Planning Region\",\n    \"South Central Connecticut Planning Region\",\n    \"Southeastern Connecticut Planning Region\",\n    \"Northeastern Connecticut Planning Region\"\n  )\n)\n\nconnecticut_newPlanningRegions &lt;- left_join(\n  x = old_counties_to_new_counties,\n  y = old,\n  by = \"old_county\"\n) %&gt;% \n  left_join(\n    y = new,\n    by = \"new_county\"\n  )\n\n# do some renamign and add new_county_fips\nconnecticut_newPlanningRegions &lt;- connecticut_newPlanningRegions %&gt;% \n  rename(\n    old_state_county_fips = old_fips,\n    new_state_county_fips = new_fips\n  ) %&gt;% \n  mutate(new_county_fips = new_state_county_fips %&gt;% str_extract(\".{3}$\"))\n\ndatatable(connecticut_newPlanningRegions)\n\n\n\n\nTable 6: Connecticut mapping of old counties to new counties.\n\n\n\n\n\n\n\n\n\n\nNow we apply the changes mentioned above to data_details_fips:\n\nremove US territories from data set\nremove state of Alaska from data set\napply new county names and FIPS to the state of Connecticut\n\n\n\nShow the code\n# we apply the changes outlined in the main text in slightly changed order\n\n# first, we apply the new county names and FIPS to the state of Connecticut\n\n# We check whether all state_county_fips for Connecticut are recorded using the old\n# fips.\ntmp &lt;- data_details_fips %&gt;% \n  filter(state_fips == \"09\") %&gt;% \n  filter(!state_county_fips %in% unmatched_fips$state_county_fips)\n\nif (!nrow(tmp)) {\n  message(\"All state_county_fips are recorded following the old FIPS codes.\")\n} else {\n  warning(\"There are state_county_fips that are recorded following the new FIPS codes!\")\n}\nrm(tmp)\n\n# create a data set without Connecticut entries that follow the old FIPS codes\ndata_details_fips_withoutCT &lt;- data_details_fips %&gt;% \n  filter(!(state_fips == \"09\" & (state_county_fips %in% unmatched_fips$state_county_fips)))\n\n# create a data set containing only Connecticut entries that follow the old FIPS codes\ndata_details_fips_CT &lt;- data_details_fips %&gt;% \n  filter(state_fips == \"09\" & (state_county_fips %in% unmatched_fips$state_county_fips))\n\n# mutate county_fips and state_county_fips so that they represent the new county_fips\n# and state_county_fips. Note that this will inflate the previously data_details_fips_CT\n# because there is a one-to-many relationsipt between old and new fips.\ndata_details_fips_CT &lt;- left_join(\n    x = data_details_fips_CT,\n    y = connecticut_newPlanningRegions %&gt;% \n      select(old_state_county_fips, new_state_county_fips, new_county_fips),\n    by = c(\"state_county_fips\" = \"old_state_county_fips\")\n  ) %&gt;% \n  mutate(\n    county_fips = new_county_fips,\n    state_county_fips = new_state_county_fips\n  ) %&gt;% \n  select(-starts_with(\"new_\"))\n\n# check whether the datasets without and with Connecticut have the same structure before\n# joning them again.\nif (all(names(data_details_fips_withoutCT) == names(data_details_fips_CT))) {\n  message(\"all(names(data_details_fips_withoutCT) == names(data_details_fips_CT)) == TRUE\")\n  data_details_fips &lt;- bind_rows(\n    data_details_fips_withoutCT,\n    data_details_fips_CT\n  )\n} else {\n  warning(\"The names of data_details_fips_withoutCT and data_details_fips_CT do not matach!\")\n}\n\n# then, we remove the US territories from the data set\ndata_details_fips &lt;- data_details_fips %&gt;%\n  filter(!state_fips %in% (unmatched_fips_states %&gt;%\n                             filter(is.na(abbr)) %&gt;%\n                             pull(state_fips)))\n\n# finally, we remove the state of Alaska (FIPS = 02) from the data set, but we save\n# a data set still containing Alaska just in case...\ndata_details_fips_withAK &lt;- data_details_fips\n\ndata_details_fips &lt;- data_details_fips %&gt;%\n  filter(state_fips != \"02\")\n\n\nFinally, we rearrange some variables in data_details_fips and save them for later use. We also store state_fips, state_county_fips and event_type as factors. This becomes handy for accurately counting number of events by groups later on.\n\n\nShow the code\n# rearrange order of variables in the data set\ndata_details_fips &lt;- data_details_fips %&gt;% \n  select(\n    begin_yearmonth,\n    episode_id, event_id,\n    state, state_county_fips,\n    event_type,\n    starts_with(\"damage\"),\n    starts_with(\"injuries\"),\n    starts_with(\"death\"),\n    everything()\n  ) %&gt;% \n  arrange(begin_yearmonth, episode_id, event_id, state_county_fips)\n\n# store state_county_fips and event_type as factor\ndata_details_fips &lt;- data_details_fips %&gt;% \n  mutate(\n    state_fips = factor(state_fips, levels = sort(unique(.$state_fips))),\n    state_county_fips = factor(state_county_fips, levels = sort(unique(.$state_county_fips))),\n    event_type = factor(event_type, levels = sort(unique(.$event_type)))\n  )\n\n# save data_details_fips\ntime &lt;- format(Sys.time(), \"%Y%m%d\")\nfileName &lt;- paste0(time, \"_data_details_fips.RDS\")\nsaveRDS(data_details_fips, file = file.path(\"../data/stormData\", fileName))"
  },
  {
    "objectID": "index.html#welcome-to-the-registered-report-supplementary-material",
    "href": "index.html#welcome-to-the-registered-report-supplementary-material",
    "title": "EcoTRACE RR SOM",
    "section": "Welcome to the Registered Report Supplementary Material",
    "text": "Welcome to the Registered Report Supplementary Material\nOn this website, you will find all the scripts used to preprocess and visualize the data reported in the Nature Climate Change RE\nThis site is maintained by emmanuel.guizarrosales@unibe.ch"
  },
  {
    "objectID": "scripts/analyseStormEventsData.html",
    "href": "scripts/analyseStormEventsData.html",
    "title": "Storm Events Data: Analysis",
    "section": "",
    "text": "Show the code\n# install package librarian if needed\nif (!(\"librarian\" %in% rownames(installed.packages()))) {\n  install.packages(\"librarian\")\n}\n\n# load required packages\nlibrarian::shelf(\n  tidyverse,\n  fs,\n  usmap,\n  ggpubr\n)\n\n# Source required functions\nmyFunctions &lt;- c(\n  \"FUNStormEventsData_filterData\"\n)\n\nfor (f in myFunctions) {\n  source(paste0(\"../functions/\", f, \".R\"))\n}\n\n# Preperations to show states boundaries\npoly_states &lt;- plot_usmap(regions = \"states\")\n\n# Read in data_details_fips\nfileName &lt;- \"data_details_fips.RDS\"\npathName &lt;- \"../data/stormData\"\nfilePath &lt;- dir_ls(path = pathName, regexp = paste0(fileName, \"$\")) %&gt;% last()\ndata_details_fips &lt;- readRDS(filePath)\n\n\n\n1 Filter Data\nFirst, we filter the storm events data for the specific years, months, and extreme weather event types we are interested in. We filter for all years from 20214 to 2023 (as data are not complete for the year 2024 yet), we highlight the month of July, and we focus on those types of extreme weather events that are predicted to increase in frequency and severity due to climate change (IPCC 2023): Excessive Heat, Drought, Wildfire, Flash Flood, Coastal Flood, Strong Wind, Hail, and Tornado.\n\n\nShow the code\n# Define variables of interest\nmyYears &lt;- seq(2014, 2023)\nmyMonths &lt;- c(\"July\")\nmyEventTypes &lt;- c(\n  \"Excessive Heat\",\n  \"Drought\",\n  \"Wildfire\",\n  \"Flash Flood\",\n  \"Coastal Flood\",\n  \"Strong Wind\",\n  \"Hail\",\n  \"Tornado\"\n)\n\n# Call function\nout &lt;- FUNStormEventsData_filterData(\n  myData = data_details_fips,\n  myYears = myYears,\n  myMonths = myMonths,\n  myEventTypes = myEventTypes\n)\n\n\n\n\n2 Seasonal Distribution\n\n\nShow the code\np.hist &lt;- out$dataForHist %&gt;% \n  group_by(year) %&gt;% \n  mutate(\n    max_nEpisodes = max(nEpisodes),\n    yearlyMean_nEpisodes = mean(nEpisodes)\n  ) %&gt;% \n  ungroup() %&gt;% \n  mutate(max_month = ifelse(nEpisodes == max_nEpisodes, TRUE, FALSE)) %&gt;% \n  ggplot(aes(\n    x = month_name, y = nEpisodes,\n    linewidth = max_month,\n    fill = month_name %in% myMonths\n  )) +\n  geom_hline(\n    mapping = aes(yintercept = yearlyMean_nEpisodes),\n    linetype = \"dashed\",\n    color = \"black\"\n  ) +\n  geom_bar(\n    stat = \"identity\",\n    color = \"black\",\n    alpha = .7,\n    show.legend = FALSE\n  ) +\n  scale_linewidth_manual(values = c(0.5, 2)) +\n  scale_x_discrete(labels = month.abb) +\n  scale_fill_manual(\n    values = c(\"darkgrey\", \"orange\"),\n  ) +\n  labs(\n    title = \"Number of Extreme Weather Episodes by Month over the Years 2014 to 2023\",\n    x = \"Month\",\n    y = \"Number of Episodes\"\n  ) +\n  theme_bw() +\n  theme(\n    text = element_text(size = 15),\n    plot.title = element_text(hjust = .5),\n    axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)\n  ) +\n  facet_wrap(~year, ncol = 5)\n\n\njpeg(\n  file = \"../images/histogramSeasonalDistribution.jpeg\",\n  width = 14, height = 7.5, units = \"in\", res = 600\n)\nprint(p.hist)\ninvisible(dev.off())\n\n\nFigure 1 shows something.\n\n\n\n\n\n\nFigure 1: Histograms showing the number of extreme weather episodes by month from 2014 to 2023. The dashed horizontal line indicates the mean number of extreme weather episodes in each year. The thick-bordered bar marks the month with the most extreme weather events each year. The orange bar represents July. July had the most extreme weather events in 4 out of 10 years, and in another 4 years, it was right before or after the peak month. Only episodes that included at least one of the following event types were considered: excessive heat, drought, wildfire, flash flood, coastal flood, strong wind, hail, tornado.\n\n\n\n\n\n3 Geographical Distribution\n\n\nShow the code\np.map_bin &lt;- plot_usmap(\n  data = out$dataForUsPlot,\n  values = \"episodes_bin\",\n  regions = \"counties\",\n  exclude = c(\"AK\", \"HI\"),\n  color = \"black\",\n  linewidth = 0.1\n  ) +\n  geom_sf(\n    data = poly_states[[1]] %&gt;% \n      filter(!(abbr %in% c(\"AK\", \"HI\"))),\n    color = \"black\",\n    fill = NA,\n    linewidth = .3\n  ) +\n  scale_fill_manual(\n    name = \"Number of Episodes &gt; 0\",\n    values = c(\"white\", \"orange\")\n  ) +\n  labs(\n    title = \"Extreme Weather Episodes in July over the Years 2014 to 2023\"\n  ) +\n  theme_bw() +\n  theme(\n    text = element_text(size = 15),\n    legend.position = \"bottom\",\n    plot.title = element_text(hjust = .5),\n    panel.grid = element_blank(),\n    axis.ticks = element_blank(),\n    axis.text = element_blank()\n  ) +\n  facet_wrap(~year, ncol = 5)\n\njpeg(\n  file = \"../images/mapGeographicalDistribution_bin.jpeg\",\n  width = 14, height = 7.5, units = \"in\", res = 600\n)\nprint(p.map_bin)\ninvisible(dev.off())\n\n\nFigure 2 shows something else.\n\n\n\n\n\n\nFigure 2: Maps displaying the geographical distribution of the occurrence of at least one extreme weather episode in July over the years 2014 to 2023. Only episodes that included at least one of the following event types were considered: excessive heat, drought, wildfire, flash flood, coastal flood, strong wind, hail, tornado.\n\n\n\n\n\nShow the code\ndataForPlot &lt;- out$dataForUsPlot %&gt;% \n  mutate(nEpisodes_withNA = ifelse(nEpisodes == 0, NA_integer_, nEpisodes))\n\np.map_cont &lt;- plot_usmap(\n  data = dataForPlot,\n  values = \"nEpisodes_withNA\",\n  regions = \"counties\",\n  exclude = c(\"AK\", \"HI\"),\n  color = \"black\",\n  linewidth = 0.1\n  ) +\n  geom_sf(\n    data = poly_states[[1]] %&gt;% \n      filter(!(abbr %in% c(\"AK\", \"HI\"))),\n    color = \"black\",\n    fill = NA,\n    linewidth = .3\n  ) +\n  scale_fill_binned(\n    name = \"Number of Episodes\",\n    n.breaks = 10,\n    type = \"viridis\",\n    na.value = \"white\"\n  ) +\n  labs(\n    title = \"Extreme Weather Episodes in July over the Years 2014 to 2023\"\n  ) +\n  theme_bw() +\n  theme(\n    text = element_text(size = 15),\n    legend.position = \"bottom\",\n    plot.title = element_text(hjust = .5),\n    panel.grid = element_blank(),\n    axis.ticks = element_blank(),\n    axis.text = element_blank()\n  ) +\n  facet_wrap(~year, ncol = 5)\n\njpeg(\n  file = \"../images/mapGeographicalDistribution_cont.jpeg\",\n  width = 14, height = 7.5, units = \"in\", res = 600\n)\nprint(p.map_cont)\ninvisible(dev.off())\n\np.hist_count &lt;- out$dataForUsPlot %&gt;% \n  group_by(year, nEpisodes) %&gt;% \n  summarise(\n    count = n(),\n    prcnt = count / n_distinct(out$dataForUsPlot$fips)\n  ) %&gt;% \n  ggplot(aes(x = nEpisodes, y = prcnt)) +\n  geom_bar(stat = \"identity\", color = \"black\", fill = \"darkgrey\") +\n  scale_y_continuous(labels = scales::label_percent()) +\n  labs(\n    x = \"Number of Episodes\",\n    y = \"Proportion of Counties\"\n  ) +\n  theme_bw() +\n  labs(\n    title = \"Extreme Weather Episodes in July over the Years 2014 to 2023\"\n  ) +\n  theme(\n    text = element_text(size = 15),\n    legend.position = \"bottom\",\n    plot.title = element_text(hjust = .5)\n  ) +\n  facet_wrap(~year, ncol = 5)\n\njpeg(\n  file = \"../images/frequencyDistribution_cont.jpeg\",\n  width = 14, height = 7.5, units = \"in\", res = 600\n)\nprint(p.hist_count)\ninvisible(dev.off())\n\n\nFigure 4 shows something else.\n\n\n\n\n\n\nFigure 3: Maps displaying the geographical distribution of the raw number of extreme weather episodes in July over the years 20214 to 2023. The color palette indicates numbers greater than zero, and white represent a count of zero episodes.\n\n\n\nFigure 3 shows something else.\n\n\n\n\n\n\nFigure 4: Histograms displaying the distribution of the raw number of extreme weather episodes in July over the years 2014 to 2023. For each number of episodes on the x-axis, the y-axis shows the proportion of counties that recorded this number of episodes.\n\n\n\n\n\n\n\n\nReferences\n\nIPCC, ed. 2023. “Weather and Climate Extreme Events in a Changing Climate.” In, 1513–1766. Cambridge: Cambridge University Press. https://doi.org/10.1017/9781009157896.013."
  }
]