[
  {
    "objectID": "scripts/supplementaryInformation.html",
    "href": "scripts/supplementaryInformation.html",
    "title": "Supplementary Information",
    "section": "",
    "text": "Show the code\n# install package librarian if needed\nif (!(\"librarian\" %in% rownames(installed.packages()))) {\n  install.packages(\"librarian\")\n}\n\n# load required packages\nlibrarian::shelf(\n  tidyverse,\n  usmap,\n  fs,\n  ggpubr,\n  ggdist,\n  ggrepel,\n  faux,\n  lme4,\n  lmerTest,\n  ggeffects,\n  binom,\n  tictoc,\n  ggthemes,\n  sessioninfo,\n  knitr,\n  kableExtra\n)\n\n# Source required functions\nmyFunctions &lt;- c(\n  \"FUNStormEventsData_filterData\"\n)\n\nfor (f in myFunctions) {\n  source(paste0(\"../functions/\", f, \".R\"))\n}\n\n# Preperations to show states boundaries\npoly_states &lt;- plot_usmap(regions = \"states\")\n\n# Read in data_details_fips\nfileName &lt;- \"data_details_fips.RDS\"\npathName &lt;- \"../data/stormData\"\nfilePath &lt;- dir_ls(path = pathName, regexp = paste0(fileName, \"$\")) %&gt;% last()\ndata_details_fips &lt;- readRDS(filePath)"
  },
  {
    "objectID": "scripts/supplementaryInformation.html#purpose-rationale",
    "href": "scripts/supplementaryInformation.html#purpose-rationale",
    "title": "Supplementary Information",
    "section": "3.1 Purpose & Rationale",
    "text": "3.1 Purpose & Rationale\nAs outlined in the Registered Report, we will assess the number of extreme weather episodes recorded in each participant’s county of residence within the 30 days prior to study completion. Regarding the time window during which we plan to conduct the study, we aim for maximizing the likelihood of capturing suitable variability in the exposure to extreme weather episodes with notable geographic variability. To this end, we analyzed records of extreme weather episodes over the last ten years."
  },
  {
    "objectID": "scripts/supplementaryInformation.html#filter-data",
    "href": "scripts/supplementaryInformation.html#filter-data",
    "title": "Supplementary Information",
    "section": "3.2 Filter Data",
    "text": "3.2 Filter Data\nWe filter the storm events data for the specific years, months, and extreme weather event types we are interested in. We filter for all years from 2014 to 2023 (as data are not complete for the year 2024 yet), we highlight the month of July, and we focus on those types of extreme weather events that are predicted to increase in frequency and severity due to climate change : Excessive Heat, Drought, Wildfire, Flash Flood, Coastal Flood, Strong Wind, Hail, and Tornado (IPCC 2023).\n\n\nShow the code\n# Define variables of interest\nmyYears &lt;- seq(2014, 2023)\nmyMonths &lt;- c(\"July\")\nmyEventTypes &lt;- c(\n  \"Excessive Heat\",\n  \"Drought\",\n  \"Wildfire\",\n  \"Flash Flood\",\n  \"Coastal Flood\",\n  \"Strong Wind\",\n  \"Hail\",\n  \"Tornado\"\n)\n\n# Call function\nout &lt;- FUNStormEventsData_filterData(\n  myData = data_details_fips,\n  myYears = myYears,\n  myMonths = myMonths,\n  myEventTypes = myEventTypes\n)"
  },
  {
    "objectID": "scripts/supplementaryInformation.html#analysis",
    "href": "scripts/supplementaryInformation.html#analysis",
    "title": "Supplementary Information",
    "section": "3.3 Analysis",
    "text": "3.3 Analysis\n\n\nShow the code\np.hist &lt;- out$dataForHist %&gt;% \n  group_by(year) %&gt;% \n  mutate(\n    max_nEpisodes = max(nEpisodes),\n    yearlyMean_nEpisodes = mean(nEpisodes)\n  ) %&gt;% \n  ungroup() %&gt;% \n  mutate(max_month = ifelse(nEpisodes == max_nEpisodes, TRUE, FALSE)) %&gt;% \n  ggplot(aes(\n    x = month_name, y = nEpisodes,\n    linewidth = max_month,\n    fill = month_name %in% myMonths\n  )) +\n  geom_hline(\n    mapping = aes(yintercept = yearlyMean_nEpisodes),\n    linetype = \"dashed\",\n    color = \"black\"\n  ) +\n  geom_bar(\n    stat = \"identity\",\n    color = \"black\",\n    alpha = .7,\n    show.legend = FALSE\n  ) +\n  scale_linewidth_manual(values = c(0.5, 2)) +\n  scale_x_discrete(labels = month.abb) +\n  scale_fill_manual(\n    values = c(\"darkgrey\", \"orange\"),\n  ) +\n  labs(\n    title = \"Number of Extreme Weather Episodes by Month over the Years 2014 to 2023\",\n    x = \"Month\",\n    y = \"Number of Episodes\"\n  ) +\n  theme_bw() +\n  theme(\n    text = element_text(size = 15),\n    plot.title = element_text(hjust = .5),\n    axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)\n  ) +\n  facet_wrap(~year, ncol = 5)\n\n\njpeg(\n  file = \"../images/histogramSeasonalDistribution.jpeg\",\n  width = 14, height = 7.5, units = \"in\", res = 600\n)\nprint(p.hist)\ninvisible(dev.off())\n\n\n\n\nShow the code\np.map_bin &lt;- plot_usmap(\n  data = out$dataForUsPlot,\n  values = \"episodes_bin\",\n  regions = \"counties\",\n  exclude = c(\"AK\", \"HI\"),\n  color = \"black\",\n  linewidth = 0.1\n  ) +\n  geom_sf(\n    data = poly_states[[1]] %&gt;% \n      filter(!(abbr %in% c(\"AK\", \"HI\"))),\n    color = \"black\",\n    fill = NA,\n    linewidth = .3\n  ) +\n  scale_fill_manual(\n    name = \"Number of Episodes &gt; 0\",\n    values = c(\"white\", \"orange\")\n  ) +\n  labs(\n    title = \"Extreme Weather Episodes in July over the Years 2014 to 2023\"\n  ) +\n  theme_bw() +\n  theme(\n    text = element_text(size = 15),\n    legend.position = \"bottom\",\n    plot.title = element_text(hjust = .5),\n    panel.grid = element_blank(),\n    axis.ticks = element_blank(),\n    axis.text = element_blank()\n  ) +\n  facet_wrap(~year, ncol = 5)\n\njpeg(\n  file = \"../images/mapGeographicalDistribution_bin.jpeg\",\n  width = 14, height = 7.5, units = \"in\", res = 600\n)\nprint(p.map_bin)\ninvisible(dev.off())\n\n\n\n\nShow the code\np.histJulyEventTypes &lt;- data_details_fips %&gt;% \n  mutate(fips = state_county_fips) %&gt;% \n  filter(year %in% myYears) %&gt;% \n  filter(month_name %in% myMonths) %&gt;% \n  filter(event_type %in% myEventTypes) %&gt;% \n  distinct(event_id, fips, .keep_all = TRUE) %&gt;% \n  group_by(year, event_type) %&gt;% \n  summarise(\n    nEvents = n(),\n    .groups = 'drop'\n  ) %&gt;% \n  ggplot(aes(y = event_type, x = nEvents)) +\n  geom_bar(\n    stat = 'identity',\n    color = \"black\",\n    fill = \"darkgrey\",\n    alpha = .7,\n  ) +\n  geom_text(\n    aes(label = scales::comma(nEvents)),\n    hjust = -0.1,\n    vjust = 0.5,\n    size = 2.5\n  ) +\n  scale_x_continuous(\n    labels = scales::comma_format(), \n    breaks = seq(0, 2.5e3, 1e3)\n  ) +\n  coord_cartesian(xlim = c(0, 2.5e3)) +\n  labs(\n    title = \"Number of Extreme Weather Events in July by Event Type over the Years 2014 to 2023\",\n    x = \"Number of Events\",\n    y = \"Event Type\"\n  ) +\n  theme_bw() +\n  theme(\n    text = element_text(size = 15),\n    plot.title = element_text(hjust = .5)\n  ) +\n  facet_wrap(~year, ncol = 5)\n\njpeg(\n  file = \"../images/histogramJulyEventTypes.jpeg\",\n  width = 14, height = 7.5, units = \"in\", res = 600\n)\nprint(p.histJulyEventTypes)\ninvisible(dev.off())\n\n\n\n\nShow the code\nadditionalStats &lt;- data_details_fips %&gt;% \n  filter(year %in% myYears) %&gt;% \n  filter(month_name %in% myMonths) %&gt;% \n  filter(event_type %in% myEventTypes) %&gt;% \n  distinct(episode_id, state_county_fips, .keep_all = TRUE) %&gt;% \n  group_by(year) %&gt;% \n  summarise(\n    nEpisodes = n(), \n    .groups = 'drop'\n  ) %&gt;% \n  summarise(\n    meanNEpisodes = round(mean(nEpisodes), 2),\n    sdNEpisodes = round(sd(nEpisodes), 2)\n  )\n\nmeanNEpisodesJuly &lt;- \n  additionalStats %&gt;% \n  pull(meanNEpisodes) %&gt;% \n  scales::comma()\nsdNEpisodesJuly &lt;- \n  additionalStats %&gt;% \n  pull(sdNEpisodes) %&gt;% \n  scales::comma()\n\n\nOur analysis spanning the last ten years evidenced high numbers of occurrences of extreme weather episodes in every single year (Figure 1) as well as considerable geographical variability (Figure 2). Analyzing the seasonal distribution of extreme weather episodes, Figure 1 shows that July consistently shows a high number of extreme weather episodes over the last ten years, with an average occurrence of 1,777 episodes in each year (SD = 450). Note that numbers represent counts of distinct episode-county combinations to represent how many counties were affected. Table 3 shows the average number of extreme weather events by event type in July over the last ten years, demonstrating that July typically witnesses a multitude of different extreme weather event types. Additionally, Figure 2 indicates that within the month of July, these extreme weather episodes also display a high geographical variability.\n\n\n\n\n\n\nFigure 1: Histograms showing the number of extreme weather episodes by month from 2014 to 2023. The dashed horizontal line indicates the mean number of extreme weather episodes in each year. The thick-bordered bar marks the month with the most extreme weather events each year. The orange bar represents July. July had the most extreme weather events in 4 out of 10 years, and in another 4 years, it was right before or after the peak month. Only episodes that included at least one of the following event types were considered: excessive heat, drought, wildfire, flash flood, coastal flood, strong wind, hail, tornado.\n\n\n\n\n\nShow the code\ndata_details_fips %&gt;% \n  mutate(fips = state_county_fips) %&gt;% \n  filter(year %in% myYears) %&gt;% \n  filter(month_name %in% myMonths) %&gt;% \n  filter(event_type %in% myEventTypes) %&gt;% \n  distinct(event_id, fips, .keep_all = TRUE) %&gt;% \n  group_by(year, event_type) %&gt;% \n  summarise(\n    nEvents = n(),\n    .groups = 'drop'\n  ) %&gt;% \n  group_by(event_type) %&gt;% \n  summarise(\n    meanNEvents = format(round(mean(nEvents), 2), nsmall = 2),\n    sdNEvents = format(round(sd(nEvents, 2)), nsmall = 2),\n    .groups = 'drop'\n  ) %&gt;% \n  knitr::kable(col.names = c(\n    \"Event Type\", \"Mean Number of Events\", \"SD\"\n  ), align = c(\"l\", \"r\", \"r\"))\n\n\n\n\nTable 3: Mean Number of Extreme Weather Events in July over the Years 2014 to 2023 by Event Type.\n\n\n\n\n\n\nEvent Type\nMean Number of Events\nSD\n\n\n\n\nCoastal Flood\n5.43\n3.00\n\n\nDrought\n272.70\n254.00\n\n\nExcessive Heat\n429.50\n347.00\n\n\nFlash Flood\n778.80\n241.00\n\n\nHail\n1249.70\n383.00\n\n\nStrong Wind\n8.60\n6.00\n\n\nTornado\n107.60\n20.00\n\n\nWildfire\n106.90\n34.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: Maps displaying the geographical distribution of the occurrence of at least one extreme weather episode in July over the years 2014 to 2023. Only episodes that included at least one of the following event types were considered: excessive heat, drought, wildfire, flash flood, coastal flood, strong wind, hail, tornado.\n\n\n\n\n\nShow the code\ndataForPlot &lt;- out$dataForUsPlot %&gt;% \n  mutate(nEpisodes_withNA = ifelse(nEpisodes == 0, NA_integer_, nEpisodes))\n\np.map_cont &lt;- plot_usmap(\n  data = dataForPlot,\n  values = \"nEpisodes_withNA\",\n  regions = \"counties\",\n  exclude = c(\"AK\", \"HI\"),\n  color = \"black\",\n  linewidth = 0.1\n  ) +\n  geom_sf(\n    data = poly_states[[1]] %&gt;% \n      filter(!(abbr %in% c(\"AK\", \"HI\"))),\n    color = \"black\",\n    fill = NA,\n    linewidth = .3\n  ) +\n  scale_fill_binned(\n    name = \"Number of Episodes\",\n    n.breaks = 10,\n    type = \"viridis\",\n    na.value = \"white\"\n  ) +\n  labs(\n    title = \"Extreme Weather Episodes in July over the Years 2014 to 2023\"\n  ) +\n  theme_bw() +\n  theme(\n    text = element_text(size = 15),\n    legend.position = \"bottom\",\n    plot.title = element_text(hjust = .5),\n    panel.grid = element_blank(),\n    axis.ticks = element_blank(),\n    axis.text = element_blank()\n  ) +\n  facet_wrap(~year, ncol = 5)\n\njpeg(\n  file = \"../images/mapGeographicalDistribution_cont.jpeg\",\n  width = 14, height = 7.5, units = \"in\", res = 600\n)\nprint(p.map_cont)\ninvisible(dev.off())\n\np.hist_count &lt;- out$dataForUsPlot %&gt;% \n  group_by(year, nEpisodes) %&gt;% \n  summarise(\n    count = n(),\n    prcnt = count / n_distinct(out$dataForUsPlot$fips)\n  ) %&gt;% \n  ggplot(aes(x = nEpisodes, y = prcnt)) +\n  geom_bar(stat = \"identity\", color = \"black\", fill = \"darkgrey\") +\n  scale_y_continuous(labels = scales::label_percent()) +\n  labs(\n    x = \"Number of Episodes\",\n    y = \"Proportion of Counties\"\n  ) +\n  theme_bw() +\n  labs(\n    title = \"Extreme Weather Episodes in July over the Years 2014 to 2023\"\n  ) +\n  theme(\n    text = element_text(size = 15),\n    legend.position = \"bottom\",\n    plot.title = element_text(hjust = .5)\n  ) +\n  facet_wrap(~year, ncol = 5)\n\njpeg(\n  file = \"../images/frequencyDistribution_cont.jpeg\",\n  width = 14, height = 7.5, units = \"in\", res = 600\n)\nprint(p.hist_count)\ninvisible(dev.off())\n\n# Calcualte some proportions for display in text\nprops2023 &lt;- out$dataForUsPlot %&gt;% \n  filter(year == 2023) %&gt;% \n  count(episodes_bin) %&gt;% \n  mutate(\n    freq = n/sum(n),\n    freq_prcnt = paste0(format(round(freq*100, 2), nsmall = 2), \"%\")\n  )\n\n\nWhile Figure 2 visualizes the occurrence of at least one extreme weather episode in July for each county and year (binary variable), Figure 4 displays the actual number of such episodes (continuous). The vast majority of counties were exposed to few episodes, indicating that most of the variability is due to whether an extreme weather episode occurred at all or not. This is further supported by Figure 3 showing histograms for the number of extreme weather episodes in July over the past ten years. Most counties reported either zero or one extreme weather episode in July, and the ratio of counties experiencing no episodes to counties experiencing at least one episode seems to gradually approach 1:1. In July 2023, for instance, this ratio reached 1.02, with 50.43% of counties being exposed to zero and 49.57% of counties being exposed to at least one extreme weather episode.\n\n\n\n\n\n\nFigure 3: Maps displaying the geographical distribution of the raw number of extreme weather episodes in July over the years 2014 to 2023. The color palette indicates numbers greater than zero, and white represent a count of zero episodes.\n\n\n\n\n\n\n\n\n\nFigure 4: Histograms displaying the distribution of the raw number of extreme weather episodes in July over the years 2014 to 2023. For each number of episodes on the x-axis, the y-axis shows the proportion of counties that recorded this number of episodes.\n\n\n\nFinally, as reported in the analysis plan and the design table, we plan to run a set of additional analyses regarding hypotheses H2 and H3, in which we will test the sensitivity of results to the time period prior to study completion used to assess extreme weather exposure. Regarding H2, we will estimate the two-way interaction effect of political affiliation and extreme weather exposure on ΔDuration for different time periods from 30 days to 360 days in increments of 30 days. Similarly for H3, we will estimate the three-way interaction effect of political affiliation, extreme weather exposure, and attribution of extreme weather events to climate change on ΔDuration for the same time periods. We will visualize results of these additional analyses by plotting the two-way (or three-way) interaction regression coefficients as points surrounded by their 95%-CI on the y-axis and the 12 time periods on the x-axis, as displayed in Figure 5 with simulated data. Based on previous research (Konisky, Hughes, and Kaylor 2016), we expect that the estimated effects will decay as the number of days prior to study completion used to assess the occurrence of extreme weather episodes increases.\n\n\nShow the code\nset.seed(123)\np.sensitivity &lt;- tibble(\n  Days = seq(30, 360, 30),\n  Coefficient = accumulate(1:11, ~ .x * .7, .init = 0.1143),\n  Error = rnorm(12, .07, 0.005),\n  CI_high = Coefficient + .5 * Error,\n  CI_low = Coefficient - .5 * Error\n) %&gt;% \n  ggplot(aes(x = Days, y = Coefficient, color = CI_low &lt; 0)) +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  geom_errorbar(aes(ymin = CI_low, ymax = CI_high), width = 3) +\n  geom_point(\n    shape = \"circle filled\",\n    fill = \"white\",\n    size = 3,\n    stroke = 1\n  ) +\n  scale_color_manual(values = c(\"black\", \"grey\")) +\n  scale_x_continuous(breaks = seq(30, 360, 30)) +\n  labs(\n    x = \"Days used to assess occurence of extreme weather episodes\",\n    y = \"Regression coefficient\\n(surrounded by 95%-CI)\"\n  ) +\n  theme_bw() +\n  theme(\n    panel.grid.minor = element_blank(),\n    legend.position = \"None\"\n  )\nset.seed(NULL)\n\njpeg(\n  file = \"../images/sensitivityAnalyses_simulation.jpeg\",\n  width = 7, height = 5, units = \"in\", res = 600\n)\nprint(p.sensitivity)\ninvisible(dev.off())\n\n\n\n\n\n\n\n\nFigure 5: Simulated regression coefficients of interaction effects for different number of days prior to study completion used to assess the occurrence of extreme weather episodes. Point estimates are surrounded by their 95% confidence intervals. The dashed line represents the absence of an interaction effect (regression coefficient of zero). Significance of regression coefficients is color-coded, with black indicating regression coefficients significantly different from zero, and grey indicating no significant difference from zero."
  },
  {
    "objectID": "scripts/supplementaryInformation.html#conclusion",
    "href": "scripts/supplementaryInformation.html#conclusion",
    "title": "Supplementary Information",
    "section": "3.4 Conclusion",
    "text": "3.4 Conclusion\nOur analyses indicate that July consistently shows a high number of extreme whether episodes with notable geographic variability (Figure 1 and Figure 2). Therefore, to maximize the likelihood of capturing suitable variability in exposure to extreme weather episodes, we plan to conduct our study at the beginning of August, ensuring that the 30-day period prior to study completion falls within July. Moreover, the main source of variability in exposure to extreme weather episodes in July is due to whether at least one episode occurred or not (Figure 4 and Figure 4). Thus, our main analyses will focus on whether a participant was exposed to at least one extreme weather episode in the 30 days prior to study completion, treated as a binary variable. In additional analyses, we will test the sensitivity of our results to different time periods used to assess extreme weather exposure prior to study completion."
  },
  {
    "objectID": "scripts/supplementaryInformation.html#purpose-rationale-1",
    "href": "scripts/supplementaryInformation.html#purpose-rationale-1",
    "title": "Supplementary Information",
    "section": "4.1 Purpose & Rationale",
    "text": "4.1 Purpose & Rationale\nThe primary goal of the present analyses is to determine the number of participants required to achieve 95% statistical power to detect a Smallest Effect Size Of Interest (SESOI) for a main effect of political affiliation (Democrat vs. Republican) on attentional information search behavior as assessed by ΔDuration. That is, we primarily aim for conducting a power analysis for sample-size determination, also called a priori power analysis (Giner-Sorolla et al. 2024). To this end, we use power simulations with parameters informed by previous studies to assess the statistical power for different sample sizes. This will allow us to decide on a sample size that will provide high statistical power to detect a true and theoretically relevant main effect of political affiliation.\nGiven this sample size, our secondary goal is to then assess the statistical power to detect different effect sizes for (1) the two-way interaction between political affiliation and extreme weather exposure and (2) the three-way interaction between political affiliation, extreme weather exposure, and the subjective attribution of extreme weather events to climate change. That is, we conduct power analyses for assessing effect-size sensitivity for these two- and three-way interactions (Giner-Sorolla et al. 2024).\nThe present report is organized as follows:\n\nWe describe all important variables of the planned study and how we will assess them.\nWe derive a SESOI for the main effect of political affiliation on ΔDuration.\nWe conduct power simulations for sample-size determination analysis based on this political affiliation main effect SESOI.\nWe conduct power simulations for effect-size sensitivity analyses for a two-way interaction effect between political affiliation and extreme weather exposure.\nWe conduct power simulations for effect-size sensitivity analyses for a three-way interaction effect between political affiliation, extreme weather exposure, and subjective attribution of extreme weather events to climate change."
  },
  {
    "objectID": "scripts/supplementaryInformation.html#important-variables",
    "href": "scripts/supplementaryInformation.html#important-variables",
    "title": "Supplementary Information",
    "section": "4.2 Important Variables",
    "text": "4.2 Important Variables\n\n4.2.1 ΔDuration\nParticipants will complete 25 trials in a new variant of the Carbon Emission Task (CET, Berger and Wyss 2021) optimized for online process-tracing using MouselabWEB (Willemsen and Johnson 2019). An example trial of the task is displayed and explained in Figure 6.\n\n\n\n\n\n\nFigure 6: An example trial of the new variant of the CET. (A) Participants are presented with two options which are associated with different bonus payment and carbon emission consequences. (B) Participants inspect the exact consequences regarding each attribute of each option by hovering their mouse over the respective boxes. Moving the mouse outside of a box occludes the information again. Note that whether the bonus or carbon attributes are displayed in the top row is randomized across participants but held constant within participants. (C) By visiting all boxes, participants can acquire all available information in a trial (all boxes opened simultaneously for demonstration purposes only). Note that whether the option maximizing the bonus payment for participants is presented in the left or right row is randomized within participants.\n\n\n\nIn all analyses, the criterion (dependent variable) will be ΔDuration (deltaDuration), which is calculated in each trial as:\n\\[\n\\Delta Duration = \\frac{(t_{Carbon_{A}} + t_{Carbon_{B}}) - (t_{Bonus_{A}} + t_{Bonus_{B}})}{t_{Carbon_{A}} + t_{Carbon_{B}} + t_{Bonus_{A}} + t_{Bonus_{B}}}\n\\]\nwith \\(t\\) representing the summed up dwell time on \\(Carbon/Bonus\\) boxes in Option \\(A/B\\). ΔDuration varies between -1 and 1 with:\n\na value of -1 indicating that the entire dwell time was spent on gathering Bonus information\na value of 0 indicating that the dwell time was equally split between gathering Bonus and Carbon information\na value of 1 indication that the entire dwell time was spent on gathering Carbon information\n\n\n\n4.2.2 Political Affiliation\nWe will assess political affiliation using the following question:\nGenerally speaking, do you think of yourself as a Democrat, Republican or Independent?\nParticipants will answer on the following 7-point Likert scale:\n[1] Strong Republican, [2] Not strong Republican, [3] Independent, close to Republican, [4] Independent, [5] Independent, close to Democrat, [6] Not strong Democrat, [7] Strong Democrat\nAdditionally, if participants self-identify as [4] Independent, they will be asked:\nYou said that you think of yourself as an Independent politically. If you had to identify with one party of the two parties, which one would you choose?\nParticipants will answer on the following scale:\n[1] Republican Party, [2] Democratic Party\nBased on these questions, we classify participants as either Republican or Democrat as represented by the variable polAff that can take on the following values:\n[rep] Republican Party, [dem] Democratic Party\n\n\n4.2.3 Extreme Weather Exposure\nFor each participant, we will assess the number of extreme weather episodes that occurred in the participants’ county of residence in the 30 days prior to study completion. We then create a variable ewe which equals to TRUE if at least one extreme weather episode occurred in the specified time interval, and FALSE otherwise.\n\n\n4.2.4 Subjective Attribution\nWe will assess the degree to which participants attribute extreme weather events to climate change (see Ogunbode et al. 2019). Participants will rate their agreement to the following three questions:\n\nExtreme weather events are caused in part by climate change.\nExtreme weather events are a sign that the impacts of climate change are happening now.\nExtreme weather events show us what we can expect from climate change in the future.\n\nParticipants will answer on the following 5-point Likert scale:\n[1] Strongly disagree, [2] Somewhat disagree, [3] Neither agree nor disagree, [4] Somewhat agree, [5] Strongly agree\nSubjective attribution of EWE to climate change will be operationalised as the mean agreement to these three statements. Note that Ogunbode et al. (2019), who used the same questions, response options, and aggregation, report a mean of 3.67 and a SD of 0.85 for this variable."
  },
  {
    "objectID": "scripts/supplementaryInformation.html#sesoi",
    "href": "scripts/supplementaryInformation.html#sesoi",
    "title": "Supplementary Information",
    "section": "4.3 SESOI",
    "text": "4.3 SESOI\nAs argued in the Registered Report, we hypothesize that (H1) compared to Republicans, Democrats prioritize searching for and attending to carbon over bonus information during decision-making in the CET. That is, Democrats display higher ΔDuration values compared to Republicans.\nWhile H1 describes the direction of the expected effect, it does not specify the expected magnitude of the effect. This later point is clarified by asking the question what would be the smallest effect size that researchers would still consider theoretically relevant, i.e., what is the smallest effect size of interest (SESOI)? We argue for such a SESOI on theoretical grounds and based on previous MouselabWEB research.\nIn mouselabWEB studies, it is standard practice to filter out any information acquisition lasting less than 200 msec because such very short (spurious) acquisitions are very unlikely to be consciously processed (Willemsen and Johnson 2019). Therefore, we derive the SESOI based on the consideration that for an effect to be meaningful, the increase in ΔDuration from a Republican to a Democrat should be due to an increase of the time spent gathering carbon (relative to bonus) information of at least 200 msec. We need to translate these considerations into the metric of ΔDuration.\nSuppose that Republicans on average spend \\(t_{Carbon}\\) msec on gathering carbon information and \\(t_{Bonus}\\) msec on gathering bonus information in each trial, with a total time of gathering any information \\(t_{Total} = t_{Carbon} + t_{Bonus}\\). Thus, for Republicans, this results in:\n\\[\n\\Delta Duration_{Rep} = \\frac{t_{Carbon} - t_{Bonus}}{t_{Total}}\n\\]\nSuppose that Democrats have the same \\(t_{Total}\\) as Republicans, but they spend 200 msec more on gathering carbon information and, correspondingly, 200 msec less on gathering bonus information. Thus, for Democrats, this results in:\n\\[\n\\Delta Duration_{Dem} = \\frac{(t_{Carbon} + 200) - (t_{Bonus} - 200)}{t_{Total}} \\\\\n                      = \\frac{400 + t_{Carbon} - t_{Bonus}}{t_{Total}}\n\\]\nTherefore, the difference in \\(\\Delta Duration\\) for Democrats and Republicans is:\n\\[\n\\begin{split}\n\\Delta Duration_{Dem} - \\Delta Duration_{Rep} = \\frac{400 + t_{Carbon} - t_{Bonus}}{t_{Total}} -  \\frac{t_{Carbon} - t_{Bonus}}{t_{Total}} \\\\\n  = \\frac {(400 + t_{Carbon} - t_{Bonus}) - (t_{Carbon} - t_{Bonus})}{t_{Total}} \\\\\n  = \\frac {400}{t_{Total}}\n\\end{split}\n\\]\nThus, we define our SESOI as:\n\\[SESOI_{polAff} = \\frac{400\\ msec}{t_{Total}}\\]\nAs this definition shows, the SESOI depends on our expectation regarding \\(t_{Total}\\). We form these expectations based on previous research. In our lab, we recently conducted another MouselabWEB study whose setup was very similar to the one described in the Registered Report (Studler et al., in preparation). In short, student participants completed a behavioral task in which they searched for and attended to information presented in a 2-by-2 decision matrix adapted from Reeck, Wall, and Johnson (2017). The average time participants spent on acquiring information in each trial (\\(t_{Total}\\)) was 3.3 seconds. In the planned study we will assess a representative US sample. That is, the average age of our sample will be higher than in a typical student sample. As processing speed is known to decline with age (Salthouse 2000), we assume a slightly higher total information acquisition time in our sample of \\(t_{Total} = 3500\\ msec\\). Therefore, we define our SESOI as:\n\\[\nSESOI_{polAff} = \\frac{400\\ msec}{3500\\ msec} = 0.1143\n\\]\nTo account for uncertainty in this estimation, we also provide sample-size determination analysis results based on \\(t_{Total} = 4000\\ msec\\) and \\(t_{Total} = 3000\\ msec\\). This results in a high and low estimate of SESOI:\n\\[\n\\begin{split}\nSESOI_{polAff_{high}} = \\frac{400\\ msec}{3000\\ msec} = 0.1333 \\\\\nSESOI_{polAff_{low}} = \\frac{400\\ msec}{4000\\ msec} = 0.1000\n\\end{split}\n\\]"
  },
  {
    "objectID": "scripts/supplementaryInformation.html#main-effect",
    "href": "scripts/supplementaryInformation.html#main-effect",
    "title": "Supplementary Information",
    "section": "4.4 Main Effect",
    "text": "4.4 Main Effect\nAs argued in the Registered Report, we hypothesize:\n(H1) Compared to Republicans, Democrats prioritize searching for and attending to carbon over bonus information during decision-making in the Carbon Emission Task. That is, Democrats display higher ΔDuration values compared to Republicans.\n\n\nShow the code\n# Create a data frame with predicted true effects\n\n# Smallest Effect Size Of Interest (SESOI)\nSESOI &lt;- 0.4/3.5\n\n# Betas\nbeta_p &lt;- SESOI\n\n# Predicted \"true\" effects\npolAff_trueEffects &lt;- expand_grid(\n  polAff = factor(c(\"rep\", \"dem\"), levels = c(\"rep\", \"dem\"))\n) %&gt;% \n  add_contrast(\"polAff\", contrast = \"anova\", colnames = \"X_p\") %&gt;% \n  mutate(\n    trueDeltaDuration =\n      0 +         # intercept\n      X_p * beta_p # main effect polAff\n  )\n\n\n\n4.4.1 Data Simulation Function\nWe first define a function that simulates data for the main effect of political affiliation on ΔDuration: FUN_sim. The function will simulate data according to the following model, expressed in lme4-lingo:\ndeltaDuration ~ polAff + (1|subj) + (1|trial)\nThe function FUN_sim takes, among others, the following important arguments:\n\nn_subj: Number of subjects. Chaning this parameter allows us to assess statistical power for different sample sizes.\nbeta_0: Fixed intercept (grand mean). We assume that the average participant (irrespective of political affiliation or any other predictor variable) spends about the same time on searching for and attending to carbon as to bonus information in the CET. Therefore, we set beta_0 to zero. The effects of predictor variables will be modeled as deviations from this grand mean.\nbeta_p: Fixed effect of political affiliation. This value represents the average difference in ΔDuration between Democrats and Republicans (Democrats - Republicans). As discussed above, we set this value to 0.1143 by default, and we assess the effect of changing this variable on statistical power.\nsubj_0: By-subject random intercept SD. We simulate that a participants’ deviations from the grand mean for ΔDuration follows a normal distribution with a mean of 0 and a standard deviation of subj_0 = 0.29. We base our default value on a study by Reeck, Wall, and Johnson (2017). They investigated whether variability in information search behavior is driven predominantly by differences in the features of a choice (i.e., in our case: the relative differences between carbon and bonus outcomes in options A and B) or by individual differences. To this end, they predicted information acquisition using a intercept-only model that included random intercepts for subjects and items. They estimated the random intercept of subjects to be 0.29.\ntrial_0: By-trial random intercept SD. We simulate that a items’ deviations from the grand mean for ΔDuration follows a normal distribution with a mean of 0 and a standard deviation of trial_0 = 0.04. Again, we base our default value on the study by Reeck, Wall, and Johnson (2017), who estimated a random intercept for trials of 0.04.\nsigma: Trial-level noise (error) SD. We model the error SD to be of the same size as the sum of the random intercept SDs = 0.29 + 0.04 = 0.33. We also report simulation results for an error SD that is twice the size of the random intercept SDs, i.e., 0.66.\n\nThe function FUN_sim is defined below (code visible in html output only):\n\n\nShow the code\n# define data simulation function\nFUN_sim &lt;- function(\n  n_subj       =        1000, # number of subjects\n  n_subj_prop  =   c(.5, .5), # proportion of republican and democrat subjects\n  n_trial      =          25, # number of trials\n  beta_0       =           0, # intercept (grand mean) for deltaDuration\n  beta_p       =     0.4/3.5, # effect of political affiliation on deltaDuration\n  subj_0       =         .29, # by-subject random intercept sd for dt carbon\n  trial_0      =         .04, # by-trial random intercept sd\n  sigma        = 1*(.29+.04), # residual (error) sd\n  \n  truncNums    =        TRUE, # should impossible deltaDuration values be truncuated?\n  setSeed      =        NULL  # seed number to achieve reproducible results. Set to NULL for simulations!\n) {\n  \n  # set seed to achieve reproducible results for demonstration purposes\n  set.seed(setSeed)\n  \n  # simulate data for dwell time on carbon information\n  dataSim &lt;- \n    # add random factor subject\n    add_random(subj = n_subj) %&gt;% \n    # add random factor trial\n    add_random(trial = n_trial) %&gt;% \n    # add between-subject factor political affiliation (with anova contrast)\n    add_between(\"subj\", polAff = c(\"rep\", \"dem\"), .prob = n_subj_prop*n_subj, .shuffle = FALSE) %&gt;% \n    add_contrast(\"polAff\", colnames = \"X_p\", contrast = \"anova\") %&gt;% \n    # add by-subject random intercept\n    add_ranef(\"subj\", S_0 = subj_0) %&gt;% \n    # add by-trial random intercept\n    add_ranef(\"trial\", T_0 = trial_0) %&gt;% \n    # add error term\n    add_ranef(e_st = sigma) %&gt;% \n    # add response values\n    mutate(\n      # add together fixed and random effects for each effect\n      B_0 = beta_0 + S_0 + T_0,\n      B_p = beta_p,\n      # calculate dv by adding each effect term multiplied by the relevant\n      # effect-coded factors and adding the error term\n      deltaDuration = B_0 + (B_p * X_p) + e_st\n    )\n  \n  # unset seed\n  set.seed(NULL)\n  \n  # truncuate impossible deltaDurations\n  if(truncNums) {\n    dataSim &lt;- dataSim %&gt;% \n      mutate(deltaDuration = if_else(deltaDuration &lt; -1, -1,\n        if_else(deltaDuration &gt; 1, 1, deltaDuration)))\n  }\n  \n  # run a linear mixed effects model and check summary\n  mod &lt;- lmer(\n    deltaDuration ~ polAff + (1 | subj) + (1 | trial),\n    data = dataSim,\n  )\n  mod.sum &lt;- summary(mod)\n  \n  # get results in tidy format\n  mod.broom &lt;- broom.mixed::tidy(mod)\n  \n  return(list(\n    dataSim = dataSim,\n    modelLmer = mod,\n    modelResults = mod.broom\n  ))\n  \n}\n\n\nWe call the function once and extract the results of this single simulation (code visible in html output only):\n\n\nShow the code\n# Call function\nout &lt;- FUN_sim(\n  n_subj       =        1000, # number of subjects\n  n_subj_prop  =   c(.5, .5), # proportion of republican and democrat subjects\n  n_trial      =          25, # number of trials\n  beta_0       =           0, # intercept (grand mean) for deltaDuration\n  beta_p       =     0.4/3.5, # effect of political affiliation on deltaDuration\n  subj_0       =         .29, # by-subject random intercept sd for dt carbon\n  trial_0      =         .04, # by-trial random intercept sd\n  sigma        = 1*(.29+.04), # residual (error) sd\n  \n  truncNums    =        TRUE, # should impossible deltaDuration values be truncuated?\n  setSeed      =        1234  # seed number to achieve reproducible results. Set to NULL for simulations!\n)\n\n# Get results table\nresultsTable &lt;- out$modelResults %&gt;% \n  select(-c(std.error, statistic, df)) %&gt;% \n  mutate(across(where(is_double), ~ round(.x, 4))) %&gt;% \n  knitr::kable()\nformulaUsedForFit &lt;- paste(as.character(formula(out$modelLmer))[c(2,1,3)], collapse = \" \")\n\n# Create plot\np.demo.mainEffect &lt;-  out$dataSim %&gt;% \n  ggplot(aes(x = polAff, y = deltaDuration, color = polAff)) +\n  geom_hline(yintercept = 0) +\n  geom_violin(alpha = 0.3) +\n  geom_point(\n    data = polAff_trueEffects,\n    mapping = aes(x = polAff, y = trueDeltaDuration),\n    shape = \"circle open\",\n    size = 3.5,\n    stroke = 2,\n    color = \"black\"\n  ) +\n  stat_summary(\n    fun = mean,\n    fun.min = \\(x){mean(x) - sd(x)},\n    fun.max = \\(x){mean(x) + sd(x)},\n    position = position_dodge(width = .9)\n  ) +\n  ggrepel::geom_label_repel(\n    data = polAff_trueEffects,\n    mapping = aes(x = polAff, y = trueDeltaDuration, label = round(trueDeltaDuration, 4)),\n    color = \"black\",\n    box.padding = 1\n  ) +\n  scale_color_manual(values = c(\"red\", \"dodgerblue\")) +\n  scale_y_continuous(breaks = seq(-1, 1, .2)) +\n  labs(title = \"Demo Output of One Simulation for Main Effect\") +\n  theme_bw() +\n  theme(legend.position = \"none\")\n\njpeg(\n  file = \"../images/pa_demoMainEffect.jpeg\",\n  width = 9.1, height = 6.5, units = \"in\", res = 600\n)\nprint(p.demo.mainEffect)\ninvisible(dev.off())\n\n\nFigure 7 visualizes the results of this single simulation and Table 4 summarises the statistical results of fitting the actual model used in data generation to the simulated data.\n\n\n\n\n\n\nFigure 7: Visual representation of results of one simulation created using FUN_sim. Violin plots display the full distribution of the data. Points and surrounding lines indicate the mean ± 1 SD. The black horizontal line displays the true sample mean and the black open circles indicate the true means for each cell.\n\n\n\n\nShow the code\nresultsTable\n\n\n\n\nTable 4: Statistical results of one simulation created using FUN_sim. Data was fit using deltaDuration ~ polAff + (1 | subj) + (1 | trial).\n\n\n\n\n\n\n\neffect\ngroup\nterm\nestimate\np.value\n\n\n\n\nfixed\nNA\n(Intercept)\n-0.0188\n0.1105\n\n\nfixed\nNA\npolAff.dem-rep\n0.0896\n0.0000\n\n\nran_pars\nsubj\nsd__(Intercept)\n0.2841\nNA\n\n\nran_pars\ntrial\nsd__(Intercept)\n0.0363\nNA\n\n\nran_pars\nResidual\nsd__Observation\n0.3223\nNA\n\n\n\n\n\n\n\n\n\n\n4.4.2 Power Simulation\nWe now simulate multiple random samples drawn from the same synthetic population with a known true effect of political affiliation. For each random sample, we fit our statistical model to the data. The statistical power to detect a true effect of political affiliation is calculated as the proportion of significant effects out of the total number of simulations. We aim for a statistical power of 95%.\nIn the following code, the simulations are calculated. We do not recommend executing this code junk as it takes several hours to run (code only shown in the html version).\n\n\nShow the code\nFUN_sim_pwr &lt;- function(sim, ...){\n  out &lt;- FUN_sim(...)\n  modelResults &lt;- out$modelResults %&gt;% \n    mutate(sim = sim) %&gt;% \n    relocate(sim)\n  return(modelResults)\n}\n\n# How many simulations should be run?\nn_sims &lt;- 1000\n\n# What are the breaks for number of subjects we would like to calculate power for?\nbreaks_subj &lt;- seq(200, 1000, 200)\n\n# What are the breaks for SESOI?\nbreaks_sesoi &lt;- c(0.4/3, 0.4/3.5, 0.4/4)\n\n# What are the breaks for different errer SDs?\nbreaks_sigma &lt;- c(1:2)*(.29+.04)\n\nres_mainEffect &lt;- tibble()\nfor (s in seq_along(breaks_sigma)) {\n  \n  res_sesoi &lt;- tibble()\n  for (sesoi in seq_along(breaks_sesoi)) {\n    \n    res_nSubj &lt;- tibble()\n    for (nSubj in seq_along(breaks_subj)) {\n      \n      # Give feedback regarding which model is simulated\n      cat(paste0(\n        \"Simulation:\\n\",\n        \"  sigma = \", round(breaks_sigma[s], 4), \"\\n\",\n        \"  sesoi = \", round(breaks_sesoi[sesoi], 4), \"\\n\",\n        \"  nSubject = \", breaks_subj[nSubj], \"\\n\"\n      ))\n      \n      # Start timer\n      cat(paste0(\"Start date time: \", lubridate::now(), \"\\n\"))\n      tic()\n      \n      # Loop over simulations\n      pwr &lt;- map_df(\n        1:n_sims, \n        FUN_sim_pwr,\n        n_subj = breaks_subj[nSubj],\n        beta_p = breaks_sesoi[sesoi],\n        sigma = breaks_sigma[s]\n      )\n      \n      # Stop timer and calculate elapsed time\n      elapsed_time &lt;- toc(quiet = TRUE)\n      elapsed_seconds &lt;- elapsed_time$toc - elapsed_time$tic\n      elapsed_minutes &lt;- elapsed_seconds / 60\n      cat(paste0(\"End date time: \", lubridate::now(), \"\\n\"))\n      cat(\"Elapsed time: \", elapsed_minutes, \" minutes\\n\\n\")\n      \n      # Add number of subjects to pwr\n      pwr &lt;- pwr %&gt;% \n        mutate(\n          nSubjects = breaks_subj[nSubj],\n          sesoi = breaks_sesoi[sesoi],\n          sigma = breaks_sigma[s]\n        )\n      \n      # Add results to the results table\n      res_nSubj &lt;- res_nSubj %&gt;%\n        rbind(pwr)\n    }\n    \n    # Add results to the results table\n    res_sesoi &lt;- res_sesoi %&gt;% \n      rbind(res_nSubj)\n  }\n  \n  # Add results to the results table\n  res_mainEffect &lt;- res_mainEffect %&gt;% \n    rbind(res_sesoi)\n  \n}\n\nres_mainEffect.summary &lt;- res_mainEffect %&gt;% \n  filter(term == \"polAff.dem-rep\") %&gt;% \n  group_by(sigma, sesoi, nSubjects) %&gt;% \n  summarise(\n    power = mean(p.value &lt; 0.05),\n    ci.lower = binom.confint(power*n_sims, n_sims, methods = \"exact\")$lower,\n    ci.upper = binom.confint(power*n_sims, n_sims, methods = \"exact\")$upper,\n    .groups = 'drop'\n  ) %&gt;% \n  mutate(\n    sigma_fact = factor(format(round(sigma, 4), nsmall = 4)),\n    sigma_level = match(sigma_fact, levels(sigma_fact)),\n    sesoi_fact = factor(format(round(sesoi, 4), nsmall = 4)),\n    sesoi_level = match(sesoi_fact, levels(sesoi_fact))\n  )\n\n# Save results in a list object\ntime &lt;- format(Sys.time(), \"%Y%m%d_%H%M\")\nfileName &lt;- paste0(\"res_mainEffect\", \"_\", time, \".RDS\")\nsaveRDS(\n  list(\n    res_mainEffect = res_mainEffect,\n    res_mainEffect.summary = res_mainEffect.summary\n  ),\n  file = file.path(\"../powerSimulationsOutput\", fileName)\n)\n\n\nWe retrieve pre-run results:\n\n\nShow the code\n# Load power simulation data\nresList_mainEffect &lt;- readRDS(file.path(\"../powerSimulationsOutput\", \"res_mainEffect_20240813_2141.RDS\"))\nresList_mainEffect.summary &lt;- resList_mainEffect$res_mainEffect.summary\n\n# Extract power values for some specific effect sizes at N = 1000\nchosenN &lt;- 600\nchosenSigma &lt;- c(\"0.3300\", \"0.6600\")\nchosenSESOI &lt;- c(\"0.1000\", \"0.1143\")\npowerValues &lt;- resList_mainEffect.summary %&gt;% \n  filter(sigma_fact %in% chosenSigma) %&gt;% \n  filter(sesoi_fact %in% chosenSESOI) %&gt;% \n  filter(nSubjects %in% chosenN) %&gt;% \n  mutate(power_str = paste0(round(ci.lower*100, 2), \"%\")) %&gt;% \n  pull(power_str)\n\n# Extract number of simulations\nlabel_nSimulations &lt;- resList_mainEffect$res_mainEffect$sim %&gt;% n_distinct()\n\n\nFigure 8 displays the distribution of estimated fixed effects across all simulations. The figure shows that the estimated fixed effects are close to the true ones provided as input in the data simulation function, validating that simulations worked as expected.\n\n\n\n\n\n\nFigure 8: Distribution of estimated fixed effects resulting from 1000 simulations for the model deltaDuration ~ polAff + (1 | subj) + (1 | trial). Shaded area represent densities, annotated points indicate medians, and thick and thin lines represent 66% and 95% quantiles.\n\n\n\nFigure 9 shows results of our sample-size determination analyses. We find that a sample size of 600 provides a statistical power of 95.4% (lower bound of 95%-CI) even under the most conservative assumptions (SESOI = 0.1000, Error SD = 0.6600).\n\n\nShow the code\n# Get power values of interest\nchosenN &lt;- c(800, 1000)\nchosenSigma &lt;- c(\"0.3300\", \"0.6600\")\nchosenSESOI &lt;- c(\"0.1000\")\npowerValues &lt;- resList_mainEffect.summary %&gt;% \n  filter(sigma_fact %in% chosenSigma) %&gt;% \n  filter(sesoi_fact %in% chosenSESOI) %&gt;% \n  filter(nSubjects %in% chosenN)\n\n# Get lower CI for power values for conservative sigma assumptions\npowerValues_sigmaCons &lt;- powerValues %&gt;% \n  filter(sigma_fact == \"0.6600\")\n\n# Interpolate the effect sizes at which we achieve 99% power\neff_sigmaCons &lt;- approx(powerValues_sigmaCons$ci.lower, powerValues_sigmaCons$nSubjects, xout = 0.99)$y\n# Round results for display in text\neff_sigmaCons_txt &lt;- toString(round(eff_sigmaCons))\n\n\nMoreover, we inspect the lower bounds of the 95%-CI power estimates in Figure 9. Specifically, we focus on the power simulation results for a conservative SESOI of 0.1000 and an error SD of 0.6600. Then, we use interpolation between sample sizes of 800 and 1000 to estimate the number of participants needed to achieve 99% statistical power (lower bounds of 95%-CI power estimates). Results reveal that with a sample size of N = 895, we would achieve 99% statistical power (lower bound of 95%-CI power estimate) to detect a true effect of at least 0.1000.\nWe optimize the study design to detect a true SESOI for political affiliation. However, we are also interested in two-way and three-way interaction effects, which are known to require greater sample sizes to achieve the same statistical power as for main effects. Moreover, greater sample sizes are more likely to accurately represent target populations with respect to variables like exposure to extreme weather events and subjective attribution of extreme weather events to climate change. Therefore, we opt for a sample size of N = 1000 for further effect-size sensitivity analyses regarding interaction effects.\n\n\n\n\n\n\nFigure 9: Power curves for the main effect of polAff. Points represent statistical power surrounded by a 95%-CI based on 1000 simulations with α = 0.05."
  },
  {
    "objectID": "scripts/supplementaryInformation.html#two-way-interaction-effect",
    "href": "scripts/supplementaryInformation.html#two-way-interaction-effect",
    "title": "Supplementary Information",
    "section": "4.5 Two-Way Interaction Effect",
    "text": "4.5 Two-Way Interaction Effect\nAs argued in the Registered Report, we hypothesize:\n(H2): Exposure to extreme weather events amplifies the polarization in attentional information search processes, increasing the difference in ΔDuration between Republicans and Democrats among individuals with (vs. without) such exposure. In other words, there is a positive two-way interaction effect of extreme weather exposure and political affiliation on ΔDuration.\n\n\nShow the code\n# Create a data frame with predicted true effects\n\n# Smallest Effect Size Of Interest (SESOI)\nSESOI &lt;- 0.4/3.5\n\n# Betas\nbeta_p &lt;- SESOI\nbeta_e &lt;- 0\nbeta_p_e_inx &lt;- SESOI\n\n# Predicted \"true\" effects\npolAff_ewe_trueEffects &lt;- expand_grid(\n  polAff = factor(c(\"rep\", \"dem\"), levels = c(\"rep\", \"dem\")),\n  ewe = factor(c(FALSE, TRUE), levels = c(FALSE, TRUE))\n) %&gt;% \n  add_contrast(\"polAff\", contrast = \"anova\", colnames = \"X_p\") %&gt;% \n  add_contrast(\"ewe\", contrast = \"anova\", colnames = \"X_e\") %&gt;% \n  mutate(\n    trueDeltaDuration =\n      0 +                        # intercept\n      X_p * beta_p +             # main effect polAff\n      X_e * beta_e +             # main effect ewe\n      X_p * X_e * beta_p_e_inx   # interaction effect polAff*ewe\n  )\n\n\n\n4.5.1 SESOI for Two-Way Interaction\nFor deriving a SESOI for the two-way interaction of interest, similar considerations apply as in the case of the SESOI for the main effect of interest. In this section, we make these considerations explicit. We start by noticing that the complete fixed two-way interaction polAff × ewe is modeled as:\n\\[\n\\Delta Duration = \\beta_{0} + \\beta_{1} \\cdot polAff + \\beta_{2} \\cdot ewe  + \\beta_{3} \\cdot (polAff \\times ewe)\n\\]\nBy rearranging terms, one can show that the effect of polAff is given by:\n\\[\nEffect_{polAff} = \\beta_{1} + \\beta_{3} \\cdot ewe\n\\]\nNow, let’s calculate this effect for two individuals who differ in their levels of ewe. As ewe is a binary variable, we have two types of individuals: individuals with (ewe = 1) and without (ewe = 0) extreme weather exposure. For an individual without extreme weather exposure, the effect of polAff will be:\n\\[\nEffect_{noEWE} = \\beta_{1} + \\beta_{3} \\cdot 0 = \\beta_{1}\n\\]\nFor an individual with extreme weather exposure, the effect of polAff will be:\n\\[\nEffect_{EWE} = \\beta_{1} + \\beta_{3} \\cdot 1 = \\beta_{1} + \\beta_{3}\n\\]\nThe difference in the effect of polAff between these two individuals is given by:\n\\[\n\\begin{split}\nEffect_{EWE} - Effect_{noEWE} = (\\beta_{1} + \\beta_{3}) - \\beta_{1} = \\beta_{3}\n\\end{split}\n\\]\nWe consider this difference as theoretically relevant if it is at least of the same size as the SESOI for the effect of polAff:\n\\[\nSESOI_{polAff \\times ewe} = Effect_{EWE} - Effect_{noEWE} = SESOI_{polAff} = 0.1143\n\\]\n\n\n4.5.2 Data Simulation Function\nWe next define a function that simulates data for the two-way interaction effect of political affiliation with extreme weather exposure on ΔDuration: FUN_sim_2wayInt. The function will simulate data according to the following model, expressed in lme4-lingo:\ndeltaDuration ~ polAff * ewe + (1|subj) + (1|trial)\nThe function FUN_sim_2wayInt takes, among others, the following important arguments (in addition to the arguments discussed for FUN_sim):\n\nbeta_p: Fixed main effect of political affiliation. Compatible with H1, we keep this value at the SESOI of 0.1143. That is, we model that the average effect of political affiliation across all participants, irrespective of their extreme weather exposure, is 0.1143.\nbeta_e: Fixed main effect of extreme weather exposure. As we are interested in the moderating role of extreme weather exposure, we set this main effect to zero. That is, we assume that the effect of extreme weather exposure is highly dependent on participants’ political affiliation.\nbeta_p_e_inx: Fixed two-way interaction effect of political affiliation and extreme weather exposure. We set this initial value to the SESOI derived above, but we investigate how changing this effect size impacts statistical power, as we are conducting effect-size sensitivity analyses for interaction effects.\n\nThe function FUN_sim_2wayInt is defined below:\n\n\nShow the code\n# define data simulation function\nFUN_sim_2wayInt &lt;- function(\n  n_subj         =        1000, # number of subjects\n  n_subj_prop_p  =   c(.5, .5), # proportion of republican and democrat subjects\n  n_subj_prop_e  =   c(.5, .5), # proportion of subjects without and with extreme weather exposure\n  n_trial        =          25, # number of trials\n  beta_0         =           0, # intercept (grand mean) for deltaDuration\n  beta_p         =     0.4/3.5, # main effect of political affiliation (polAff)\n  beta_e         =           0, # main effect of extreme weather exposure (ewe)\n  beta_p_e_inx   =     0.4/3.5, # two-way interaction effect of polAff and ewe\n  subj_0         =         .29, # by-subject random intercept sd for dt carbon\n  trial_0        =         .04, # by-trial random intercept sd\n  sigma          = 1*(.29+.04), # residual (error) sd\n  \n  truncNums      =        TRUE, # should impossible numbers be truncuated?\n  setSeed        =        NULL  # seed number to achieve reproducible results. Set to NULL for simulations!\n) {\n  \n  # set seed to achieve reproducible results for demonstration purposes\n  set.seed(setSeed)\n  \n  # simulate data for dwell time on carbon information\n  dataSim &lt;- \n    # add random factor subject\n    add_random(subj = n_subj) %&gt;% \n    # add random factor trial\n    add_random(trial = n_trial) %&gt;% \n    # add between-subject factor political affiliation (with anova contrast)\n    add_between(\"subj\", polAff = c(\"rep\", \"dem\"), .prob = n_subj_prop_p*n_subj, .shuffle = TRUE) %&gt;% \n    add_contrast(\"polAff\", colnames = \"X_p\", contrast = \"anova\") %&gt;% \n    # add between-subject factor extreme weather exposure (with anova contrast)\n    add_between(\"subj\", ewe = c(FALSE, TRUE), .prob = n_subj_prop_e*n_subj, .shuffle = TRUE) %&gt;% \n    add_contrast(\"ewe\", colnames = \"X_e\", contrast = \"anova\") %&gt;% \n    # add by-subject random intercept\n    add_ranef(\"subj\", S_0 = subj_0) %&gt;% \n    # add by-trial random intercept\n    add_ranef(\"trial\", T_0 = trial_0) %&gt;% \n    # add error term\n    add_ranef(e_st = sigma) %&gt;% \n    # add response values\n    mutate(\n      # add together fixed and random effects for each effect\n      B_0 = beta_0 + S_0 + T_0,\n      B_p = beta_p,\n      B_e = beta_e,\n      B_p_e_inx = beta_p_e_inx,\n      # calculate dv by adding each effect term multiplied by the relevant\n      # effect-coded factors and adding the error term\n      deltaDuration = \n        B_0 + e_st +\n        (X_p * B_p) +\n        (X_e * B_e) +\n        (X_p * X_e * B_p_e_inx)\n    )\n  \n  # truncuate impossible deltaDurations\n  if(truncNums) {\n    dataSim &lt;- dataSim %&gt;% \n      mutate(deltaDuration = if_else(deltaDuration &lt; -1, -1,\n        if_else(deltaDuration &gt; 1, 1, deltaDuration)))\n  }\n  \n  # run a linear mixed effects model and check summary\n  mod &lt;- lmer(\n    deltaDuration ~ polAff*ewe + (1 | subj) + (1 | trial),\n    data = dataSim\n  )\n  mod.sum &lt;- summary(mod)\n  \n  # get results in tidy format\n  mod.broom &lt;- broom.mixed::tidy(mod)\n  \n  return(list(\n    dataSim = dataSim,\n    modelLmer = mod,\n    modelResults = mod.broom\n  ))\n  \n}\n\n\nWe call the function once and extract the results of this single simulation:\n\n\nShow the code\nout &lt;- FUN_sim_2wayInt(\n  n_subj         =        1000, # number of subjects\n  n_subj_prop_p  =   c(.5, .5), # proportion of republican and democrat subjects\n  n_subj_prop_e  =   c(.5, .5), # proportion of subjects without and with extreme weather exposure\n  n_trial        =          25, # number of trials\n  beta_0         =           0, # intercept (grand mean) for deltaDuration\n  beta_p         =     0.4/3.5, # main effect of political affiliation (polAff)\n  beta_e         =           0, # main effect of extreme weather exposure (ewe)\n  beta_p_e_inx   =     0.4/3.5, # two-way interaction effect of polAff and ewe\n  subj_0         =         .29, # by-subject random intercept sd for dt carbon\n  trial_0        =         .04, # by-trial random intercept sd\n  sigma          = 1*(.29+.04), # residual (error) sd\n  \n  truncNums      =        TRUE, # should impossible numbers be truncuated?\n  setSeed        =        1234  # seed number to achieve reproducible results. Set to NULL for simulations!\n)\n\n# Get results table\nresultsTable &lt;- out$modelResults %&gt;% \n  select(-c(std.error, statistic, df)) %&gt;% \n  mutate(across(where(is_double), ~ round(.x, 4))) %&gt;% \n  knitr::kable()\nformulaUsedForFit &lt;- paste(as.character(formula(out$modelLmer))[c(2,1,3)], collapse = \" \")\n\n# Create plot\np.demo.2wayInt &lt;-  out$dataSim %&gt;% \n  ggplot(aes(x = ewe, y = deltaDuration, color = polAff)) +\n  geom_hline(yintercept = 0) +\n  geom_violin(alpha = 0.3) +\n  geom_point(\n    data = polAff_ewe_trueEffects,\n    mapping = aes(x = ewe, y = trueDeltaDuration, fill = polAff),\n    shape = \"circle open\",\n    size = 3.5,\n    stroke = 2,\n    color = \"black\",\n    position = position_dodge(width = .9),\n    show.legend = FALSE\n  ) +\n  stat_summary(\n    fun = mean,\n    fun.min = \\(x){mean(x) - sd(x)},\n    fun.max = \\(x){mean(x) + sd(x)},\n    position = position_dodge(width = .9)\n  ) +\n  ggrepel::geom_label_repel(\n    data = polAff_ewe_trueEffects,\n    mapping = aes(x = ewe, y = trueDeltaDuration, fill = polAff, label = round(trueDeltaDuration, 4)),\n    color = \"black\",\n    box.padding = 1,\n    position = position_dodge(width = .9),\n    show.legend = FALSE\n  ) +\n  scale_color_manual(values = c(\"red\", \"dodgerblue\")) +\n  scale_fill_manual(values = c(\"white\", \"white\")) +\n  scale_y_continuous(breaks = seq(-1, 1, .2)) +\n  labs(title = \"Demo Output of One Simulation for Two-Way Interaction\") +\n  theme_bw()\n\njpeg(\n  file = \"../images/pa_demo2wayInt.jpeg\",\n  width = 9.1, height = 6.3, units = \"in\", res = 600\n)\nprint(p.demo.2wayInt)\ninvisible(dev.off())\n\n\nFigure 10 visualizes the results of this single simulation and Table 5 summarizes the statistical results of fitting the actual model used in data generation to the simulated data.\n\n\n\n\n\n\nFigure 10: Visual representation of results of one simulation created using FUN_sim_2wayInt. Violin plots display the full distribution of the data. Points and surrounding lines indicate the mean ± 1 SD. The black horizontal line displays the true sample mean and the black open circles indicate the true means for each cell.\n\n\n\n\n\n\nTable 5: Statistical results of one simulation created using FUN_sim_2wayInt. Data was fit using deltaDuration ~ polAff * ewe + (1 | subj) + (1 | trial).\n\n\n\n\n\n\n\neffect\ngroup\nterm\nestimate\np.value\n\n\n\n\nfixed\nNA\n(Intercept)\n-0.0006\n0.9625\n\n\nfixed\nNA\npolAff.dem-rep\n0.1290\n0.0000\n\n\nfixed\nNA\newe.TRUE-FALSE\n-0.0139\n0.4516\n\n\nfixed\nNA\npolAff.dem-rep:ewe.TRUE-FALSE\n0.1398\n0.0002\n\n\nran_pars\nsubj\nsd__(Intercept)\n0.2855\nNA\n\n\nran_pars\ntrial\nsd__(Intercept)\n0.0382\nNA\n\n\nran_pars\nResidual\nsd__Observation\n0.3232\nNA\n\n\n\n\n\n\n\n\n\n\n4.5.3 Power Simulation\nIn the following code, the simulations are calculated. We do not recommend executing this code junk as it takes several hours to run.\n\n\nShow the code\nFUN_sim_2wayInt_pwr &lt;- function(sim, ...){\n  out &lt;- FUN_sim_2wayInt(...)\n  modelResults &lt;- out$modelResults %&gt;% \n    mutate(sim = sim) %&gt;% \n    relocate(sim)\n  return(modelResults)\n}\n\n# How many simulations should be run?\nn_sims &lt;- 1000\n\n# What are the breaks for number of subjects we would like to calculate power for?\nbreaks_subj &lt;- c(900, 950, 1000)\n\n# What are the breaks for SESOI?\nbreaks_sesoi &lt;- (0.4/3.5)*seq(1, 2, .25)\n\n# What are the breaks for different error SDs?\nbreaks_sigma &lt;- c((.29+.04), 2*(.29+.04))\n\nres_2wayInt &lt;- tibble()\nfor (s in seq_along(breaks_sigma)) {\n  \n  res_sesoi &lt;- tibble()\n  for (sesoi in seq_along(breaks_sesoi)) {\n    \n    res_nSubj &lt;- tibble()\n    for (nSubj in seq_along(breaks_subj)) {\n      \n      # Give feedback regarding which model is simulated\n      cat(paste0(\n        \"Simulation:\\n\",\n        \"  sigma = \", round(breaks_sigma[s], 4), \"\\n\",\n        \"  sesoi = \", round(breaks_sesoi[sesoi], 4), \"\\n\",\n        \"  nSubject = \", breaks_subj[nSubj], \"\\n\"\n      ))\n      \n      # Start timer\n      cat(paste0(\"Start date time: \", lubridate::now(), \"\\n\"))\n      tic()\n      \n      # Loop over simulations\n      pwr &lt;- map_df(\n        1:n_sims, \n        FUN_sim_2wayInt_pwr,\n        n_subj = breaks_subj[nSubj],\n        beta_p_e_inx = breaks_sesoi[sesoi],\n        sigma = breaks_sigma[s]\n      )\n      \n      # Stop timer and calculate elapsed time\n      elapsed_time &lt;- toc(quiet = TRUE)\n      elapsed_seconds &lt;- elapsed_time$toc - elapsed_time$tic\n      elapsed_minutes &lt;- elapsed_seconds / 60\n      cat(paste0(\"End date time: \", lubridate::now(), \"\\n\"))\n      cat(\"Elapsed time: \", elapsed_minutes, \" minutes\\n\\n\")\n      \n      # Add number of subjects to pwr\n      pwr &lt;- pwr %&gt;% \n        mutate(\n          nSubjects = breaks_subj[nSubj],\n          sesoi = breaks_sesoi[sesoi],\n          sigma = breaks_sigma[s]\n        )\n      \n      # Add results to the results table\n      res_nSubj &lt;- res_nSubj %&gt;%\n        rbind(pwr)\n    }\n    \n    # Add results to the results table\n    res_sesoi &lt;- res_sesoi %&gt;% \n      rbind(res_nSubj)\n  }\n  \n  # Add results to the results table\n  res_2wayInt &lt;- res_2wayInt %&gt;% \n    rbind(res_sesoi)\n  \n}\n\nres_2wayInt.summary &lt;- res_2wayInt %&gt;% \n  filter(term == \"polAff.dem-rep:ewe.TRUE-FALSE\") %&gt;% \n  group_by(sigma, sesoi, nSubjects) %&gt;% \n  summarise(\n    power = mean(p.value &lt; 0.05),\n    ci.lower = binom.confint(power*n_sims, n_sims, methods = \"exact\")$lower,\n    ci.upper = binom.confint(power*n_sims, n_sims, methods = \"exact\")$upper,\n    .groups = 'drop'\n  ) %&gt;% \n  mutate(\n    sigma_fact = factor(format(round(sigma, 4), nsmall = 4)),\n    sigma_level = match(sigma_fact, levels(sigma_fact)),\n    sesoi_fact = factor(format(round(sesoi, 4), nsmall = 4)),\n    sesoi_level = match(sesoi_fact, levels(sesoi_fact))\n  )\n\n# Save results in a list object\ntime &lt;- format(Sys.time(), \"%Y%m%d_%H%M\")\nfileName &lt;- paste0(\"res_2wayInt\", \"_\", time, \".RDS\")\nsaveRDS(\n  list(\n    res_2wayInt = res_2wayInt,\n    res_2wayInt.summary = res_2wayInt.summary\n  ),\n  file = file.path(\"../powerSimulationsOutput\", fileName)\n)\n\n\nWe retrieve pre-run results:\n\n\nShow the code\n# Load power simulation data\nresList_2wayInt &lt;- readRDS(file.path(\"../powerSimulationsOutput\", \"res_2wayInt_20240814_1052.RDS\"))\nresList_2wayInt.summary &lt;- resList_2wayInt$res_2wayInt.summary\n\n# Extract power values for some specific assumptions\nchosenN &lt;- 950\nchosenSigma &lt;- c(\"0.3300\", \"0.6600\")\nchosenSESOI &lt;- c(\"0.1429\", \"0.1714\")\npowerValues &lt;- resList_2wayInt.summary %&gt;% \n  filter(sigma_fact %in% chosenSigma) %&gt;% \n  filter(sesoi_fact %in% chosenSESOI) %&gt;% \n  filter(nSubjects %in% chosenN) %&gt;% \n  mutate(power_str = paste0(round(power*100, 2), \"%\")) %&gt;% \n  pull(power_str)\n\n# Extract number of simulations\nlabel_nSimulations &lt;- resList_2wayInt$res_2wayInt$sim %&gt;% n_distinct()\n\n# Repeat breaks_sesoi\nbreaks_sesoi &lt;- (0.4/3.5)*seq(1, 2, .25)\n\n\nFigure 11 displays the distribution of estimated fixed effects across all simulations. The figure shows that the estimated fixed effects are close to the true ones provided as input in the data simulation function, validating that simulations worked as expected.\n\n\nShow the code\n# Define some filters \nfilter_nSubjects &lt;- 1000\nfilter_sesoi &lt;- unique(resList_2wayInt$res_2wayInt$sesoi)[1]\nfilter_sigma &lt;- unique(resList_2wayInt$res_2wayInt$sigma)[1]\n\n# Prepare data for plot\nfixedEstimates &lt;- resList_2wayInt$res_2wayInt %&gt;% \n  mutate(\n    group = ifelse(is.na(group), \"\", group),\n    group_term = str_remove(str_c(group, term, sep = \"_\"), \"^_\")\n  ) %&gt;% \n  filter(effect == \"fixed\") %&gt;% \n  filter(nSubjects == filter_nSubjects) %&gt;% \n  filter(sesoi == filter_sesoi) %&gt;% \n  filter(sigma == filter_sigma)\nfixedEstimates_medians &lt;- fixedEstimates %&gt;% \n  group_by(group_term) %&gt;% \n  summarise(\n    median = median(estimate, na.rm = TRUE),\n    median_rounded = format(round(median, 4), nsmall = 4, scientific = FALSE),\n    .groups = 'drop'\n  )\n\n# Create plot\np.checkSims.2wayInt &lt;-fixedEstimates %&gt;% \n  ggplot(aes(x = estimate, y = group_term)) +\n  ggdist::stat_halfeye() +\n  ggrepel::geom_label_repel(\n    data = fixedEstimates_medians,\n    mapping = aes(x = median, y = group_term, label = median_rounded),\n    box.padding = .5\n  ) +\n  labs(\n    title = \"Distribution of Estimated Fixed Effects\",\n    subtitle = paste0(\n      \"SESOI = \", round(filter_sesoi, 4), \", \",\n      \"σ = \", round(filter_sigma, 4), \", \",\n      \"N = \", filter_nSubjects, \", \",\n      \"Number of Simulations = \", label_nSimulations\n    ),\n    x = \"Estimate\",\n    y = \"Term\"\n  ) +\n  theme_bw()\n\njpeg(\n  file = \"../images/pa_checkSims2wayInt.jpeg\",\n  width = 9.1, height = 6.5, units = \"in\", res = 600\n)\nprint(p.checkSims.2wayInt)\ninvisible(dev.off())\n\n\n\n\n\n\n\n\nFigure 11: Distribution of estimated fixed effects resulting from 1000 simulations for the model deltaDuration ~ polAff * ewe + (1 | subj) + (1 | trial). Shaded area represent densities, annotated points indicate medians, and thick and thin lines represent 66% and 95% quantiles.\n\n\n\nFigure 12 shows results of our effect-size sensitivity analyses. We plot statistical power (y-axis) for different effect sizes (x-axis), taking into account different assumptions for the error SD (color) and sample size (panel). Regarding the latter, we report results not only for the full sample size we aim for (N = 1000), but also for sample sizes taking into account different participant exclusion-rates due to exclusion criteria defined in the Registered Report.\n\n\n\n\n\n\nFigure 12: Power curves for the two-way interaction polAff × ewe. Points represent simulated power surrounded by a 95%-CI based on 1000 simulations with α = 0.05. Note that, in contrast to Figure 9, the x-axsis represents different effect sizes, starting from the defined SESOI, while the panels represent different sample sizes, taking into account participant exclusion-rates of 10% (N = 900), 5% (N = 950), and 0% (N = 1000). Note that estimates are displayed with a slight shift along the x-axis to reduce overlap. Since we only consider effect sizes equal to or greater than the SESOI to be of relevance, power curves were only examined for positive effect sizes, which is why only positive values are shown.\n\n\n\n\n\nShow the code\n# Get power values of interest\nchosenN &lt;- 950\nchosenSigma &lt;- c(\"0.3300\", \"0.6600\")\nchosenSESOI &lt;- c(\"0.1429\", \"0.1714\")\npowerValues &lt;- resList_2wayInt.summary %&gt;% \n  filter(sigma_fact %in% chosenSigma) %&gt;% \n  filter(sesoi_fact %in% chosenSESOI) %&gt;% \n  filter(nSubjects %in% chosenN)\n\n# Get lower CI for power values for more liberal and more conservative sigma assumptions\npowerValues_sigmaLib &lt;- powerValues %&gt;% \n  filter(sigma_fact == \"0.3300\")\npowerValues_sigmaCons &lt;- powerValues %&gt;% \n  filter(sigma_fact == \"0.6600\")\n\n# Interpolate the effect sizes at which we achieve 95% power\neff_sigmaLib &lt;- approx(powerValues_sigmaLib$ci.lower, powerValues_sigmaLib$sesoi, xout = 0.95)$y\neff_sigmaCons &lt;- approx(powerValues_sigmaCons$ci.lower, powerValues_sigmaCons$sesoi, xout = 0.95)$y\n# Round results for display in text\neff_sigmaLib_txt &lt;- format(round(eff_sigmaLib, 4), nsmall = 4)\neff_sigmaCons_txt &lt;- format(round(eff_sigmaCons, 4), nsmall = 4)\n\n\nTo assess the smallest effect size that can be detected with 95% statistical power, we inspect the lower bounds of the 95%-CI power estimates in Figure 12. Specifically, we focus on the power simulation results for N = 950, which takes into account a participant exclusion-rate of 5%. There, we interpolate between the two point estimates that lie just below and above the 95% power line, i.e., between the power estimates for effect sizes 0.1429 and 0.1714. Assuming an error SD of 0.3300, we achieve 95% statistical power to detect a two-way interaction effect of at least 0.1530. For a more conservative error SD of 0.6600, this smallest detectable effect size is only marginally higher (0.1619).\n\n4.5.3.1 Increased Sample Size\nWe additionally conduct an effect-size sensitivity analysis for increased sample sizes.\n\n\nShow the code\nFUN_sim_2wayInt_pwr &lt;- function(sim, ...){\n  out &lt;- FUN_sim_2wayInt(...)\n  modelResults &lt;- out$modelResults %&gt;% \n    mutate(sim = sim) %&gt;% \n    relocate(sim)\n  return(modelResults)\n}\n\n# How many simulations should be run?\nn_sims &lt;- 1000\n\n# What are the breaks for number of subjects we would like to calculate power for?\nbreaks_subj &lt;- c(1500, 1750, 2000)\n\n# What are the breaks for SESOI?\nbreaks_sesoi &lt;- (0.4/3.5)*seq(1, 2, .25)\n\n# What are the breaks for different error SDs?\nbreaks_sigma &lt;- c((.29+.04), 2*(.29+.04))\n\nres_2wayInt &lt;- tibble()\nfor (s in seq_along(breaks_sigma)) {\n  \n  res_sesoi &lt;- tibble()\n  for (sesoi in seq_along(breaks_sesoi)) {\n    \n    res_nSubj &lt;- tibble()\n    for (nSubj in seq_along(breaks_subj)) {\n      \n      # Give feedback regarding which model is simulated\n      cat(paste0(\n        \"Simulation:\\n\",\n        \"  sigma = \", round(breaks_sigma[s], 4), \"\\n\",\n        \"  sesoi = \", round(breaks_sesoi[sesoi], 4), \"\\n\",\n        \"  nSubject = \", breaks_subj[nSubj], \"\\n\"\n      ))\n      \n      # Start timer\n      cat(paste0(\"Start date time: \", lubridate::now(), \"\\n\"))\n      tic()\n      \n      # Loop over simulations\n      pwr &lt;- map_df(\n        1:n_sims, \n        FUN_sim_2wayInt_pwr,\n        n_subj = breaks_subj[nSubj],\n        beta_p_e_inx = breaks_sesoi[sesoi],\n        sigma = breaks_sigma[s]\n      )\n      \n      # Stop timer and calculate elapsed time\n      elapsed_time &lt;- toc(quiet = TRUE)\n      elapsed_seconds &lt;- elapsed_time$toc - elapsed_time$tic\n      elapsed_minutes &lt;- elapsed_seconds / 60\n      cat(paste0(\"End date time: \", lubridate::now(), \"\\n\"))\n      cat(\"Elapsed time: \", elapsed_minutes, \" minutes\\n\\n\")\n      \n      # Add number of subjects to pwr\n      pwr &lt;- pwr %&gt;% \n        mutate(\n          nSubjects = breaks_subj[nSubj],\n          sesoi = breaks_sesoi[sesoi],\n          sigma = breaks_sigma[s]\n        )\n      \n      # Add results to the results table\n      res_nSubj &lt;- res_nSubj %&gt;%\n        rbind(pwr)\n    }\n    \n    # Add results to the results table\n    res_sesoi &lt;- res_sesoi %&gt;% \n      rbind(res_nSubj)\n  }\n  \n  # Add results to the results table\n  res_2wayInt &lt;- res_2wayInt %&gt;% \n    rbind(res_sesoi)\n  \n}\n\nres_2wayInt.summary &lt;- res_2wayInt %&gt;% \n  filter(term == \"polAffX_p:eweX_e\") %&gt;% \n  group_by(sigma, sesoi, nSubjects) %&gt;% \n  summarise(\n    power = mean(p.value &lt; 0.05),\n    ci.lower = binom.confint(power*n_sims, n_sims, methods = \"exact\")$lower,\n    ci.upper = binom.confint(power*n_sims, n_sims, methods = \"exact\")$upper,\n    .groups = 'drop'\n  ) %&gt;% \n  mutate(\n    sigma_fact = factor(format(round(sigma, 4), nsmall = 4)),\n    sigma_level = match(sigma_fact, levels(sigma_fact)),\n    sesoi_fact = factor(format(round(sesoi, 4), nsmall = 4)),\n    sesoi_level = match(sesoi_fact, levels(sesoi_fact))\n  )\n\n# Save results in a list object\ntime &lt;- format(Sys.time(), \"%Y%m%d_%H%M\")\nfileName &lt;- paste0(\"res_2wayInt_increasedN\", \"_\", time, \".RDS\")\nsaveRDS(\n  list(\n    res_2wayInt = res_2wayInt,\n    res_2wayInt.summary = res_2wayInt.summary\n  ),\n  file = file.path(\"../powerSimulationsOutput\", fileName)\n)\n\n\n\n\nShow the code\n# Load power simulation data\nresList_2wayInt &lt;- readRDS(file.path(\"../powerSimulationsOutput\", \"res_2wayInt_increasedN_20250308_0703.RDS\"))\nresList_2wayInt.summary &lt;- resList_2wayInt$res_2wayInt.summary\n\n# Extract power values for some specific assumptions\nchosenN &lt;- 2000\nchosenSigma &lt;- c(\"0.3300\", \"0.6600\")\nchosenSESOI &lt;- c(\"0.1429\", \"0.1714\")\npowerValues &lt;- resList_2wayInt.summary %&gt;% \n  filter(sigma_fact %in% chosenSigma) %&gt;% \n  filter(sesoi_fact %in% chosenSESOI) %&gt;% \n  filter(nSubjects %in% chosenN) %&gt;% \n  mutate(power_str = paste0(round(power*100, 2), \"%\")) %&gt;% \n  pull(power_str)\n\n# Extract number of simulations\nlabel_nSimulations &lt;- resList_2wayInt$res_2wayInt$sim %&gt;% n_distinct()\n\n# Repeat breaks_sesoi\nbreaks_sesoi &lt;- (0.4/3.5)*seq(1, 2, .25)\n\n\nFigure 12 shows results of our effect-size sensitivity analyses. We plot statistical power (y-axis) for different effect sizes (x-axis), taking into account different assumptions for the error SD (color) and sample size (panel). Regarding the latter, we report results not only for the full sample size we aim for (N = 1000), but also for sample sizes taking into account different participant exclusion-rates due to exclusion criteria defined in the Registered Report.\n\n\n\n\n\n\nFigure 13: Power curves for the two-way interaction polAff × ewe. Points represent simulated power surrounded by a 95%-CI based on 1000 simulations with α = 0.05. Note that, in contrast to Figure 9, the x-axsis represents different effect sizes, starting from the defined SESOI, while the panels represent different sample sizes. Note that estimates are displayed with a slight shift along the x-axis to reduce overlap. Since we only consider effect sizes equal to or greater than the SESOI to be of relevance, power curves were only examined for positive effect sizes, which is why only positive values are shown."
  },
  {
    "objectID": "scripts/supplementaryInformation.html#three-way-interaction-effect",
    "href": "scripts/supplementaryInformation.html#three-way-interaction-effect",
    "title": "Supplementary Information",
    "section": "4.6 Three-Way Interaction Effect",
    "text": "4.6 Three-Way Interaction Effect\nAs argued in the Registered Report, we hypothesize:\n(H3): The two-way interaction effect of extreme weather exposure and political affiliation is greater for individuals who more strongly attribute extreme weather events to climate change. In other words, there is a positive three-way interaction effect of political affiliation, exposure to extreme weather events, and their attribution to climate change on ΔDuration.\n\n\nShow the code\n# Smallest Effect Size Of Interest (SESOI)\nSESOI &lt;- 0.4/3.5\n\n# Betas\nbeta_p &lt;- SESOI\nbeta_e &lt;- 0\nbeta_s &lt;- 0\nbeta_p_e_inx &lt;- SESOI\nbeta_p_s_inx &lt;- 0\nbeta_e_s_inx &lt;- 0\nbeta_p_e_s_inx &lt;- SESOI\n\n# Predicted \"true\" effects\npolAff_ewe_subjAttr_trueEffects &lt;- expand_grid(\n  polAff = factor(c(\"rep\", \"dem\"), levels = c(\"rep\", \"dem\")),\n  ewe = factor(c(FALSE, TRUE), levels = c(FALSE, TRUE)),\n  subjAttr = factor(c(\"-SD\", \"M\", \"+SD\"), levels = c(\"-SD\", \"M\", \"+SD\"))\n) %&gt;% \n  add_contrast(\"polAff\", contrast = \"anova\", colnames = \"X_p\") %&gt;% \n  add_contrast(\"ewe\", contrast = \"anova\", colnames = \"X_e\") %&gt;% \n  add_contrast(\"subjAttr\", contrast = \"anova\", colnames = c(\"X_s_1\", \"X_s_2\")) %&gt;% \n  mutate(\n    trueDeltaDuration =\n      0 +                                      # intercept\n      X_p * beta_p +                           # main effect polAff\n      X_e * beta_e +                           # main effect ewe\n      X_s_1 * beta_s +                         # main effect subjAttr, dummy variable for M vs. -SD\n      X_s_2 * (2 * beta_s) +                   # main effect subjAttr, dummy variable for +SD vs. -SD\n      X_p * X_e * beta_p_e_inx +               # 2-way interaction polAff * ewe\n      X_p * X_s_1 * beta_p_s_inx +             # 2-way interaction polAff * subjAttr, dummy variable for M vs. -SD\n      X_p * X_s_2 * (2 * beta_p_s_inx) +       # 2-way interaction polAff * subjAttr, dummy variable for +SD vs. -SD\n      X_e * X_s_1 * beta_e_s_inx +             # 2-way interaction ewe * subjAttr, dummy variable for M vs. -SD\n      X_e * X_s_2 * (2 * beta_e_s_inx) +       # 2-way interaction ewe * subjAttr, dummy variable for +SD vs. -SD\n      X_p * X_e * X_s_1 * beta_p_e_s_inx +     # 3-way interaction polAff*ewe*subjAttr, dummy variable for M vs -SD\n      X_p * X_e * X_s_2 * (2 * beta_p_e_s_inx) # 3-way interaction polAff*ewe*subjAttr, dummy variable for +SD vs. -SD\n  )\n\n\n\n4.6.1 SESOI for Three-way Interaction\nIn the sections above, we derived the SESOI used for the main effect sample-size determination analysis and for the two-way interaction effect-size sensitivity analysis for the binary variables polAff (dem vs. rep) and ewe (TRUE vs. FALSE). subjAttr, however, is a continuous variable that ranges from 1 to 5. Fortunately, in finding a theoretically sound SESOI for the three-way interaction, the same considerations apply as for the main effect and two-way interaction before. We just need to translate these considerations into the continuous metric of subjAttr.\nWe start by noticing that the complete fixed three-way interaction polAff × ewe × subjAttr is modeled as:\n\\[\n\\begin{split}\n\\Delta Duration = \\beta_{0} + \\\\\n\\beta_{1} \\cdot polAff + \\beta_{2} \\cdot ewe + \\beta_{3} \\cdot subjAttr + \\\\\n\\beta_{4} \\cdot (polAff \\times ewe) + \\beta_{5} \\cdot (polAff \\times subjAttr) + \\beta_{6} \\cdot (ewe \\times subjAttr) + \\\\\n\\beta_{7} \\cdot (polAff \\times ewe \\times subjAttr)\n\\end{split}\n\\]\nBy rearranging terms, one can show that the two-way interaction polAff × ewe is given by:\n\\[\nTwo{-}way\\ Interaction_{polAff \\times ewe} = \\beta_{4} + \\beta_{7} \\cdot subjAttr\n\\]\nNow, let’s calculate this two-way interaction for two individuals who differ in their level of subjective attribution of extreme weather events to climate change. First, an individual who has an average score on subjAttr will show the following two-way interaction effect, with \\(\\mu_{subjAttr}\\) being the sample average of the variable subjAttr:\n\\[\nEffect_{Avg} = \\beta_{4} + \\beta_{7} \\cdot \\mu_{subjAttr}\n\\]\nSecond, we define an individual with a low score on subjAttr as one that shows a subjective attribution of one SD bellow the average. This individual will show the following two-way interaction effect, with \\(\\sigma_{subjAttr}\\) being the SD of subjAttr:\n\\[\nEffect_{Low} = \\beta_{4} + \\beta_{7} \\cdot (\\mu_{subjAttr} - \\sigma_{subjAttr})\n\\]\nThe difference in the two-way interaction effect polAff × ewe between these two individuals is given by:\n\\[\n\\begin{split}\nEffect_{Avg} - Effect_{Low} = \\\\\n\\beta_{4} + \\beta_{7} \\cdot \\mu_{subjAttr} - (\\beta_{4} + \\beta_{7} \\cdot (\\mu_{subjAttr} - \\sigma_{subjAttr})) = \\\\\n\\beta_{7} \\cdot [\\mu_{subjAttr} - (\\mu_{subjAttr} - \\sigma_{subjAttr})] = \\\\\n\\beta_{7} \\cdot \\sigma_{subjAttr}\n\\end{split}\n\\]\nAs outlined above in Section Section 4.5.1, we assume that the SESOI for the two-way interaction polAff × ewe is 0.1143 for an average individual (with respect to subjAttr). If the same two-way interaction polAff × ewe shrinks to zero for an individual low in subjAttr, we would consider this interaction effect difference as theoretically relevant (see Figure 14). These assumptions translate to:\n\\[\nEffect_{Avg} - Effect_{Low} = 0.1143 = \\beta_{7} \\cdot \\sigma_{subjAttr}\n\\]\nDivision by \\(\\sigma_{subjAttr}\\) gives us the SESOI for the three-way interaction in the suitable metric of subjAttr:\n\\[\nSESOI_{polAff \\times ewe \\times subjAttr} = \\frac{0.1143}{\\sigma_{subjAttr}}\n\\]\nWe will assess subjective attribution of extreme weather events to climate change using the same questions, response options, and aggregation as Ogunbode et al. (2019). These authors reported \\(\\mu_{subjAttr}\\) = 3.67 and \\(\\sigma_{subjAttr}\\) = 0.85, resulting in:\n\\[\nSESOI_{polAff \\times ewe \\times subjAttr} = \\frac{0.1143}{0.85} = 0.1345\n\\]\n\n\n\n\n\n\nFigure 14: Assumed ΔDuration values for individuals scoring low (-SD) and average (M) on subjAttr. While individuals scoring average on subjAttr show a two-way interaction effect of polAff × ewe of 0.1143, this effect shrinks to zero for individuals scoring low on subjAttr. These individuals only show the predicted main effect of polAff (whis is 0.1143).\n\n\n\n\n\n4.6.2 Data Simulation Function\nWe finally define a function that simulates data for the three-way interaction effect of political affiliation with extreme weather exposure and attribution of extreme weather events to climate change on ΔDuration: FUN_sim_3wayInt. The function will simulate data according to the following model, expressed in lme4-lingo:\ndeltaDuration ~ polAff * ewe * subjAttr + (1|subj) + (1|trial)\nThe function FUN_sim_3wayInt takes, among others, the following important arguments (in addition to the arguments discussed for FUN_sim_2wayInt):\n\ns_mean: Sample mean of subjective attribution. Based on results reported by Ogunbode et al. (2019), we set this value to 3.67.\ns_sd: Sample SD of subjective attribution. Based on results reported by Ogunbode et al. (2019), we set this value to 0.85.\nbeta_s: Fixed main effect of subjective attribution. As we are interested in the moderating role of subjective attribution of extreme weather events to climate change, we set this main effect to zero.\nbeta_p_s_inx Fixed two-way interaction effect of political affiliation and subjective attribution. In order to accurately model a three-way interaction, one needs to include all two-way interactions in statistical models. Therefore, we include this two-way interaction, but we assume it to be zero.\nbeta_e_s_inx Fixed two-way interaction effect of extreme weather exposure and subjective attribution. As before, we include this interaction for accurately modelling the three-way interaction of interest, but we assume this two-way interaction to be zero.\nbeta_p_e_s_inx Fixed three-way interaction effect of political affiliation, extreme weather exposure, and subjective attribution. We set this initial value to the SESOI derived above, i.e. 0.1345. We investigate how changing this effect size impacts statistical power, as we are conducting effect-size sensitivity analyses for interaction effects.\n\nThe function is defined below:\n\n\nShow the code\n# define data simulation function\nFUN_sim_3wayInt &lt;- function(\n  n_subj         =                1000, # number of subjects\n  n_subj_prop_p  =           c(.5, .5), # proportion of republican and democrat subjects\n  n_subj_prop_e  =           c(.5, .5), # proportion of subjects without and with extreme weather exposure\n  n_subj_prop_s  =           c(.5, .5), # proportion of subjects with low and high subjective attribution of EWE to CC\n  n_trial        =                  25, # number of trials\n  s_mean         =                3.67, # mean of subjAttr, see Ogunbode et al. (2019)\n  s_sd           =                0.85, # sd of subjAttr, see Ogunbode et al. (2019)\n  beta_0         =                   0, # intercept (grand mean) for deltaDuration\n  beta_p         =             0.4/3.5, # main effect of political affiliation (polAff)\n  beta_e         =                   0, # main effect of extreme weather exposure (ewe)\n  beta_s         =                   0, # main effect of subjective attribution of ewe to climate change (subjAttr)\n  beta_p_e_inx   =             0.4/3.5, # two-way interaction effect of polAff and ewe\n  beta_p_s_inx   =                   0, # two-way interaction effect of polAff and subjAttr\n  beta_e_s_inx   =                   0, # two-way interaction effect of ewe and subjAttr\n  beta_p_e_s_inx =      (0.4/3.5)/0.85, # three-way interaction effect of polAff, ewe, and subjAttr\n  subj_0         =                 .29, # by-subject random intercept sd for dt carbon\n  trial_0        =                 .04, # by-trial random intercept sd\n  sigma          =         1*(.29+.04), # residual (error) sd\n  \n  truncNums      =                TRUE, # should impossible numbers be truncuated?\n  setSeed        =                NULL  # seed number to achieve reproducible results. Set to NULL for simulations!\n) {\n  \n  # set seed to achieve reproducible results for demonstration purposes\n  set.seed(setSeed)\n  \n  # simulate data for dwell time on carbon information\n  dataSim &lt;- \n    # add random factor subject\n    add_random(subj = n_subj) %&gt;% \n    # add random factor trial\n    add_random(trial = n_trial) %&gt;% \n    # add between-subject factor political affiliation (with anova contrast)\n    add_between(\"subj\", polAff = c(\"rep\", \"dem\"), .prob = n_subj_prop_p*n_subj, .shuffle = TRUE) %&gt;% \n    add_contrast(\"polAff\", colnames = \"X_p\", contrast = \"anova\") %&gt;% \n    # add between-subject factor extreme weather exposure (with anova contrast)\n    add_between(\"subj\", ewe = c(FALSE, TRUE), .prob = n_subj_prop_e*n_subj, .shuffle = TRUE) %&gt;% \n    add_contrast(\"ewe\", colnames = \"X_e\", contrast = \"anova\") %&gt;% \n    # add between-subject variable subjective attribution of EWE to climate change\n    mutate(\n      subjAttr = rep(rnorm(n = n_subj, mean = s_mean, sd = s_sd), each = n_trial),\n      subjAttr_c = scale(subjAttr, center = TRUE, scale = FALSE)[,1]\n    ) %&gt;% \n    # add by-subject random intercept\n    add_ranef(\"subj\", S_0 = subj_0) %&gt;% \n    # add by-trial random intercept\n    add_ranef(\"trial\", T_0 = trial_0) %&gt;% \n    # add error term\n    add_ranef(e_st = sigma) %&gt;% \n    # add response values\n    mutate(\n      # add together fixed and random effects for each effect\n      B_0 = beta_0 + S_0 + T_0,\n      B_p = beta_p,\n      B_e = beta_e,\n      B_s = beta_s,\n      B_p_e_inx = beta_p_e_inx,\n      B_p_s_inx = beta_p_s_inx,\n      B_e_s_inx = beta_e_s_inx,\n      B_p_e_s_inx = beta_p_e_s_inx,\n      # calculate dv by adding each effect term multiplied by the relevant\n      # effect-coded factors and adding the error term\n      deltaDuration = \n        B_0 + e_st +\n        (X_p * B_p) +\n        (X_e * B_e) +\n        (subjAttr_c * B_s) +\n        (X_p * X_e * B_p_e_inx) +\n        (X_p * subjAttr_c * B_p_s_inx) +\n        (X_e * subjAttr_c * B_e_s_inx) +\n        (X_p * X_e * subjAttr_c * B_p_e_s_inx)\n    )\n  \n  # unset seed\n  set.seed(NULL)\n  \n  # truncuate impossible deltaDurations\n  if(truncNums) {\n    dataSim &lt;- dataSim %&gt;% \n      mutate(deltaDuration = if_else(deltaDuration &lt; -1, -1,\n        if_else(deltaDuration &gt; 1, 1, deltaDuration)))\n  }\n  \n  # run a linear mixed effects model and check summary\n  mod &lt;- lmer(\n    deltaDuration ~ polAff*ewe*subjAttr_c + (1 | subj) + (1 | trial),\n    data = dataSim\n  )\n  mod.sum &lt;- summary(mod)\n\n  # get results in tidy format\n  mod.broom &lt;- broom.mixed::tidy(mod)\n\n  return(list(\n    dataSim = dataSim,\n    modelLmer = mod,\n    modelResults = mod.broom\n  ))\n  \n}\n\n\nWe call the function once and extract the results of this single simulation:\n\n\nShow the code\n# Note to myself: Consider setting beta_p = 0.4/3.5, beta_p_e_inx = 0.4/3.5,\n# and beta_p_e_s_inx to 2 * 0.4/3.5/(2*.85).\n# This way, the interaction effect polAff:ewe is 0.4/3.5 for individuals\n# with an average subjAttr (subjAttr_c = 0). For individuals with\n# subjAttr = mean - SD, polAff:ewe is 0. For individuals with subjAttr = mean + SD,\n# polAff:ewe is  2 * 0.4/3.5.\n\nout &lt;- FUN_sim_3wayInt(\n  n_subj         =                1000, # number of subjects\n  n_subj_prop_p  =           c(.5, .5), # proportion of republican and democrat subjects\n  n_subj_prop_e  =           c(.5, .5), # proportion of subjects without and with extreme weather exposure\n  n_subj_prop_s  =           c(.5, .5), # proportion of subjects with low and high subjective attribution of EWE to CC\n  n_trial        =                  25, # number of trials\n  s_mean         =                3.67, # mean of subjAttr, see Ogunbode et al. (2019)\n  s_sd           =                0.85, # sd of subjAttr, see Ogunbode et al. (2019)\n  beta_0         =                   0, # intercept (grand mean) for deltaDuration\n  beta_p         =             0.4/3.5, # main effect of political affiliation (polAff)\n  beta_e         =                   0, # main effect of extreme weather exposure (ewe)\n  beta_s         =                   0, # main effect of subjective attribution of ewe to climate change (subjAttr)\n  beta_p_e_inx   =             0.4/3.5, # two-way interaction effect of polAff and ewe\n  beta_p_s_inx   =                   0, # two-way interaction effect of polAff and subjAttr\n  beta_e_s_inx   =                   0, # two-way interaction effect of ewe and subjAttr\n  beta_p_e_s_inx =      (0.4/3.5)/0.85, # three-way interaction effect of polAff, ewe, and subjAttr\n  subj_0         =                 .29, # by-subject random intercept sd for dt carbon\n  trial_0        =                 .04, # by-trial random intercept sd\n  sigma          =         1*(.29+.04), # residual (error) sd\n  \n  truncNums      =                TRUE, # should impossible numbers be truncuated?\n  setSeed        =                 123  # seed number to achieve reproducible results. Set to NULL for simulations!\n)\n\n# Get results table\nresultsTable &lt;- out$modelResults %&gt;% \n  select(-c(std.error, statistic, df)) %&gt;% \n  mutate(across(where(is_double), ~ round(.x, 4))) %&gt;% \n  knitr::kable()\nformulaUsedForFit &lt;- paste(as.character(formula(out$modelLmer))[c(2,1,3)], collapse = \" \")\n\n# Create predictions plot\n\n# refit model to dispaly subjAttr levels in original metric (not mean centered)\nm &lt;- lmer(\n  deltaDuration ~ polAff*ewe*subjAttr + (1 | subj) + (1 | trial),\n  data = out$dataSim\n)\n# define spotlights for spotlight analysis\nspotlights &lt;- c(3.67 - 0.85, 3.67, 3.67 + 0.85)\n\n# create plot showing predictions\np.demo.3wayInt.pred &lt;- predict_response(m, terms = c(\"ewe\", \"polAff\", \"subjAttr[spotlights]\"))\np.demo.3wayInt &lt;- p.demo.3wayInt.pred %&gt;% \n  plot(colors = c(\"red\", \"dodgerblue\")) +\n  coord_cartesian(ylim = c(-.25, .25)) +\n  theme_bw()\n\njpeg(\n  file = \"../images/pa_demo3wayInt.jpeg\",\n  width = 9.1, height = 6.3, units = \"in\", res = 600\n)\nprint(p.demo.3wayInt)\ninvisible(dev.off())\n\n\nFigure 15 visualizes predictions based on this single simulation and Table 6 summarizes the statistical results of fitting the actual model used in data generation to the simulated data.\n\n\n\n\n\n\nFigure 15: Visual representation of results of one simulation created using FUN_sim_3wayInt. Points indicate the predicted means surrounded by 95% Confidence Intervals. Panels indicate predictions for different values of subjAttr (Mean - SD, Mean, and Mean + SD).\n\n\n\n\n\n\nTable 6: Statistical results of one simulation created using FUN_sim_3wayInt. Data was fit using deltaDuration ~ polAff * ewe * subjAttr_c + (1 | subj) + (1 | trial). Note that subjAttr is mean centered to ease interpretation of lower-level interactions and main effects.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\neffect\ngroup\nterm\nestimate\np.value\n\n\n\n\nfixed\nNA\n(Intercept)\n-0.0022\n0.8478\n\n\nfixed\nNA\npolAff.dem-rep\n0.1149\n0.0000\n\n\nfixed\nNA\newe.TRUE-FALSE\n-0.0023\n0.9031\n\n\nfixed\nNA\nsubjAttr_c\n0.0091\n0.4141\n\n\nfixed\nNA\npolAff.dem-rep:ewe.TRUE-FALSE\n0.1426\n0.0001\n\n\nfixed\nNA\npolAff.dem-rep:subjAttr_c\n0.0187\n0.4025\n\n\nfixed\nNA\newe.TRUE-FALSE:subjAttr_c\n0.0142\n0.5239\n\n\nfixed\nNA\npolAff.dem-rep:ewe.TRUE-FALSE:subjAttr_c\n0.1111\n0.0130\n\n\nran_pars\nsubj\nsd__(Intercept)\n0.2849\nNA\n\n\nran_pars\ntrial\nsd__(Intercept)\n0.0323\nNA\n\n\nran_pars\nResidual\nsd__Observation\n0.3240\nNA\n\n\n\n\n\n\n\n\n\n\n4.6.3 Power Simulation\nIn the following code, the simulations are calculated. We do not recommend executing this code junk as it takes several hours to run.\n\n\nShow the code\nFUN_sim_3wayInt_pwr &lt;- function(sim, ...){\n  out &lt;- FUN_sim_3wayInt(...)\n  modelResults &lt;- out$modelResults %&gt;% \n    mutate(sim = sim) %&gt;% \n    relocate(sim)\n  return(modelResults)\n}\n\n# How many simulations should be run?\nn_sims &lt;- 1000\n\n# What are the breaks for number of subjects we would like to calculate power for?\nbreaks_subj &lt;- c(900, 950, 1000)\n\n# What are the breaks for SESOI?\nbreaks_sesoi &lt;- (0.4/3.5)/0.85 * seq(1, 2, .25)\n\n# What are the breaks for different error SDs?\nbreaks_sigma &lt;- c((.29+.04), 2*(.29+.04))\n\nres_3wayInt &lt;- tibble()\nfor (s in seq_along(breaks_sigma)) {\n  \n  res_sesoi &lt;- tibble()\n  for (sesoi in seq_along(breaks_sesoi)) {\n    \n    res_nSubj &lt;- tibble()\n    for (nSubj in seq_along(breaks_subj)) {\n      \n      # Give feedback regarding which model is simulated\n      cat(paste0(\n        \"Simulation:\\n\",\n        \"  sigma = \", round(breaks_sigma[s], 4), \"\\n\",\n        \"  sesoi = \", round(breaks_sesoi[sesoi], 4), \"\\n\",\n        \"  nSubject = \", breaks_subj[nSubj], \"\\n\"\n      ))\n      \n      # Start timer\n      cat(paste0(\"Start date time: \", lubridate::now(), \"\\n\"))\n      tic()\n      \n      # Loop over simulations\n      pwr &lt;- map_df(\n        1:n_sims, \n        FUN_sim_3wayInt_pwr,\n        n_subj = breaks_subj[nSubj],\n        beta_p_e_s_inx = breaks_sesoi[sesoi],\n        sigma = breaks_sigma[s]\n      )\n      \n      # Stop timer and calculate elapsed time\n      elapsed_time &lt;- toc(quiet = TRUE)\n      elapsed_seconds &lt;- elapsed_time$toc - elapsed_time$tic\n      elapsed_minutes &lt;- elapsed_seconds / 60\n      cat(paste0(\"End date time: \", lubridate::now(), \"\\n\"))\n      cat(\"Elapsed time: \", elapsed_minutes, \" minutes\\n\\n\")\n      \n      # Add number of subjects to pwr\n      pwr &lt;- pwr %&gt;% \n        mutate(\n          nSubjects = breaks_subj[nSubj],\n          sesoi = breaks_sesoi[sesoi],\n          sigma = breaks_sigma[s]\n        )\n      \n      # Add results to the results table\n      res_nSubj &lt;- res_nSubj %&gt;%\n        rbind(pwr)\n    }\n    \n    # Add results to the results table\n    res_sesoi &lt;- res_sesoi %&gt;% \n      rbind(res_nSubj)\n  }\n  \n  # Add results to the results table\n  res_3wayInt &lt;- res_3wayInt %&gt;% \n    rbind(res_sesoi)\n  \n}\n\nres_3wayInt.summary &lt;- res_3wayInt %&gt;% \n  filter(term == \"polAff.dem-rep:ewe.TRUE-FALSE:subjAttr_c\") %&gt;% \n  group_by(sigma, sesoi, nSubjects) %&gt;% \n  summarise(\n    power = mean(p.value &lt; 0.05),\n    ci.lower = binom.confint(power*n_sims, n_sims, methods = \"exact\")$lower,\n    ci.upper = binom.confint(power*n_sims, n_sims, methods = \"exact\")$upper,\n    .groups = 'drop'\n  ) %&gt;% \n  mutate(\n    sigma_fact = factor(format(round(sigma, 4), nsmall = 4)),\n    sigma_level = match(sigma_fact, levels(sigma_fact)),\n    sesoi_fact = factor(format(round(sesoi, 4), nsmall = 4)),\n    sesoi_level = match(sesoi_fact, levels(sesoi_fact))\n  )\n\n# Save results in a list object\ntime &lt;- format(Sys.time(), \"%Y%m%d_%H%M\")\nfileName &lt;- paste0(\"res_3wayInt\", \"_\", time, \".RDS\")\nsaveRDS(\n  list(\n    res_3wayInt = res_3wayInt,\n    res_3wayInt.summary = res_3wayInt.summary\n  ),\n  file = file.path(\"../powerSimulationsOutput\", fileName)\n)\n\n\nWe retrieve pre-run results:\n\n\nShow the code\n# Load power simulation data\nresList_3wayInt &lt;- readRDS(file.path(\"../powerSimulationsOutput\", \"res_3wayInt_20240814_1612.RDS\")) \nresList_3wayInt.summary &lt;- resList_3wayInt$res_3wayInt.summary\n\n# Extract power values for some specific effect sizes at N = 1000\npowerValues &lt;- resList_3wayInt.summary %&gt;% \n  filter(sigma_fact == \"0.3300\") %&gt;% \n  filter(sesoi_fact == \"0.1345\") %&gt;% \n  filter(nSubjects == 950) %&gt;% \n  mutate(power_str = paste0(round(power*100, 2), \"%\")) %&gt;% \n  pull(power_str)\n\n# Extract number of simulations\nlabel_nSimulations &lt;- resList_3wayInt$res_3wayInt$sim %&gt;% n_distinct()\n\n# Repeat breaks_sesoi\nbreaks_sesoi &lt;- (0.4/3.5)/(0.85) * seq(1, 2, .25)\n\n\nFigure 16 displays the distribution of estimated fixed effects across all simulations. The figure shows that the estimated fixed effects are close to the true ones provided as input in the data simulation function, validating that simulations worked as expected.\n\n\n\n\n\n\nFigure 16: Distribution of estimated fixed effects resulting from 1000 simulations for the model deltaDuration ~ polAff * ewe * subjAttr_c + (1 | subj) + (1 | trial). Shaded area represent densities, annotated points indicate medians, and thick and thin lines represent 66% and 95% quantiles.\n\n\n\nFigure 17 shows results of our effect-size sensitivity analyses. We plot statistical power (y-axis) for different effect sizes (x-axis), taking into account different assumptions for the error SD (color) and sample size (panel). Regarding the latter, we report results not only for the full sample size we aim for (N = 1000), but also for sample sizes taking into account different participant exclusion-rates due to exclusion criteria defined in the Registered Report.\n\n\n\n\n\n\nFigure 17: Power curves for the three-way interaction polAff × ewe × subjAttr. Points represent simulated power surrounded by a 95%-CI based on 1000 simulations with α = 0.05. Note that, in contrast to Figure 9, the x-axsis represents different effect sizes, starting from the defined SESOI, while the panels represent different sample sizes, taking into account participant exclusion-rates of 10% (N = 900), 5% (N = 950), and 0% (N = 1000). Note that estimates are displayed with a slight shift along the x-axis to reduce overlap. Since we only consider effect sizes equal to or greater than the SESOI to be of relevance, power curves were only examined for positive effect sizes, which is why only positive values are shown.\n\n\n\n\n\nShow the code\n# Get power values of interest\nchosenN &lt;- 950\nchosenSigma &lt;- c(\"0.3300\", \"0.6600\")\nchosenSESOI &lt;- c(\"0.1681\", \"0.2017\")\npowerValues &lt;- resList_3wayInt.summary %&gt;% \n  filter(sigma_fact %in% chosenSigma) %&gt;% \n  filter(sesoi_fact %in% chosenSESOI) %&gt;% \n  filter(nSubjects %in% chosenN)\n\n# Get lower CI for power values for more liberal and more conservative sigma assumptions\npowerValues_sigmaLib &lt;- powerValues %&gt;% \n  filter(sigma_fact == \"0.3300\")\npowerValues_sigmaCons &lt;- powerValues %&gt;% \n  filter(sigma_fact == \"0.6600\")\n\n# Interpolate the effect sizes at which we achieve 95% power\neff_sigmaLib &lt;- approx(powerValues_sigmaLib$ci.lower, powerValues_sigmaLib$sesoi, xout = 0.95)$y\neff_sigmaCons &lt;- approx(powerValues_sigmaCons$ci.lower, powerValues_sigmaCons$sesoi, xout = 0.95)$y\n# Round results for display in text\neff_sigmaLib_txt_3way &lt;- format(round(eff_sigmaLib, 4), nsmall = 4)\neff_sigmaCons_txt_3way &lt;- format(round(eff_sigmaCons, 4), nsmall = 4)\n\n\nTo assess the smallest effect size that can be detected with 95% statistical power, we inspect the lower bounds of the 95%-CI power estimates in Figure 17. Specifically, we focus on the power simulation results for N = 950, which takes into account a participant exclusion rate of 5%. There, we interpolate between the two point estimates that lie just below and above the 95% power line, i.e., between the power estimates for effect sizes 0.1681 and 0.2017. Assuming an error SD of 0.3300, we achieve 95% statistical power to detect a three-way interaction effect of at least 0.1728. For a more conservative error SD of 0.6600, this smallest detectable effect size is only marginally higher (0.1890).\n\n4.6.3.1 Increased Sample Size\nWe additionally conduct an effect-size sensitivity analysis for increased sample sizes.\n\n\nShow the code\nFUN_sim_3wayInt_pwr &lt;- function(sim, ...){\n  out &lt;- FUN_sim_3wayInt(...)\n  modelResults &lt;- out$modelResults %&gt;% \n    mutate(sim = sim) %&gt;% \n    relocate(sim)\n  return(modelResults)\n}\n\n# How many simulations should be run?\nn_sims &lt;- 1000\n\n# What are the breaks for number of subjects we would like to calculate power for?\nbreaks_subj &lt;- c(1500, 1750, 2000)\n\n# What are the breaks for SESOI?\nbreaks_sesoi &lt;- (0.4/3.5)/0.85 * seq(1, 2, .25)\n\n# What are the breaks for different error SDs?\nbreaks_sigma &lt;- c((.29+.04), 2*(.29+.04))\n\nres_3wayInt &lt;- tibble()\nfor (s in seq_along(breaks_sigma)) {\n  \n  res_sesoi &lt;- tibble()\n  for (sesoi in seq_along(breaks_sesoi)) {\n    \n    res_nSubj &lt;- tibble()\n    for (nSubj in seq_along(breaks_subj)) {\n      \n      # Give feedback regarding which model is simulated\n      cat(paste0(\n        \"Simulation:\\n\",\n        \"  sigma = \", round(breaks_sigma[s], 4), \"\\n\",\n        \"  sesoi = \", round(breaks_sesoi[sesoi], 4), \"\\n\",\n        \"  nSubject = \", breaks_subj[nSubj], \"\\n\"\n      ))\n      \n      # Start timer\n      cat(paste0(\"Start date time: \", lubridate::now(), \"\\n\"))\n      tic()\n      \n      # Loop over simulations\n      pwr &lt;- map_df(\n        1:n_sims, \n        FUN_sim_3wayInt_pwr,\n        n_subj = breaks_subj[nSubj],\n        beta_p_e_s_inx = breaks_sesoi[sesoi],\n        sigma = breaks_sigma[s]\n      )\n      \n      # Stop timer and calculate elapsed time\n      elapsed_time &lt;- toc(quiet = TRUE)\n      elapsed_seconds &lt;- elapsed_time$toc - elapsed_time$tic\n      elapsed_minutes &lt;- elapsed_seconds / 60\n      cat(paste0(\"End date time: \", lubridate::now(), \"\\n\"))\n      cat(\"Elapsed time: \", elapsed_minutes, \" minutes\\n\\n\")\n      \n      # Add number of subjects to pwr\n      pwr &lt;- pwr %&gt;% \n        mutate(\n          nSubjects = breaks_subj[nSubj],\n          sesoi = breaks_sesoi[sesoi],\n          sigma = breaks_sigma[s]\n        )\n      \n      # Add results to the results table\n      res_nSubj &lt;- res_nSubj %&gt;%\n        rbind(pwr)\n    }\n    \n    # Add results to the results table\n    res_sesoi &lt;- res_sesoi %&gt;% \n      rbind(res_nSubj)\n  }\n  \n  # Add results to the results table\n  res_3wayInt &lt;- res_3wayInt %&gt;% \n    rbind(res_sesoi)\n  \n}\n\nres_3wayInt.summary &lt;- res_3wayInt %&gt;% \n  filter(term == \"polAffX_p:eweX_e:subjAttr_c\") %&gt;% \n  group_by(sigma, sesoi, nSubjects) %&gt;% \n  summarise(\n    power = mean(p.value &lt; 0.05),\n    ci.lower = binom.confint(power*n_sims, n_sims, methods = \"exact\")$lower,\n    ci.upper = binom.confint(power*n_sims, n_sims, methods = \"exact\")$upper,\n    .groups = 'drop'\n  ) %&gt;% \n  mutate(\n    sigma_fact = factor(format(round(sigma, 4), nsmall = 4)),\n    sigma_level = match(sigma_fact, levels(sigma_fact)),\n    sesoi_fact = factor(format(round(sesoi, 4), nsmall = 4)),\n    sesoi_level = match(sesoi_fact, levels(sesoi_fact))\n  )\n\n# Save results in a list object\ntime &lt;- format(Sys.time(), \"%Y%m%d_%H%M\")\nfileName &lt;- paste0(\"res_3wayInt_increasedN\", \"_\", time, \".RDS\")\nsaveRDS(\n  list(\n    res_3wayInt = res_3wayInt,\n    res_3wayInt.summary = res_3wayInt.summary\n  ),\n  file = file.path(\"../powerSimulationsOutput\", fileName)\n)\n\n\n\n\nShow the code\n# Load power simulation data\nresList_3wayInt &lt;- readRDS(file.path(\"../powerSimulationsOutput\", \"res_3wayInt_increasedN_20250308_1649.RDS\"))\nresList_3wayInt.summary &lt;- resList_3wayInt$res_3wayInt.summary\n\n# Extract power values for some specific effect sizes at N = 1000\npowerValues &lt;- resList_3wayInt.summary %&gt;% \n  filter(sigma_fact == \"0.3300\") %&gt;% \n  filter(sesoi_fact == \"0.1345\") %&gt;% \n  filter(nSubjects == 950) %&gt;% \n  mutate(power_str = paste0(round(power*100, 2), \"%\")) %&gt;% \n  pull(power_str)\n\n# Extract number of simulations\nlabel_nSimulations &lt;- resList_3wayInt$res_3wayInt$sim %&gt;% n_distinct()\n\n# Repeat breaks_sesoi\nbreaks_sesoi &lt;- (0.4/3.5)/(0.85) * seq(1, 2, .25)\n\n\n\n\n\n\n\n\nFigure 18: Power curves for the three-way interaction polAff × ewe × subjAttr. Points represent simulated power surrounded by a 95%-CI based on 1000 simulations with α = 0.05. Note that, in contrast to Figure 9, the x-axsis represents different effect sizes, starting from the defined SESOI, while the panels represent different sample sizes. Note that estimates are displayed with a slight shift along the x-axis to reduce overlap. Since we only consider effect sizes equal to or greater than the SESOI to be of relevance, power curves were only examined for positive effect sizes, which is why only positive values are shown."
  },
  {
    "objectID": "scripts/supplementaryInformation.html#conclusion-1",
    "href": "scripts/supplementaryInformation.html#conclusion-1",
    "title": "Supplementary Information",
    "section": "4.7 Conclusion",
    "text": "4.7 Conclusion\nUsing power simulations with mixed-effects models for sample-size determination and effect-size sensitivity analyses, we show that with a final sample size of N = 950:\n\nWe will achieve \\(\\ge\\) 95% statistical power to detect a main effect of political affiliation.\nWe will be able to detect a two-way interaction effect of political affiliation with extreme weather exposure of at least 0.1619 with \\(\\ge\\) 95% statistical power.\nWe will be able to detect a three-way interaction effect of political affiliation with extreme weather exposure and subjective attribution of extreme weather events to climate change of at least 0.1890 with \\(\\ge\\) 95% statistical power.\n\nBy increasing the planned sample size to N = 2’000, we will be able to detect all of the defined smallest effect sizes of interest of the hypothesized main effect and the two- and three-way interaction effects with a statistical power of at least 95%.\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.0 (2024-04-24)\n os       macOS Sonoma 14.4.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/Zurich\n date     2024-09-19\n pandoc   3.1.11 @ /usr/local/bin/ (via rmarkdown)\n quarto   1.5.45 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version  date (UTC) lib source\n binom       * 1.1-1.1  2022-05-02 [1] CRAN (R 4.4.0)\n dplyr       * 1.1.4    2023-11-17 [1] CRAN (R 4.4.0)\n faux        * 1.2.1    2023-04-20 [1] CRAN (R 4.4.0)\n forcats     * 1.0.0    2023-01-29 [1] CRAN (R 4.4.0)\n fs          * 1.6.4    2024-04-25 [1] CRAN (R 4.4.0)\n ggdist      * 3.3.2    2024-03-05 [1] CRAN (R 4.4.0)\n ggeffects   * 1.7.0    2024-06-20 [1] CRAN (R 4.4.0)\n ggplot2     * 3.5.1    2024-04-23 [1] CRAN (R 4.4.0)\n ggpubr      * 0.6.0    2023-02-10 [1] CRAN (R 4.4.0)\n ggrepel     * 0.9.5    2024-01-10 [1] CRAN (R 4.4.0)\n ggthemes    * 5.1.0    2024-02-10 [1] CRAN (R 4.4.0)\n lme4        * 1.1-35.5 2024-07-03 [1] CRAN (R 4.4.0)\n lmerTest    * 3.1-3    2020-10-23 [1] CRAN (R 4.4.0)\n lubridate   * 1.9.3    2023-09-27 [1] CRAN (R 4.4.0)\n Matrix      * 1.7-0    2024-03-22 [1] CRAN (R 4.4.0)\n purrr       * 1.0.2    2023-08-10 [1] CRAN (R 4.4.0)\n readr       * 2.1.5    2024-01-10 [1] CRAN (R 4.4.0)\n sessioninfo * 1.2.2    2021-12-06 [1] CRAN (R 4.4.0)\n stringr     * 1.5.1    2023-11-14 [1] CRAN (R 4.4.0)\n tibble      * 3.2.1    2023-03-20 [1] CRAN (R 4.4.0)\n tictoc      * 1.2.1    2024-03-18 [1] CRAN (R 4.4.0)\n tidyr       * 1.3.1    2024-01-24 [1] CRAN (R 4.4.0)\n tidyverse   * 2.0.0    2023-02-22 [1] CRAN (R 4.4.0)\n usmap       * 0.7.1    2024-03-21 [1] CRAN (R 4.4.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "scripts/accessStormEventsData.html",
    "href": "scripts/accessStormEventsData.html",
    "title": "Extreme Weather Events Data: Access & Preprocessing",
    "section": "",
    "text": "Show the code\n# install package librarian if needed\nif (!(\"librarian\" %in% rownames(installed.packages()))) {\n  install.packages(\"librarian\")\n}\n\n# load required packages\nlibrarian::shelf(\n  ropensci/rnoaa,\n  openxlsx,\n  tidyverse,\n  DT,\n  usmap,\n  sessioninfo\n)"
  },
  {
    "objectID": "scripts/accessStormEventsData.html#download-storm-events-data",
    "href": "scripts/accessStormEventsData.html#download-storm-events-data",
    "title": "Extreme Weather Events Data: Access & Preprocessing",
    "section": "1.1 Download Storm Events Data",
    "text": "1.1 Download Storm Events Data\nWe will use the Storm Events Database operated by the US National Oceanic and Atmospheric Administration. Full documentation regarding this database can be found here. A detailed variable codebook is found here.\nThere is a handy R package that allows to download different NOAA data products: rnoaa. We use the functions se_files() and se_data.\nWe first want to get a feeling for all available files:\n\n\nShow the code\n# read in meta data of available files\nse_availableFiles &lt;- se_files()\n\n# get an overview of metadata\ncat(\"Structure of meta data:\\n\")\n\n\nStructure of meta data:\n\n\nShow the code\nstr(se_availableFiles)\n\n\ntibble [221 × 4] (S3: tbl_df/tbl/data.frame)\n $ type   : chr [1:221] \"details\" \"details\" \"details\" \"details\" ...\n $ year   : num [1:221] 1950 1951 1952 1953 1954 ...\n $ created: num [1:221] 20210803 20210803 20210803 20210803 20210803 ...\n $ url    : chr [1:221] \"https://www1.ncdc.noaa.gov/pub/data/swdi/stormevents/csvfiles/StormEvents_details-ftp_v1.0_d1950_c20210803.csv.gz\" \"https://www1.ncdc.noaa.gov/pub/data/swdi/stormevents/csvfiles/StormEvents_details-ftp_v1.0_d1951_c20210803.csv.gz\" \"https://www1.ncdc.noaa.gov/pub/data/swdi/stormevents/csvfiles/StormEvents_details-ftp_v1.0_d1952_c20210803.csv.gz\" \"https://www1.ncdc.noaa.gov/pub/data/swdi/stormevents/csvfiles/StormEvents_details-ftp_v1.0_d1953_c20210803.csv.gz\" ...\n\n\nShow the code\n# display unique file types\ncat(\"\\nUnique file types:\\n\")\n\n\n\nUnique file types:\n\n\nShow the code\nunique(se_availableFiles$type)\n\n\n[1] \"details\"    \"fatalities\" \"locations\"  \"legacy\"    \n\n\nWe will mostly be interested in “details”, “locations”, and (maybe) “fatalities”. What is the most recent data available for these files?\n\n\nShow the code\nse_availableFiles %&gt;% \n  filter(year &gt; 2020) %&gt;% \n  arrange(desc(year)) %&gt;% \n  select(-url) %&gt;% \n  knitr::kable()\n\n\n\n\n\ntype\nyear\ncreated\n\n\n\n\ndetails\n2024\n20240716\n\n\nfatalities\n2024\n20240716\n\n\nlocations\n2024\n20240716\n\n\ndetails\n2023\n20240716\n\n\nfatalities\n2023\n20240716\n\n\nlocations\n2023\n20240716\n\n\ndetails\n2022\n20240716\n\n\nfatalities\n2022\n20240716\n\n\nlocations\n2022\n20240716\n\n\ndetails\n2021\n20240716\n\n\nfatalities\n2021\n20240716\n\n\nlocations\n2021\n20240716\n\n\n\n\n\nNow, let’s read in “details”, “locations”, and “fatalities for the years 2013 up to 2023\n\n\nShow the code\n# define simple function (putting code in fuctions prevents workspace from being\n# clutered with variables we will not use again)\nread_in_storm_data &lt;- function(\n    years_to_read_in = seq(params$currentYear - 10, params$currentYear, 1),\n    types_to_read_in = c(\"details\", \"locations\", \"fatalities\")\n    ) {\n  \n  # initialize data_list\n  data_list &lt;- vector(\"list\", length = length(years_to_read_in))\n  names(data_list) &lt;- years_to_read_in\n  for (year in seq(1, length(years_to_read_in))) {\n    data_list[[year]] &lt;- vector(\"list\", length = length(types_to_read_in))\n    names(data_list[[year]]) &lt;- as.character(types_to_read_in)\n  }\n  \n  # read in data over nested loop\n  for (i in seq(1,length(years_to_read_in))) {\n    for (j in seq(1,length(types_to_read_in))) {\n      currentData &lt;- se_data(year = years_to_read_in[i], type = types_to_read_in[j])\n      data_list[[i]][[j]] &lt;- currentData\n    }\n  }\n  \n  # save data_list\n  time &lt;- format(Sys.time(), \"%Y%m%d\")\n  fileName &lt;- paste0(time, \"_data_list.RDS\")\n  saveRDS(data_list, file = file.path(\"../data/stormData\", fileName))\n  # to read in data, use:\n  # data_list &lt;- readRDS(\"../0_Data/data_list.RDS\")\n  \n  return(data_list)\n}\n\n# call function and store results in data_list\ndata_list &lt;- read_in_storm_data()\n\n\n\n\nShow the code\n# load most recent data_list file\nfileName &lt;- \"data_list.RDS\"\npathName &lt;- \"../data/stormData\"\nfilePath &lt;- fs::dir_ls(path = pathName, regexp = paste0(fileName, \"$\")) %&gt;% last()\ndata_list &lt;- readRDS(filePath)"
  },
  {
    "objectID": "scripts/accessStormEventsData.html#inspect-data-structures",
    "href": "scripts/accessStormEventsData.html#inspect-data-structures",
    "title": "Extreme Weather Events Data: Access & Preprocessing",
    "section": "1.2 Inspect Data Structures",
    "text": "1.2 Inspect Data Structures\nWhat is the structure of “details”, “locations”, and “fatalities”?\n\n1.2.1 Details\n\n\nShow the code\ndata_list[[as.character(params$currentYear)]]$details %&gt;% \n  select(-c(episode_narrative, event_narrative)) %&gt;% \n  head(.,10) %&gt;% \n  datatable(options = list(scrollY = \"300px\"), fillContainer = TRUE)\n\n\n\n\n\n\nNote: two additional variables are not included in the table above:\n\nepisode_narrative (example:) In late October, a winter storm dumped heavy snow in eastern North Dakota and northwestern Minnesota over a period of 2 days. Due to mesoscale forces at play, some areas received a foot of snow or more where the band stalled. In addition to heavy snow, there was also blowing snow, reducing visibility across the area.\nevent_narrative (example:) Public reports 7.5 inches at Black Tiger Bay Campground in Saint Michael.\n\n\n\n1.2.2 Locations\n\n\nShow the code\ndata_list[[as.character(params$currentYear)]]$locations %&gt;% \n  head(.,10) %&gt;% \n  datatable(options = list(scrollY = \"300px\"), fillContainer = TRUE)\n\n\n\n\n\n\n\n\n1.2.3 Fatalities\n\n\nShow the code\ndata_list[[as.character(params$currentYear)]]$fatalities %&gt;% \n  head(.,10) %&gt;% \n  datatable(options = list(scrollY = \"300px\"), fillContainer = TRUE)"
  },
  {
    "objectID": "scripts/accessStormEventsData.html#recency-of-data",
    "href": "scripts/accessStormEventsData.html#recency-of-data",
    "title": "Extreme Weather Events Data: Access & Preprocessing",
    "section": "1.3 Recency of Data",
    "text": "1.3 Recency of Data\nWhat is the most recent data available in “details” for params$currentYear?\n\n\nShow the code\ndata_list[[as.character(params$currentYear)]]$details %&gt;% \n  mutate(arrange_date = strptime(end_date_time, format = \"%d-%b-%y %H:%M:%S\") %&gt;% as_datetime()) %&gt;% \n  arrange(desc(arrange_date)) %&gt;% \n  .$end_date_time %&gt;% .[1]\n\n\n[1] \"31-DEC-23 23:59:00\""
  },
  {
    "objectID": "scripts/accessStormEventsData.html#create-combined-datasets",
    "href": "scripts/accessStormEventsData.html#create-combined-datasets",
    "title": "Extreme Weather Events Data: Access & Preprocessing",
    "section": "1.4 Create Combined Datasets",
    "text": "1.4 Create Combined Datasets\n\n\nShow the code\ndata_details &lt;- tibble()\nfor (i in seq(1, length(data_list))) {\n  data_details &lt;- rbind(data_details, data_list[[i]]$details)\n}\n\ndata_locations &lt;- tibble()\nfor (i in seq(1, length(data_list))) {\n  data_locations &lt;- rbind(data_locations, data_list[[i]]$locations)\n}\n\ndata_fatalities &lt;- tibble()\nfor (i in seq(1, length(data_list))) {\n  data_fatalities &lt;- rbind(data_fatalities, data_list[[i]]$fatalities)\n}\n\n# since we will mostly work with data_details, let's save this data set\ntime &lt;- format(Sys.time(), \"%Y%m%d\")\nfileName &lt;- paste0(time, \"_data_details.RDS\")\nsaveRDS(data_details, file = file.path(\"../data/stormData\", fileName))"
  },
  {
    "objectID": "scripts/accessStormEventsData.html#simple-tidying",
    "href": "scripts/accessStormEventsData.html#simple-tidying",
    "title": "Extreme Weather Events Data: Access & Preprocessing",
    "section": "2.1 Simple Tidying",
    "text": "2.1 Simple Tidying\nWe will mainly work with data_details. Let’s tidy up this data (convert some integers to characters, some characters to integers, and some characters to date-time format).\n\n\nShow the code\n# load most recent data_details\nfileName &lt;- \"data_details.RDS\"\npathName &lt;- \"../data/stormData\"\nfilePath &lt;- fs::dir_ls(path = pathName, regexp = paste0(fileName, \"$\")) %&gt;% last()\ndata_details &lt;- readRDS(filePath)\n\n# convert some integers to characters so that they are not mistakenly treated\n# as integers\ntoChar &lt;- c(\n  \"episode_id\", \"event_id\",\n  \"state_fips\", \"cz_fips\",\n  \"category\",\n  \"tor_other_cz_fips\"\n)\ndata_details &lt;- data_details %&gt;% \n  mutate(across(all_of(toChar), as.character))\nrm(toChar)\n\n# for damage values, we need to convert strings like\n# \"3.12M\" and \"117.00K\" to integer values. We define a function to do so:\nconvert_to_integer &lt;- function(x) {\n  multiplier &lt;- c(\"K\" = 1000, \"M\" = 1000000)\n  numeric_part &lt;- as.numeric(sub(\"[^0-9.]\", \"\", x))\n  multiplier_part &lt;- substr(x, nchar(x), nchar(x))\n  multiplier_value &lt;- multiplier[multiplier_part]\n  return(as.integer(numeric_part * multiplier_value))\n}\n# apply function to \"damage\" variables\ndata_details &lt;- data_details %&gt;% \n  mutate(across(contains(\"damage\"), convert_to_integer))\nrm(convert_to_integer)\n\n# convert some character columns to date-time format\ndata_details &lt;- data_details %&gt;% \n  mutate(across(contains(\"date_time\"), dmy_hms))\n\n# store month_name as factor with the correct order of months as levels\ndata_details &lt;- data_details %&gt;% \n  mutate(month_name = factor(month_name, levels = month.name))\n\n# state_fips need to be two digits long. If the first digit was zero, this leading\n# zero was removed during the read in process of the data. This is corrected\n# using str_pad. Similarly, cz_fips needs to be three digits long.\ndata_details &lt;- data_details %&gt;% \n  mutate(state_fips = str_pad(state_fips, width = 2, side = \"left\", pad = \"0\")) %&gt;% \n  mutate(cz_fips = str_pad(cz_fips, width = 3, side = \"left\", pad = \"0\"))"
  },
  {
    "objectID": "scripts/accessStormEventsData.html#fips-tidying",
    "href": "scripts/accessStormEventsData.html#fips-tidying",
    "title": "Extreme Weather Events Data: Access & Preprocessing",
    "section": "2.2 FIPS Tidying",
    "text": "2.2 FIPS Tidying\nFor various forms of analyses, we will need the Federal Information Processing System (FIPS) Codes for States and Counties. For instance, we will need this information to associate specific extreme weather events with certain geographical regions (mostly Counties). The package usmap, which we will use to display geographical distributions of extreme weather events, works with county FIPS. Therefore, we need to tidy up our data to show events that conform to such FIPS data. The FIPS information is stored in two separate variables in the data set: state_fips and cz_fips.\nNote that the storm event database assigns FIPS not only to County/Parish (cz_type == \"C\"), but also NWS Public Forecast Zone and Marine Zones (cz_type == \"Z\").\nThus, the meaning of variable cz_fips depends on cz_type. Therefore, we first need to convert Z-type FIPS to C-type FIPS. There is a mapping of Forecast Zones onto County FIPS we can use for this. In the following code block, we\n\ncreate a data set mappingData with all the information to map NWS Forecast Zones to County FIPS and\nuse this mapping information to create a variable county_fips representing the County FIPS and\nultimately create a variable state_county_fips representing the full FIPS identifying each County in each State.\n\n\n\nShow the code\nFUNConvertFips &lt;- function(myData) {\n  \n  # define vector of urls to .txt files containing the mapping information\n  urlsToFiles &lt;- c(\n    \"https://www.weather.gov/source/pimar/PubRep/PUB_AR.txt\",\n    \"https://www.weather.gov/source/pimar/PubRep/PUB_CR.txt\",\n    \"https://www.weather.gov/source/pimar/PubRep/PUB_ER.txt\",\n    \"https://www.weather.gov/source/pimar/PubRep/PUB_PR.txt\",\n    \"https://www.weather.gov/source/pimar/PubRep/PUB_SR.txt\",\n    \"https://www.weather.gov/source/pimar/PubRep/PUB_WR.txt\"\n  )\n  \n  # define the variable names of each column in these files\n  varNames &lt;- c(\n    \"state_abr\",\n    \"id_zone\",\n    \"location_descr\",\n    \"county\",\n    \"fips\",\n    \"city\",\n    \"state_city_abr\"\n  )\n  \n  # define a function to read in the files\n  FUNReadFiles &lt;- function(myURL) {\n    dataOut &lt;- read.table(\n      file = myURL,\n      sep = \"|\",\n      header = FALSE,\n      quote = \"\",\n      colClasses = \"character\",\n      fill = FALSE\n    )\n    names(dataOut) &lt;- varNames\n    return(dataOut)\n  }\n  \n  # \"loop\" over this function and continuously combine read in data into one data frame\n  mappingData &lt;- plyr::ldply(urlsToFiles, FUNReadFiles) %&gt;% \n    as_tibble()\n  \n  # create data set that maps state abbreviations to full state names\n  mapping_states_abbr &lt;- usmap::fips_info() %&gt;%\n    as_tibble() %&gt;% \n    select(abbr, full) %&gt;% \n    mutate(state = toupper(full)) %&gt;% \n    select(-full)\n  \n  # combine mappingData with mapping_states_abbr\n  mappingData &lt;- mappingData %&gt;% \n    left_join(y = mapping_states_abbr, by = c(\"state_abr\" = \"abbr\")) %&gt;% \n    relocate(state, .after = state_abr) %&gt;% \n    mutate(cz_fips = id_zone) %&gt;% \n    relocate(cz_fips, .after = id_zone) %&gt;% \n    mutate(county_fips = str_extract(fips, \".{3}$\")) %&gt;% \n    relocate(county_fips, .after = fips)\n  \n  # subset myData to myData_czTypeC and myData_czTypeZ\n  myData_czTypeC &lt;- myData %&gt;% \n    filter(cz_type == \"C\")\n  myData_czTypeZ &lt;- myData %&gt;% \n    filter(cz_type == \"Z\")\n  \n  # define county_fips in myData_czTypeC\n  myData_czTypeC &lt;- myData_czTypeC %&gt;% \n    mutate(county_fips = cz_fips)\n  \n  # define county_fips in myData_czTypeZ\n  # first, create a temporary dataset\n  tmp &lt;- left_join(\n    x = myData_czTypeZ,\n    y = mappingData %&gt;% \n      select(state, cz_fips, county_fips),\n    by = c(\"state\", \"cz_fips\"),\n    relationship = \"many-to-many\"\n  )\n  # then, create a list with meta information for myData_czTypeZ\n  myData_czTypeZ_meta &lt;- list(\n    county_fips_isNA = tmp %&gt;% filter(is.na(county_fips)),\n    event_id_isDoublicated = tmp %&gt;% filter(duplicated(event_id)),\n    myData_czTypeZ_raw = tmp,\n    myData_czTypeZ_county_fips_isNA.removed = tmp %&gt;% filter(!is.na(county_fips))\n  )\n  # define myData_czTypeZ\n  # note that we only retain events whose county_fips is not NA! To see where\n  # these NAs come from, see myData_czTypeZ_meta$county_fips_isNA\n  myData_czTypeZ &lt;- myData_czTypeZ_meta$myData_czTypeZ_county_fips_isNA.removed\n  \n  # join myData_czTypeC and myData_czTypeZ\n  if (all(names(myData_czTypeC) == names(myData_czTypeZ))) {\n    myData_fips &lt;- rbind(\n      myData_czTypeC,\n      myData_czTypeZ\n    )\n  } else {\n    stop(\"all(names(myData_czTypeC) == names(myData_czTypeZ)) != TRUE\")\n  }\n  \n  # create variable state_county_fips representing the full and correct fips for each county\n  myData_fips &lt;- myData_fips %&gt;% \n    mutate(state_county_fips = str_c(state_fips, county_fips))\n  \n  return(list(\n    myData_fips = myData_fips,\n    myData_czTypeZ_meta = myData_czTypeZ_meta\n  ))\n  \n}\n\n# call function\nout_FUNConvertFips &lt;- FUNConvertFips(data_details)\n\n# define data_details_fips\ndata_details_fips &lt;- out_FUNConvertFips$myData_fips\n\n# save data_details_fips\ntime &lt;- format(Sys.time(), \"%Y%m%d\")\nfileName &lt;- paste0(time, \"_data_details_fips_raw.RDS\")\nsaveRDS(data_details_fips, file = file.path(\"../data/stormData\", fileName))\n\n\nAfter these changes, some challenges remain, which become obvious, if we try to match the FIPS provided in the data set with current FIPS available in usmap.\n\n\nShow the code\n# load most recent data_details_fips\nfileName &lt;- \"data_details_fips_raw.RDS\"\npathName &lt;- \"../data/stormData\"\nfilePath &lt;- fs::dir_ls(path = pathName, regexp = paste0(fileName, \"$\")) %&gt;% last()\ndata_details_fips &lt;- readRDS(filePath)\n\n# capture the warning message produced if we apply usmap::fips_info to\n# all unique state_county_fips in data_details_fips\nwarning_message &lt;- tryCatch({\n  result &lt;- fips_info(fips = unique(as.character(data_details_fips$state_county_fips)))\n}, warning = function(w) {\n  return(conditionMessage(w))\n})\nunmatched_fips &lt;- str_extract_all(warning_message, \"\\\\b\\\\d{5}\\\\b\")[[1]] %&gt;% unique()\n\n# create a tibble containing all unmatched fips\nunmatched_fips &lt;- tibble(\n  state_county_fips = unmatched_fips,\n  state_fips = state_county_fips %&gt;% \n    str_extract(\"^.{2}\"),\n  county_fips = state_county_fips %&gt;% \n    str_extract(\".{3}$\")\n) %&gt;% \n  arrange(state_county_fips)\n\n# in which states do we find unmatched fips?\nunmatched_fips_states &lt;- unmatched_fips %&gt;% \n  distinct(state_fips) %&gt;% \n  left_join(\n    y = usmap::fips_info(),\n    by =c(\"state_fips\" = \"fips\")\n  )\n\n# # inspect the main land states that had unmatched fips\n# unmatched_fips_states_mainLand &lt;- unmatched_fips_states %&gt;% \n#   filter(!is.na(abbr))\n# plot_usmap(regions = \"counties\", include = unmatched_fips_states_mainLand$abbr[1], labels = TRUE)\n# plot_usmap(regions = \"counties\", include = unmatched_fips_states_mainLand$abbr[2], labels = TRUE)\n# unmatched_fips %&gt;%\n#   filter(state_fips == \"02\")\n# \n# data_details_fips %&gt;% \n#   filter(state_fips %in% (unmatched_fips_states %&gt;% \n#            filter(is.na(abbr)) %&gt;% \n#            pull(state_fips))) %&gt;% \n#   select(state, cz_name) %&gt;% \n#   distinct(state)\n\n\n\n\nShow the code\ndatatable(unmatched_fips)\n\n\n\n\nTable 1: FIPS in data_details_fips that do not match with current FIPS as provided by usmap.\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nknitr::kable(unmatched_fips_states)\n\n\n\n\nTable 2: States associated with the unmatched FIPS reported in Table 1.\n\n\n\n\n\n\nstate_fips\nabbr\nfull\n\n\n\n\n02\nAK\nAlaska\n\n\n09\nCT\nConnecticut\n\n\n96\nNA\nNA\n\n\n97\nNA\nNA\n\n\n98\nNA\nNA\n\n\n99\nNA\nNA\n\n\n\n\n\n\n\n\nWhat is the origin of these unmatched FIPS? First, as listed in Table 3, state_fips 96, 97, 98, 99 are assigned to the following states that are considered territories (and not states) of the US. We will exclude these territories in further analyses.\n\n\nShow the code\ndata_details_fips %&gt;%\n  filter(state_fips %in% (unmatched_fips_states %&gt;%\n           filter(is.na(abbr)) %&gt;%\n           pull(state_fips))) %&gt;%\n  distinct(state_fips, .keep_all = TRUE) %&gt;% \n  select(state_fips, state) %&gt;% \n  knitr::kable()\n\n\n\n\nTable 3: Terretories of the US in the data_details_fips\n\n\n\n\n\n\nstate_fips\nstate\n\n\n\n\n99\nPUERTO RICO\n\n\n96\nVIRGIN ISLANDS\n\n\n98\nGUAM\n\n\n97\nAMERICAN SAMOA\n\n\n\n\n\n\n\n\nSecond, there are many unmatched FIPS in the state of Alaska (Table 4). This is due to the fact that Alaska had substantial changes to counties and their boundaries over the years (see here). Consistent information on how to map old counties to new counties is not readily available. We will exclude Alaska from further analyses.\n\n\nShow the code\ndata_details_fips %&gt;% \n  filter(state_county_fips %in% filter(unmatched_fips, state_fips == \"02\")$state_county_fips) %&gt;% \n  select(state_county_fips, state, cz_name) %&gt;% \n  distinct() %&gt;% \n  datatable()\n# # are there unmatched FIPS for Alaska in the latest year data? - YES\n# data_details_fips %&gt;% \n#   filter(year == params$currentYear, state_fips == \"02\") %&gt;% \n#   filter(state_county_fips %in% unmatched_fips$state_county_fips) %&gt;% \n#   select(state_county_fips, state, cz_name)\n\n\n\n\nTable 4: Unmatched FIPS in the state of Alaska.\n\n\n\n\n\n\n\n\n\n\nThird, there were substantial changes in the state of Connecticut: Originally, it consisted of 8 counties. After the changes, these counties were replaced with 9 new counties (for more information, see here and here). The old counties map to the new counties according to Table 5.\n\n\nShow the code\n# read in xlsx file mapping old counties and FIPS to new counties and FIPS\nconnecticut_newPlanningRegions &lt;- openxlsx::read.xlsx(\n  xlsxFile = \"https://www2.census.gov/geo/docs/reference/ct_change/ct_cou_to_cousub_crosswalk.xlsx\"\n) %&gt;% \n  as_tibble() %&gt;% \n  select(c(1:5))\n\n# rename variable names\nnames(connecticut_newPlanningRegions) &lt;- c(\n  \"state_fips\",\n  \"old_county_fips\",\n  \"old_county_name\",\n  \"new_county_fips\",\n  \"new_county_name\"\n)\n\n# select distinct combinations of our variables of interest\nconnecticut_newPlanningRegions &lt;- connecticut_newPlanningRegions %&gt;% \n  distinct(state_fips, old_county_fips, new_county_fips, .keep_all = TRUE)\n\n# combine state and county fips\nconnecticut_newPlanningRegions &lt;- connecticut_newPlanningRegions %&gt;% \n  mutate(state_county_fips_old = paste0(state_fips, old_county_fips),\n         state_county_fips_new = paste0(state_fips, new_county_fips))\n\n# display table\ndatatable(connecticut_newPlanningRegions)\n\n\n\n\nTable 5: Connecticut exact mapping of old counties to new counties.\n\n\n\n\n\n\n\n\n\n\nHowever, this mapping is too fine grained for our purposes. A better mapping can be achieved following Figure 1, which results in the following mapping summarized in Table 6.\n\n\n\n\n\n\nFigure 1: Mapping of old to new counties in Connecticut.\n\n\n\n\n\nShow the code\n# https://www.federalregister.gov/documents/2022/06/06/2022-12063/change-to-county-equivalents-in-the-state-of-connecticut\n\nold_fips &lt;- unmatched_fips %&gt;% \n  filter(state_fips == \"09\") %&gt;% \n  arrange(state_county_fips) %&gt;% \n  pull(state_county_fips)\nold_counties &lt;- c(\n  \"Fairfield\",\n  \"Harford\",\n  \"Litchfield\",\n  \"Middlesex\",\n  \"New Haven\",\n  \"New London\",\n  \"Tolland\",\n  \"Windham\"\n)\nold &lt;- tibble(\n  old_county = old_counties,\n  old_fips = old_fips\n)\n\nnew_counties &lt;- c(\n  \"Greater Bridgeport Planning Region\",\n  \"Western Connecticut Planning Region\",\n  \"Capitol Planning Region\",\n  \"Northwest Hills Planning Region\",\n  \"Lower Connecticut River Valley Planning Region\",\n  \"Naugatuck Valley Planning Region\",\n  \"South Central Connecticut Planning Region\",\n  \"Southeastern Connecticut Planning Region\",\n  \"Northeastern Connecticut Planning Region\"\n)\nnew_fips &lt;- usmap::fips(state = \"CT\", county = new_counties)\nnew &lt;- tibble(\n  new_county = new_counties,\n  new_fips = new_fips\n)\n\nold_counties_to_new_counties &lt;- tibble(\n  old_county = c(\n    \"Fairfield\",\n    \"Fairfield\",\n    \"Harford\",\n    \"Tolland\",\n    \"Litchfield\",\n    \"Middlesex\",\n    \"New Haven\",\n    \"New Haven\",\n    \"New London\",\n    \"Windham\"\n  ),\n  new_county = c(\n    \"Greater Bridgeport Planning Region\",\n    \"Western Connecticut Planning Region\",\n    \"Capitol Planning Region\",\n    \"Capitol Planning Region\",\n    \"Northwest Hills Planning Region\",\n    \"Lower Connecticut River Valley Planning Region\",\n    \"Naugatuck Valley Planning Region\",\n    \"South Central Connecticut Planning Region\",\n    \"Southeastern Connecticut Planning Region\",\n    \"Northeastern Connecticut Planning Region\"\n  )\n)\n\nconnecticut_newPlanningRegions &lt;- left_join(\n  x = old_counties_to_new_counties,\n  y = old,\n  by = \"old_county\"\n) %&gt;% \n  left_join(\n    y = new,\n    by = \"new_county\"\n  )\n\n# do some renamign and add new_county_fips\nconnecticut_newPlanningRegions &lt;- connecticut_newPlanningRegions %&gt;% \n  rename(\n    old_state_county_fips = old_fips,\n    new_state_county_fips = new_fips\n  ) %&gt;% \n  mutate(new_county_fips = new_state_county_fips %&gt;% str_extract(\".{3}$\"))\n\ndatatable(connecticut_newPlanningRegions)\n\n\n\n\nTable 6: Connecticut mapping of old counties to new counties.\n\n\n\n\n\n\n\n\n\n\nNow we apply the changes mentioned above to data_details_fips:\n\nremove US territories from data set\nremove state of Alaska from data set\napply new county names and FIPS to the state of Connecticut\n\n\n\nShow the code\n# we apply the changes outlined in the main text in slightly changed order\n\n# first, we apply the new county names and FIPS to the state of Connecticut\n\n# We check whether all state_county_fips for Connecticut are recorded using the old\n# fips.\ntmp &lt;- data_details_fips %&gt;% \n  filter(state_fips == \"09\") %&gt;% \n  filter(!state_county_fips %in% unmatched_fips$state_county_fips)\n\nif (!nrow(tmp)) {\n  message(\"All state_county_fips are recorded following the old FIPS codes.\")\n} else {\n  warning(\"There are state_county_fips that are recorded following the new FIPS codes!\")\n}\nrm(tmp)\n\n# create a data set without Connecticut entries that follow the old FIPS codes\ndata_details_fips_withoutCT &lt;- data_details_fips %&gt;% \n  filter(!(state_fips == \"09\" & (state_county_fips %in% unmatched_fips$state_county_fips)))\n\n# create a data set containing only Connecticut entries that follow the old FIPS codes\ndata_details_fips_CT &lt;- data_details_fips %&gt;% \n  filter(state_fips == \"09\" & (state_county_fips %in% unmatched_fips$state_county_fips))\n\n# mutate county_fips and state_county_fips so that they represent the new county_fips\n# and state_county_fips. Note that this will inflate the previously data_details_fips_CT\n# because there is a one-to-many relationsipt between old and new fips.\ndata_details_fips_CT &lt;- left_join(\n    x = data_details_fips_CT,\n    y = connecticut_newPlanningRegions %&gt;% \n      select(old_state_county_fips, new_state_county_fips, new_county_fips),\n    by = c(\"state_county_fips\" = \"old_state_county_fips\")\n  ) %&gt;% \n  mutate(\n    county_fips = new_county_fips,\n    state_county_fips = new_state_county_fips\n  ) %&gt;% \n  select(-starts_with(\"new_\"))\n\n# check whether the datasets without and with Connecticut have the same structure before\n# joning them again.\nif (all(names(data_details_fips_withoutCT) == names(data_details_fips_CT))) {\n  message(\"all(names(data_details_fips_withoutCT) == names(data_details_fips_CT)) == TRUE\")\n  data_details_fips &lt;- bind_rows(\n    data_details_fips_withoutCT,\n    data_details_fips_CT\n  )\n} else {\n  warning(\"The names of data_details_fips_withoutCT and data_details_fips_CT do not matach!\")\n}\n\n# then, we remove the US territories from the data set\ndata_details_fips &lt;- data_details_fips %&gt;%\n  filter(!state_fips %in% (unmatched_fips_states %&gt;%\n                             filter(is.na(abbr)) %&gt;%\n                             pull(state_fips)))\n\n# finally, we remove the state of Alaska (FIPS = 02) from the data set, but we save\n# a data set still containing Alaska just in case...\ndata_details_fips_withAK &lt;- data_details_fips\n\ndata_details_fips &lt;- data_details_fips %&gt;%\n  filter(state_fips != \"02\")\n\n\nFinally, we rearrange some variables in data_details_fips and save them for later use. We also store state_fips, state_county_fips and event_type as factors. This becomes handy for accurately counting number of events by groups later on.\n\n\nShow the code\n# rearrange order of variables in the data set\ndata_details_fips &lt;- data_details_fips %&gt;% \n  select(\n    begin_yearmonth,\n    episode_id, event_id,\n    state, state_county_fips,\n    event_type,\n    starts_with(\"damage\"),\n    starts_with(\"injuries\"),\n    starts_with(\"death\"),\n    everything()\n  ) %&gt;% \n  arrange(begin_yearmonth, episode_id, event_id, state_county_fips)\n\n# store state_county_fips and event_type as factor\ndata_details_fips &lt;- data_details_fips %&gt;% \n  mutate(\n    state_fips = factor(state_fips, levels = sort(unique(.$state_fips))),\n    state_county_fips = factor(state_county_fips, levels = sort(unique(.$state_county_fips))),\n    event_type = factor(event_type, levels = sort(unique(.$event_type)))\n  )\n\n# save data_details_fips\ntime &lt;- format(Sys.time(), \"%Y%m%d\")\nfileName &lt;- paste0(time, \"_data_details_fips.RDS\")\nsaveRDS(data_details_fips, file = file.path(\"../data/stormData\", fileName))\n\n\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.0 (2024-04-24)\n os       macOS Sonoma 14.4.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/Zurich\n date     2024-08-19\n pandoc   3.1.11 @ /usr/local/bin/ (via rmarkdown)\n quarto   1.5.45 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n dplyr       * 1.1.4   2023-11-17 [1] CRAN (R 4.4.0)\n DT          * 0.33    2024-04-04 [1] CRAN (R 4.4.0)\n forcats     * 1.0.0   2023-01-29 [1] CRAN (R 4.4.0)\n ggplot2     * 3.5.1   2024-04-23 [1] CRAN (R 4.4.0)\n lubridate   * 1.9.3   2023-09-27 [1] CRAN (R 4.4.0)\n openxlsx    * 4.2.5.2 2023-02-06 [1] CRAN (R 4.4.0)\n purrr       * 1.0.2   2023-08-10 [1] CRAN (R 4.4.0)\n readr       * 2.1.5   2024-01-10 [1] CRAN (R 4.4.0)\n rnoaa       * 1.4.0   2024-07-15 [1] Github (ropensci/rnoaa@95868c9)\n sessioninfo * 1.2.2   2021-12-06 [1] CRAN (R 4.4.0)\n stringr     * 1.5.1   2023-11-14 [1] CRAN (R 4.4.0)\n tibble      * 3.2.1   2023-03-20 [1] CRAN (R 4.4.0)\n tidyr       * 1.3.1   2024-01-24 [1] CRAN (R 4.4.0)\n tidyverse   * 2.0.0   2023-02-22 [1] CRAN (R 4.4.0)\n usmap       * 0.7.1   2024-03-21 [1] CRAN (R 4.4.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "index.html#registered-report-supplementary-information",
    "href": "index.html#registered-report-supplementary-information",
    "title": "EcoTRACE",
    "section": "Registered Report Supplementary Information",
    "text": "Registered Report Supplementary Information\nWelcome to our project’s supplementary information website. Here, you’ll find all the scripts used to preprocess and visualize the data reported in the first stage of our Registered Report, which has been submitted to Nature Climate Change:\n\nExtreme Weather Events Data\n\nAccess & Preprocessing\nThis section provides guidance on accessing the storm events database and documents all the preprocessing steps applied to the data, ensuring it is ready for further analysis.\nAnalysis\nHere, we document our analyses aimed at determining the optimal time window for the study, focusing on maximizing the chances of capturing meaningful variability in extreme weather exposure.\n\nPower Analyses\nThis section includes all the code used to simulate data and conduct power analyses. We also provide detailed explanations of the rationale and previous empirical work that informed our simulations and analyses.\nSupplementary Information\nAll analyses included in the Supplementary Information are compiled in this section. The Supplementary Information file submitted in our Registered Report was generated by rendering this website as a PDF."
  },
  {
    "objectID": "scripts/analyseStormEventsData.html",
    "href": "scripts/analyseStormEventsData.html",
    "title": "Extreme Weather Events Data: Analysis",
    "section": "",
    "text": "Show the code\n# install package librarian if needed\nif (!(\"librarian\" %in% rownames(installed.packages()))) {\n  install.packages(\"librarian\")\n}\n\n# load required packages\nlibrarian::shelf(\n  tidyverse,\n  fs,\n  usmap,\n  ggpubr,\n  sessioninfo\n)\n\n# Source required functions\nmyFunctions &lt;- c(\n  \"FUNStormEventsData_filterData\"\n)\n\nfor (f in myFunctions) {\n  source(paste0(\"../functions/\", f, \".R\"))\n}\n\n# Preperations to show states boundaries\npoly_states &lt;- plot_usmap(regions = \"states\")\n\n# Read in data_details_fips\nfileName &lt;- \"data_details_fips.RDS\"\npathName &lt;- \"../data/stormData\"\nfilePath &lt;- dir_ls(path = pathName, regexp = paste0(fileName, \"$\")) %&gt;% last()\ndata_details_fips &lt;- readRDS(filePath)\n\n\n\n1 Purpose & Rationale\nAs outlined in the Registered Report, we will assess the number of extreme weather episodes recorded in each participant’s county of residence within the 30 days prior to study completion. Regarding the time window during which we plan to conduct the study, we aim for maximizing the likelihood of capturing suitable variability in the exposure to extreme weather episodes with notable geographic variability. To this end, we analyzed records of extreme weather episodes over the last ten years.\n\n\n2 Filter Data\nWe filter the storm events data for the specific years, months, and extreme weather event types we are interested in. We filter for all years from 2014 to 2023 (as data are not complete for the year 2024 yet), we highlight the month of July, and we focus on those types of extreme weather events that are predicted to increase in frequency and severity due to climate change (IPCC 2023): Excessive Heat, Drought, Wildfire, Flash Flood, Coastal Flood, Strong Wind, Hail, and Tornado.\n\n\nShow the code\n# Define variables of interest\nmyYears &lt;- seq(2014, 2023)\nmyMonths &lt;- c(\"July\")\nmyEventTypes &lt;- c(\n  \"Excessive Heat\",\n  \"Drought\",\n  \"Wildfire\",\n  \"Flash Flood\",\n  \"Coastal Flood\",\n  \"Strong Wind\",\n  \"Hail\",\n  \"Tornado\"\n)\n\n# Call function\nout &lt;- FUNStormEventsData_filterData(\n  myData = data_details_fips,\n  myYears = myYears,\n  myMonths = myMonths,\n  myEventTypes = myEventTypes\n)\n\n\n\n\n3 Analysis\n\n\nShow the code\np.hist &lt;- out$dataForHist %&gt;% \n  group_by(year) %&gt;% \n  mutate(\n    max_nEpisodes = max(nEpisodes),\n    yearlyMean_nEpisodes = mean(nEpisodes)\n  ) %&gt;% \n  ungroup() %&gt;% \n  mutate(max_month = ifelse(nEpisodes == max_nEpisodes, TRUE, FALSE)) %&gt;% \n  ggplot(aes(\n    x = month_name, y = nEpisodes,\n    linewidth = max_month,\n    fill = month_name %in% myMonths\n  )) +\n  geom_hline(\n    mapping = aes(yintercept = yearlyMean_nEpisodes),\n    linetype = \"dashed\",\n    color = \"black\"\n  ) +\n  geom_bar(\n    stat = \"identity\",\n    color = \"black\",\n    alpha = .7,\n    show.legend = FALSE\n  ) +\n  scale_linewidth_manual(values = c(0.5, 2)) +\n  scale_x_discrete(labels = month.abb) +\n  scale_fill_manual(\n    values = c(\"darkgrey\", \"orange\"),\n  ) +\n  labs(\n    title = \"Number of Extreme Weather Episodes by Month over the Years 2014 to 2023\",\n    x = \"Month\",\n    y = \"Number of Episodes\"\n  ) +\n  theme_bw() +\n  theme(\n    text = element_text(size = 15),\n    plot.title = element_text(hjust = .5),\n    axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)\n  ) +\n  facet_wrap(~year, ncol = 5)\n\n\njpeg(\n  file = \"../images/histogramSeasonalDistribution.jpeg\",\n  width = 14, height = 7.5, units = \"in\", res = 600\n)\nprint(p.hist)\ninvisible(dev.off())\n\n\n\n\nShow the code\np.map_bin &lt;- plot_usmap(\n  data = out$dataForUsPlot,\n  values = \"episodes_bin\",\n  regions = \"counties\",\n  exclude = c(\"AK\", \"HI\"),\n  color = \"black\",\n  linewidth = 0.1\n  ) +\n  geom_sf(\n    data = poly_states[[1]] %&gt;% \n      filter(!(abbr %in% c(\"AK\", \"HI\"))),\n    color = \"black\",\n    fill = NA,\n    linewidth = .3\n  ) +\n  scale_fill_manual(\n    name = \"Number of Episodes &gt; 0\",\n    values = c(\"white\", \"orange\")\n  ) +\n  labs(\n    title = \"Extreme Weather Episodes in July over the Years 2014 to 2023\"\n  ) +\n  theme_bw() +\n  theme(\n    text = element_text(size = 15),\n    legend.position = \"bottom\",\n    plot.title = element_text(hjust = .5),\n    panel.grid = element_blank(),\n    axis.ticks = element_blank(),\n    axis.text = element_blank()\n  ) +\n  facet_wrap(~year, ncol = 5)\n\njpeg(\n  file = \"../images/mapGeographicalDistribution_bin.jpeg\",\n  width = 14, height = 7.5, units = \"in\", res = 600\n)\nprint(p.map_bin)\ninvisible(dev.off())\n\n\nAnalyzing the seasonal distribution of extreme weather episodes, Figure 1 shows that July consistently shows a high number of extreme weather episodes over the last ten years. Additionally, Figure 2 indicates that withing the month of July, these extreme weather episodes also display a high geographical variability.\n\n\n\n\n\n\nFigure 1: Histograms showing the number of extreme weather episodes by month from 2014 to 2023. The dashed horizontal line indicates the mean number of extreme weather episodes in each year. The thick-bordered bar marks the month with the most extreme weather events each year. The orange bar represents July. July had the most extreme weather events in 4 out of 10 years, and in another 4 years, it was right before or after the peak month. Only episodes that included at least one of the following event types were considered: excessive heat, drought, wildfire, flash flood, coastal flood, strong wind, hail, tornado.\n\n\n\n\n\n\n\n\n\nFigure 2: Maps displaying the geographical distribution of the occurrence of at least one extreme weather episode in July over the years 2014 to 2023. Only episodes that included at least one of the following event types were considered: excessive heat, drought, wildfire, flash flood, coastal flood, strong wind, hail, tornado.\n\n\n\n\n\nShow the code\ndataForPlot &lt;- out$dataForUsPlot %&gt;% \n  mutate(nEpisodes_withNA = ifelse(nEpisodes == 0, NA_integer_, nEpisodes))\n\np.map_cont &lt;- plot_usmap(\n  data = dataForPlot,\n  values = \"nEpisodes_withNA\",\n  regions = \"counties\",\n  exclude = c(\"AK\", \"HI\"),\n  color = \"black\",\n  linewidth = 0.1\n  ) +\n  geom_sf(\n    data = poly_states[[1]] %&gt;% \n      filter(!(abbr %in% c(\"AK\", \"HI\"))),\n    color = \"black\",\n    fill = NA,\n    linewidth = .3\n  ) +\n  scale_fill_binned(\n    name = \"Number of Episodes\",\n    n.breaks = 10,\n    type = \"viridis\",\n    na.value = \"white\"\n  ) +\n  labs(\n    title = \"Extreme Weather Episodes in July over the Years 2014 to 2023\"\n  ) +\n  theme_bw() +\n  theme(\n    text = element_text(size = 15),\n    legend.position = \"bottom\",\n    plot.title = element_text(hjust = .5),\n    panel.grid = element_blank(),\n    axis.ticks = element_blank(),\n    axis.text = element_blank()\n  ) +\n  facet_wrap(~year, ncol = 5)\n\njpeg(\n  file = \"../images/mapGeographicalDistribution_cont.jpeg\",\n  width = 14, height = 7.5, units = \"in\", res = 600\n)\nprint(p.map_cont)\ninvisible(dev.off())\n\np.hist_count &lt;- out$dataForUsPlot %&gt;% \n  group_by(year, nEpisodes) %&gt;% \n  summarise(\n    count = n(),\n    prcnt = count / n_distinct(out$dataForUsPlot$fips)\n  ) %&gt;% \n  ggplot(aes(x = nEpisodes, y = prcnt)) +\n  geom_bar(stat = \"identity\", color = \"black\", fill = \"darkgrey\") +\n  scale_y_continuous(labels = scales::label_percent()) +\n  labs(\n    x = \"Number of Episodes\",\n    y = \"Proportion of Counties\"\n  ) +\n  theme_bw() +\n  labs(\n    title = \"Extreme Weather Episodes in July over the Years 2014 to 2023\"\n  ) +\n  theme(\n    text = element_text(size = 15),\n    legend.position = \"bottom\",\n    plot.title = element_text(hjust = .5)\n  ) +\n  facet_wrap(~year, ncol = 5)\n\njpeg(\n  file = \"../images/frequencyDistribution_cont.jpeg\",\n  width = 14, height = 7.5, units = \"in\", res = 600\n)\nprint(p.hist_count)\ninvisible(dev.off())\n\n# Calcualte some proportions for display in text\nprops2023 &lt;- out$dataForUsPlot %&gt;% \n  filter(year == 2023) %&gt;% \n  count(episodes_bin) %&gt;% \n  mutate(\n    freq = n/sum(n),\n    freq_prcnt = paste0(format(round(freq*100, 2), nsmall = 2), \"%\")\n  )\n\n\nWhile Figure 2 visualizes the occurrence of at least one extreme weather episode in July for each county and year (binary variable), Figure 4 displays the actual number of such episodes (continuous). The vast majority of counties were exposed to few episodes, indicating that most of the variability is due to whether an extreme weather episode occurred at all or not. This is further supported by Figure 3 showing histograms for the number of extreme weather episodes in July over the past ten years. Most counties reported either zero or one extreme weather episode in July, and the ratio of counties experiencing no episodes to counties experiencing at least one episode seems to gradually approach 1:1. In July 2023, for instance, this ratio reached 1.02, with 50.43% of counties being exposed to zero and 49.57% of counties being exposed to at least one extreme weather episode.\n\n\n\n\n\n\nFigure 3: Maps displaying the geographical distribution of the raw number of extreme weather episodes in July over the years 2014 to 2023. The color palette indicates numbers greater than zero, and white represent a count of zero episodes.\n\n\n\n\n\n\n\n\n\nFigure 4: Histograms displaying the distribution of the raw number of extreme weather episodes in July over the years 2014 to 2023. For each number of episodes on the x-axis, the y-axis shows the proportion of counties that recorded this number of episodes.\n\n\n\nFinally, as reported in the analysis plan and the design table, we plan to run a set of additional analyses regarding hypotheses H2 and H3, in which we will test the sensitivity of results to the time period prior to study completion used to assess extreme weather exposure. Regarding H2, we will estimate the two-way interaction effect of political affiliation and extreme weather exposure on ΔDuration for different time periods from 30 days to 360 days in increments of 30 days. Similarly for H3, we will estimate the three-way interaction effect of political affiliation, extreme weather exposure, and attribution of extreme weather events to climate change on ΔDuration for the same time periods. We will visualize results of these additional analyses by plotting the two-way (or three-way) interaction regression coefficients as points surrounded by their 95%-CI on the y-axis and the 12 time periods on the x-axis, as displayed in Figure 5 with simulated data. Based on previous research (Konisky, Hughes, and Kaylor 2016), we expect that the estimated effects will decay as the number of days prior to study completion used to assess the occurrence of extreme weather episodes increases.\n\n\nShow the code\nset.seed(123)\np.sensitivity &lt;- tibble(\n  Days = seq(30, 360, 30),\n  Coefficient = accumulate(1:11, ~ .x * .7, .init = 0.1143),\n  Error = rnorm(12, .07, 0.005),\n  CI_high = Coefficient + .5 * Error,\n  CI_low = Coefficient - .5 * Error\n) %&gt;% \n  ggplot(aes(x = Days, y = Coefficient, color = CI_low &lt; 0)) +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  geom_errorbar(aes(ymin = CI_low, ymax = CI_high), width = 3) +\n  geom_point(\n    shape = \"circle filled\",\n    fill = \"white\",\n    size = 3,\n    stroke = 1\n  ) +\n  scale_color_manual(values = c(\"black\", \"grey\")) +\n  scale_x_continuous(breaks = seq(30, 360, 30)) +\n  labs(\n    x = \"Days used to assess occurence of extreme weather episodes\",\n    y = \"Regression coefficient\\n(surrounded by 95%-CI)\"\n  ) +\n  theme_bw() +\n  theme(\n    panel.grid.minor = element_blank(),\n    legend.position = \"None\"\n  )\nset.seed(NULL)\n\njpeg(\n  file = \"../images/sensitivityAnalyses_simulation.jpeg\",\n  width = 7, height = 5, units = \"in\", res = 600\n)\nprint(p.sensitivity)\ninvisible(dev.off())\n\n\n\n\n\n\n\n\nFigure 5: Simulated regression coefficients of interaction effects for different number of days prior to study completion used to assess the occurrence of extreme weather episodes. Point estimates are surrounded by their 95% confidence intervals. The dashed line represents the absence of an interaction effect (regression coefficient of zero). Significance of regression coefficients is color-coded, with black indicating regression coefficients significantly different from zero, and grey indicating no significant difference from zero.\n\n\n\n\n\n4 Conclusion\nOur analyses indicate that July consistently shows a high number of extreme whether episodes with notable geographic variability (Figure 1 and Figure 2). Therefore, to maximize the likelihood of capturing suitable variability in exposure to extreme weather episodes, we plan to conduct our study at the beginning of August, ensuring that the 30-day period prior to study completion falls within July. Moreover, the main source of variability in exposure to extreme weather episodes in July is due to whether at least one episode occurred or not (Figure 4 and Figure 4). Thus, our main analyses will focus on whether a participant was exposed to at least one extreme weather episode in the 30 days prior to study completion, treated as a binary variable. In additional analyses, we will test the sensitivity of our results to different time periods used to assess extreme weather exposure prior to study completion.\n\n\n\n\n\n\nExpand for Session Info\n\n\n\n\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.0 (2024-04-24)\n os       macOS Sonoma 14.4.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/Zurich\n date     2024-08-19\n pandoc   3.1.11 @ /usr/local/bin/ (via rmarkdown)\n quarto   1.5.45 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n dplyr       * 1.1.4   2023-11-17 [1] CRAN (R 4.4.0)\n forcats     * 1.0.0   2023-01-29 [1] CRAN (R 4.4.0)\n fs          * 1.6.4   2024-04-25 [1] CRAN (R 4.4.0)\n ggplot2     * 3.5.1   2024-04-23 [1] CRAN (R 4.4.0)\n ggpubr      * 0.6.0   2023-02-10 [1] CRAN (R 4.4.0)\n lubridate   * 1.9.3   2023-09-27 [1] CRAN (R 4.4.0)\n purrr       * 1.0.2   2023-08-10 [1] CRAN (R 4.4.0)\n readr       * 2.1.5   2024-01-10 [1] CRAN (R 4.4.0)\n sessioninfo * 1.2.2   2021-12-06 [1] CRAN (R 4.4.0)\n stringr     * 1.5.1   2023-11-14 [1] CRAN (R 4.4.0)\n tibble      * 3.2.1   2023-03-20 [1] CRAN (R 4.4.0)\n tidyr       * 1.3.1   2024-01-24 [1] CRAN (R 4.4.0)\n tidyverse   * 2.0.0   2023-02-22 [1] CRAN (R 4.4.0)\n usmap       * 0.7.1   2024-03-21 [1] CRAN (R 4.4.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────\n\n\n\n\n\n\n\n\n\n\nReferences\n\nIPCC, ed. 2023. “Weather and Climate Extreme Events in a Changing Climate.” In, 1513–1766. Cambridge: Cambridge University Press. https://doi.org/10.1017/9781009157896.013.\n\n\nKonisky, David M., Llewelyn Hughes, and Charles H. Kaylor. 2016. “Extreme Weather Events and Climate Change Concern.” Climatic Change 134 (4): 533–47. https://doi.org/10.1007/s10584-015-1555-3."
  },
  {
    "objectID": "scripts/powerSimulations.html",
    "href": "scripts/powerSimulations.html",
    "title": "Power Simulations for Registered Report",
    "section": "",
    "text": "Summary\n\n\n\n\nSample-size determination analysis suggests that a sample size of N = 600 would result in high statistical power (≥ 95%) to detect a smallest effect size of interest (SESOI) of 0.1143 (see Figure 4) for the effect of political affiliation on ΔDuration. Taking into account potential participant exclusions, we aim for a final sample size of N = 950.\nEffect-size sensitivity analysis suggests that a final sample size of N = 950 enables the detection of a two-way interaction effect of political affiliation with extreme weather exposure of 0.1619 with ≥ 95% statistical power (see Figure 7).\nEffect-size sensitivity analysis suggests that a final sample size of N = 950 enables the detection of a three-way interaction effect of political affiliation with extreme weather exposure and subjective attribution of extreme weather events to climate change of 0.1890 with ≥ 95% statistical power (see Figure 11)."
  },
  {
    "objectID": "scripts/powerSimulations.html#δduration",
    "href": "scripts/powerSimulations.html#δduration",
    "title": "Power Simulations for Registered Report",
    "section": "2.1 ΔDuration",
    "text": "2.1 ΔDuration\nParticipants will complete 25 trials in a new variant of the Carbon Emission Task (CET, Berger and Wyss 2021) optimized for online process-tracing using MouselabWEB (Willemsen and Johnson 2019). An example trial of the task is displayed and explained in Figure 1.\n\n\n\n\n\n\nFigure 1: An example trial of the new variant of the CET. (A) Participants are presented with two options which are associated with different bonus payment and carbon emission consequences. (B) Participants inspect the exact consequences regarding each attribute of each option by hovering their mouse over the respective boxes. Moving the mouse outside of a box occludes the information again. Note that whether the bonus or carbon attributes are displayed in the top row is randomized across participants but held constant within participants. (C) By visiting all boxes, participants can acquire all available information in a trial (all boxes opened simultaneously for demonstration purposes only). Note that whether the option maximizing the bonus payment for participants is presented in the left or right row is randomized within participants.\n\n\n\nIn all analyses, the criterion (dependent variable) will be ΔDuration (deltaDuration), which is calculated in each trial as:\n\\[\n\\Delta Duration = \\frac{(t_{Carbon_{A}} + t_{Carbon_{B}}) - (t_{Bonus_{A}} + t_{Bonus_{B}})}{t_{Carbon_{A}} + t_{Carbon_{B}} + t_{Bonus_{A}} + t_{Bonus_{B}}}\n\\]\nwith \\(t\\) representing the summed up dwell time on \\(Carbon/Bonus\\) boxes in Option \\(A/B\\). ΔDuration varies between -1 and 1 with:\n\na value of -1 indicating that the entire dwell time was spent on gathering Bonus information\na value of 0 indicating that the dwell time was equally split between gathering Bonus and Carbon information\na value of 1 indication that the entire dwell time was spent on gathering Carbon information"
  },
  {
    "objectID": "scripts/powerSimulations.html#political-affiliation",
    "href": "scripts/powerSimulations.html#political-affiliation",
    "title": "Power Simulations for Registered Report",
    "section": "2.2 Political Affiliation",
    "text": "2.2 Political Affiliation\nWe will assess political affiliation using the following question:\nGenerally speaking, do you think of yourself as a Democrat, Republican or Independent?\nParticipants will answer on the following 7-point Likert scale:\n[1] Strong Republican, [2] Not strong Republican, [3] Independent, close to Republican, [4] Independent, [5] Independent, close to Democrat, [6] Not strong Democrat, [7] Strong Democrat\nAdditionally, if participants self-identify as [4] Independent, they will be asked:\nYou said that you think of yourself as an Independent politically. If you had to identify with one party of the two parties, which one would you choose?\nParticipants will answer on the following scale:\n[1] Republican Party, [2] Democratic Party\nBased on these questions, we classify participants as either Republican or Democrat as represented by the variable polAff that can take on the following values:\n[rep] Republican Party, [dem] Democratic Party"
  },
  {
    "objectID": "scripts/powerSimulations.html#extreme-weather-exposure",
    "href": "scripts/powerSimulations.html#extreme-weather-exposure",
    "title": "Power Simulations for Registered Report",
    "section": "2.3 Extreme Weather Exposure",
    "text": "2.3 Extreme Weather Exposure\nFor each participant, we will assess the number of extreme weather episodes that occurred in the participants’ county of residence in the 30 days prior to study completion. We then create a variable ewe which equals to TRUE if at least one extreme weather episode occurred in the specified time interval, and FALSE otherwise."
  },
  {
    "objectID": "scripts/powerSimulations.html#subjective-attribution",
    "href": "scripts/powerSimulations.html#subjective-attribution",
    "title": "Power Simulations for Registered Report",
    "section": "2.4 Subjective Attribution",
    "text": "2.4 Subjective Attribution\nWe will assess the degree to which participants attribute extreme weather events to climate change (see Ogunbode et al. 2019). Participants will rate their agreement to the following three questions:\n\nExtreme weather events are caused in part by climate change.\nExtreme weather events are a sign that the impacts of climate change are happening now.\nExtreme weather events show us what we can expect from climate change in the future.\n\nParticipants will answer on the following 5-point Likert scale:\n[1] Strongly disagree, [2] Somewhat disagree, [3] Neither agree nor disagree, [4] Somewhat agree, [5] Strongly agree\nSubjective attribution of EWE to climate change will be operationalised as the mean agreement to these three statements. Note that Ogunbode et al. (2019), who used the same questions, response options, and aggregation, report a mean of 3.67 and a SD of 0.85 for this variable."
  },
  {
    "objectID": "scripts/powerSimulations.html#data-simulation-function",
    "href": "scripts/powerSimulations.html#data-simulation-function",
    "title": "Power Simulations for Registered Report",
    "section": "4.1 Data Simulation Function",
    "text": "4.1 Data Simulation Function\nWe first define a function that simulates data for the main effect of political affiliation on ΔDuration: FUN_sim. The function will simulate data according to the following model, expressed in lme4-lingo:\ndeltaDuration ~ polAff + (1|subj) + (1|trial)\nThe function FUN_sim takes, among others, the following important arguments:\n\nn_subj: Number of subjects. Chaning this parameter allows us to assess statistical power for different sample sizes.\nbeta_0: Fixed intercept (grand mean). We assume that the average participant (irrespective of political affiliation or any other predictor variable) spends about the same time on searching for and attending to carbon as to bonus information in the CET. Therefore, we set beta_0 to zero. The effects of predictor variables will be modeled as deviations from this grand mean.\nbeta_p: Fixed effect of political affiliation. This value represents the average difference in ΔDuration between Democrats and Republicans (Democrats - Republicans). As discussed above, we set this value to 0.1143 by default, and we assess the effect of changing this variable on statistical power.\nsubj_0: By-subject random intercept SD. We simulate that a participants’ deviations from the grand mean for ΔDuration follows a normal distribution with a mean of 0 and a standard deviation of subj_0 = 0.29. We base our default value on a study by Reeck, Wall, and Johnson (2017). They investigated whether variability in information search behavior is driven predominantly by differences in the features of a choice (i.e., in our case: the relative differences between carbon and bonus outcomes in options A and B) or by individual differences. To this end, they predicted information acquisition using a intercept-only model that included random intercepts for subjects and items. They estimated the random intercept of subjects to be 0.29.\ntrial_0: By-trial random intercept SD. We simulate that a items’ deviations from the grand mean for ΔDuration follows a normal distribution with a mean of 0 and a standard deviation of trial_0 = 0.04. Again, we base our default value on the study by Reeck, Wall, and Johnson (2017), who estimated a random intercept for trials of 0.04.\nsigma: Trial-level noise (error) SD. We model the error SD to be of the same size as the sum of the random intercept SDs = 0.29 + 0.04 = 0.33. We also report simulation results for an error SD that is twice the size of the random intercept SDs, i.e., 0.66.\n\nThe function FUN_sim is defined below:\n\n\nShow the code\n# define data simulation function\nFUN_sim &lt;- function(\n  n_subj       =        1000, # number of subjects\n  n_subj_prop  =   c(.5, .5), # proportion of republican and democrat subjects\n  n_trial      =          25, # number of trials\n  beta_0       =           0, # intercept (grand mean) for deltaDuration\n  beta_p       =     0.4/3.5, # effect of political affiliation on deltaDuration\n  subj_0       =         .29, # by-subject random intercept sd for dt carbon\n  trial_0      =         .04, # by-trial random intercept sd\n  sigma        = 1*(.29+.04), # residual (error) sd\n  \n  truncNums    =        TRUE, # should impossible deltaDuration values be truncuated?\n  setSeed      =        NULL  # seed number to achieve reproducible results. Set to NULL for simulations!\n) {\n  \n  # set seed to achieve reproducible results for demonstration purposes\n  set.seed(setSeed)\n  \n  # simulate data for dwell time on carbon information\n  dataSim &lt;- \n    # add random factor subject\n    add_random(subj = n_subj) %&gt;% \n    # add random factor trial\n    add_random(trial = n_trial) %&gt;% \n    # add between-subject factor political affiliation (with anova contrast)\n    add_between(\"subj\", polAff = c(\"rep\", \"dem\"), .prob = n_subj_prop*n_subj, .shuffle = FALSE) %&gt;% \n    add_contrast(\"polAff\", colnames = \"X_p\", contrast = \"anova\") %&gt;% \n    # add by-subject random intercept\n    add_ranef(\"subj\", S_0 = subj_0) %&gt;% \n    # add by-trial random intercept\n    add_ranef(\"trial\", T_0 = trial_0) %&gt;% \n    # add error term\n    add_ranef(e_st = sigma) %&gt;% \n    # add response values\n    mutate(\n      # add together fixed and random effects for each effect\n      B_0 = beta_0 + S_0 + T_0,\n      B_p = beta_p,\n      # calculate dv by adding each effect term multiplied by the relevant\n      # effect-coded factors and adding the error term\n      deltaDuration = B_0 + (B_p * X_p) + e_st\n    )\n  \n  # unset seed\n  set.seed(NULL)\n  \n  # truncuate impossible deltaDurations\n  if(truncNums) {\n    dataSim &lt;- dataSim %&gt;% \n      mutate(deltaDuration = if_else(deltaDuration &lt; -1, -1,\n        if_else(deltaDuration &gt; 1, 1, deltaDuration)))\n  }\n  \n  # run a linear mixed effects model and check summary\n  mod &lt;- lmer(\n    deltaDuration ~ polAff + (1 | subj) + (1 | trial),\n    data = dataSim,\n  )\n  mod.sum &lt;- summary(mod)\n  \n  # get results in tidy format\n  mod.broom &lt;- broom.mixed::tidy(mod)\n  \n  return(list(\n    dataSim = dataSim,\n    modelLmer = mod,\n    modelResults = mod.broom\n  ))\n  \n}\n\n\nWe call the function once and extract the results of this single simulation:\n\n\nShow the code\n# Call function\nout &lt;- FUN_sim(\n  n_subj       =        1000, # number of subjects\n  n_subj_prop  =   c(.5, .5), # proportion of republican and democrat subjects\n  n_trial      =          25, # number of trials\n  beta_0       =           0, # intercept (grand mean) for deltaDuration\n  beta_p       =     0.4/3.5, # effect of political affiliation on deltaDuration\n  subj_0       =         .29, # by-subject random intercept sd for dt carbon\n  trial_0      =         .04, # by-trial random intercept sd\n  sigma        = 1*(.29+.04), # residual (error) sd\n  \n  truncNums    =        TRUE, # should impossible deltaDuration values be truncuated?\n  setSeed      =        1234  # seed number to achieve reproducible results. Set to NULL for simulations!\n)\n\n# Get results table\nresultsTable &lt;- out$modelResults %&gt;% \n  select(-c(std.error, statistic, df)) %&gt;% \n  mutate(across(where(is_double), ~ round(.x, 4))) %&gt;% \n  knitr::kable()\nformulaUsedForFit &lt;- paste(as.character(formula(out$modelLmer))[c(2,1,3)], collapse = \" \")\n\n# Create plot\np.demo.mainEffect &lt;-  out$dataSim %&gt;% \n  ggplot(aes(x = polAff, y = deltaDuration, color = polAff)) +\n  geom_hline(yintercept = 0) +\n  geom_violin(alpha = 0.3) +\n  geom_point(\n    data = polAff_trueEffects,\n    mapping = aes(x = polAff, y = trueDeltaDuration),\n    shape = \"circle open\",\n    size = 3.5,\n    stroke = 2,\n    color = \"black\"\n  ) +\n  stat_summary(\n    fun = mean,\n    fun.min = \\(x){mean(x) - sd(x)},\n    fun.max = \\(x){mean(x) + sd(x)},\n    position = position_dodge(width = .9)\n  ) +\n  ggrepel::geom_label_repel(\n    data = polAff_trueEffects,\n    mapping = aes(x = polAff, y = trueDeltaDuration, label = round(trueDeltaDuration, 4)),\n    color = \"black\",\n    box.padding = 1\n  ) +\n  scale_color_manual(values = c(\"red\", \"dodgerblue\")) +\n  scale_y_continuous(breaks = seq(-1, 1, .2)) +\n  labs(title = \"Demo Output of One Simulation for Main Effect\") +\n  theme_bw() +\n  theme(legend.position = \"none\")\n\n\nFigure 2 visualizes the results of this single simulation and Table 1 summarises the statistical results of fitting the actual model used in data generation to the simulated data.\n\n\n\n\n\n\n\n\nFigure 2: Visual representation of results of one simulation created using FUN_sim. Violin plots display the full distribution of the data. Points and surrounding lines indicate the mean ± 1 SD. The black horizontal line displays the true sample mean and the black open circles indicate the true means for each cell.\n\n\n\n\n\n\n\n\nTable 1: Statistical results of one simulation created using FUN_sim. Data was fit using deltaDuration ~ polAff + (1 | subj) + (1 | trial).\n\n\n\n\n\n\n\neffect\ngroup\nterm\nestimate\np.value\n\n\n\n\nfixed\nNA\n(Intercept)\n-0.0188\n0.1105\n\n\nfixed\nNA\npolAff.dem-rep\n0.0896\n0.0000\n\n\nran_pars\nsubj\nsd__(Intercept)\n0.2841\nNA\n\n\nran_pars\ntrial\nsd__(Intercept)\n0.0363\nNA\n\n\nran_pars\nResidual\nsd__Observation\n0.3223\nNA"
  },
  {
    "objectID": "scripts/powerSimulations.html#power-simulation",
    "href": "scripts/powerSimulations.html#power-simulation",
    "title": "Power Simulations for Registered Report",
    "section": "4.2 Power Simulation",
    "text": "4.2 Power Simulation\nWe now simulate multiple random samples drawn from the same synthetic population with a known true effect of political affiliation. For each random sample, we fit our statistical model to the data. The statistical power to detect a true effect of political affiliation is calculated as the proportion of significant effects out of the total number of simulations. We aim for a statistical power of 95%.\nIn the following code, the simulations are calculated. We do not recommend executing this code junk as it takes several hours to run.\n\n\nShow the code\nFUN_sim_pwr &lt;- function(sim, ...){\n  out &lt;- FUN_sim(...)\n  modelResults &lt;- out$modelResults %&gt;% \n    mutate(sim = sim) %&gt;% \n    relocate(sim)\n  return(modelResults)\n}\n\n# How many simulations should be run?\nn_sims &lt;- 1000\n\n# What are the breaks for number of subjects we would like to calculate power for?\nbreaks_subj &lt;- seq(200, 1000, 200)\n\n# What are the breaks for SESOI?\nbreaks_sesoi &lt;- c(0.4/3, 0.4/3.5, 0.4/4)\n\n# What are the breaks for different errer SDs?\nbreaks_sigma &lt;- c(1:2)*(.29+.04)\n\nres_mainEffect &lt;- tibble()\nfor (s in seq_along(breaks_sigma)) {\n  \n  res_sesoi &lt;- tibble()\n  for (sesoi in seq_along(breaks_sesoi)) {\n    \n    res_nSubj &lt;- tibble()\n    for (nSubj in seq_along(breaks_subj)) {\n      \n      # Give feedback regarding which model is simulated\n      cat(paste0(\n        \"Simulation:\\n\",\n        \"  sigma = \", round(breaks_sigma[s], 4), \"\\n\",\n        \"  sesoi = \", round(breaks_sesoi[sesoi], 4), \"\\n\",\n        \"  nSubject = \", breaks_subj[nSubj], \"\\n\"\n      ))\n      \n      # Start timer\n      cat(paste0(\"Start date time: \", lubridate::now(), \"\\n\"))\n      tic()\n      \n      # Loop over simulations\n      pwr &lt;- map_df(\n        1:n_sims, \n        FUN_sim_pwr,\n        n_subj = breaks_subj[nSubj],\n        beta_p = breaks_sesoi[sesoi],\n        sigma = breaks_sigma[s]\n      )\n      \n      # Stop timer and calculate elapsed time\n      elapsed_time &lt;- toc(quiet = TRUE)\n      elapsed_seconds &lt;- elapsed_time$toc - elapsed_time$tic\n      elapsed_minutes &lt;- elapsed_seconds / 60\n      cat(paste0(\"End date time: \", lubridate::now(), \"\\n\"))\n      cat(\"Elapsed time: \", elapsed_minutes, \" minutes\\n\\n\")\n      \n      # Add number of subjects to pwr\n      pwr &lt;- pwr %&gt;% \n        mutate(\n          nSubjects = breaks_subj[nSubj],\n          sesoi = breaks_sesoi[sesoi],\n          sigma = breaks_sigma[s]\n        )\n      \n      # Add results to the results table\n      res_nSubj &lt;- res_nSubj %&gt;%\n        rbind(pwr)\n    }\n    \n    # Add results to the results table\n    res_sesoi &lt;- res_sesoi %&gt;% \n      rbind(res_nSubj)\n  }\n  \n  # Add results to the results table\n  res_mainEffect &lt;- res_mainEffect %&gt;% \n    rbind(res_sesoi)\n  \n}\n\nres_mainEffect.summary &lt;- res_mainEffect %&gt;% \n  filter(term == \"polAff.dem-rep\") %&gt;% \n  group_by(sigma, sesoi, nSubjects) %&gt;% \n  summarise(\n    power = mean(p.value &lt; 0.05),\n    ci.lower = binom.confint(power*n_sims, n_sims, methods = \"exact\")$lower,\n    ci.upper = binom.confint(power*n_sims, n_sims, methods = \"exact\")$upper,\n    .groups = 'drop'\n  ) %&gt;% \n  mutate(\n    sigma_fact = factor(format(round(sigma, 4), nsmall = 4)),\n    sigma_level = match(sigma_fact, levels(sigma_fact)),\n    sesoi_fact = factor(format(round(sesoi, 4), nsmall = 4)),\n    sesoi_level = match(sesoi_fact, levels(sesoi_fact))\n  )\n\n# Save results in a list object\ntime &lt;- format(Sys.time(), \"%Y%m%d_%H%M\")\nfileName &lt;- paste0(\"res_mainEffect\", \"_\", time, \".RDS\")\nsaveRDS(\n  list(\n    res_mainEffect = res_mainEffect,\n    res_mainEffect.summary = res_mainEffect.summary\n  ),\n  file = file.path(\"../powerSimulationsOutput\", fileName)\n)\n\n\nWe retrieve pre-run results:\n\n\nShow the code\n# Load power simulation data\nresList_mainEffect &lt;- readRDS(file.path(\"../powerSimulationsOutput\", \"res_mainEffect_20240813_2141.RDS\"))\nresList_mainEffect.summary &lt;- resList_mainEffect$res_mainEffect.summary\n\n# Extract power values for some specific effect sizes at N = 1000\nchosenN &lt;- 600\nchosenSigma &lt;- c(\"0.3300\", \"0.6600\")\nchosenSESOI &lt;- c(\"0.1000\", \"0.1143\")\npowerValues &lt;- resList_mainEffect.summary %&gt;% \n  filter(sigma_fact %in% chosenSigma) %&gt;% \n  filter(sesoi_fact %in% chosenSESOI) %&gt;% \n  filter(nSubjects %in% chosenN) %&gt;% \n  mutate(power_str = paste0(round(ci.lower*100, 2), \"%\")) %&gt;% \n  pull(power_str)\n\n# Extract number of simulations\nlabel_nSimulations &lt;- resList_mainEffect$res_mainEffect$sim %&gt;% n_distinct()\n\n\nFigure 3 displays the distribution of estimated fixed effects across all simulations. The figure shows that the estimated fixed effects are close to the true ones provided as input in the data simulation function, validating that simulations worked as expected.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: Distribution of estimated fixed effects resulting from 1000 simulations for the model deltaDuration ~ polAff + (1 | subj) + (1 | trial). Shaded area represent densities, annotated points indicate medians, and thick and thin lines represent 66% and 95% quantiles.\n\n\n\nFigure 4 shows results of our sample-size determination analyses. We find that a sample size of 600 provides a statistical power of 95.4% (lower bound of 95%-CI) even under the most conservative assumptions (SESOI = 0.1000, Error SD = 0.6600).\nWe optimize the study design to detect a true SESOI for political affiliation. However, we are also interested in two-way and three-way interaction effects, which are known to require greater sample sizes to achieve the same statistical power as for main effects. Moreover, greater sample sizes are more likely to accurately represent target populations with respect to variables like exposure to extreme weather events and subjective attribution of extreme weather events to climate change. Therefore, we opt for a sample size of N = 1000 for further effect-size sensitivity analyses regarding interaction effects.\n\n\n\n\n\n\n\n\nFigure 4: Power curves for the main effect of polAff. Points represent statistical power surrounded by a 95%-CI based on 1000 simulations with α = 0.05."
  },
  {
    "objectID": "scripts/powerSimulations.html#sec-SESOI_2wayInt",
    "href": "scripts/powerSimulations.html#sec-SESOI_2wayInt",
    "title": "Power Simulations for Registered Report",
    "section": "5.1 SESOI for Two-Way Interaction",
    "text": "5.1 SESOI for Two-Way Interaction\nFor deriving a SESOI for the two-way interaction of interest, similar considerations apply as in the case of the SESOI for the main effect of interest. In this section, we make these considerations explicit. We start by noticing that the complete fixed two-way interaction polAff × ewe is modeled as:\n\\[\n\\Delta Duration = \\beta_{0} + \\beta_{1} \\cdot polAff + \\beta_{2} \\cdot ewe  + \\beta_{3} \\cdot (polAff \\times ewe)\n\\]\nBy rearranging terms, one can show that the effect of polAff is given by:\n\\[\nEffect_{polAff} = \\beta_{1} + \\beta_{3} \\cdot ewe\n\\]\nNow, let’s calculate this effect for two individuals who differ in their levels of ewe. As ewe is a binary variable, we have two types of individuals: individuals with (ewe = 1) and without (ewe = 0) extreme weather exposure. For an individual without extreme weather exposure, the effect of polAff will be:\n\\[\nEffect_{noEWE} = \\beta_{1} + \\beta_{3} \\cdot 0 = \\beta_{1}\n\\]\nFor an individual with extreme weather exposure, the effect of polAff will be:\n\\[\nEffect_{EWE} = \\beta_{1} + \\beta_{3} \\cdot 1 = \\beta_{1} + \\beta_{3}\n\\]\nThe difference in the effect of polAff between these two individuals is given by:\n\\[\n\\begin{split}\nEffect_{EWE} - Effect_{noEWE} = (\\beta_{1} + \\beta_{3}) - \\beta_{1} = \\beta_{3}\n\\end{split}\n\\]\nWe consider this difference as theoretically relevant if it is at least of the same size as the SESOI for the effect of polAff:\n\\[\nSESOI_{polAff \\times ewe} = Effect_{EWE} - Effect_{noEWE} = SESOI_{polAff} = 0.1143\n\\]"
  },
  {
    "objectID": "scripts/powerSimulations.html#data-simulation-function-1",
    "href": "scripts/powerSimulations.html#data-simulation-function-1",
    "title": "Power Simulations for Registered Report",
    "section": "5.2 Data Simulation Function",
    "text": "5.2 Data Simulation Function\nWe next define a function that simulates data for the two-way interaction effect of political affiliation with extreme weather exposure on ΔDuration: FUN_sim_2wayInt. The function will simulate data according to the following model, expressed in lme4-lingo:\ndeltaDuration ~ polAff * ewe + (1|subj) + (1|trial)\nThe function FUN_sim_2wayInt takes, among others, the following important arguments (in addition to the arguments discussed for FUN_sim):\n\nbeta_p: Fixed main effect of political affiliation. Compatible with H1, we keep this value at the SESOI of 0.1143. That is, we model that the average effect of political affiliation across all participants, irrespective of their extreme weather exposure, is 0.1143.\nbeta_e: Fixed main effect of extreme weather exposure. As we are interested in the moderating role of extreme weather exposure, we set this main effect to zero. That is, we assume that the effect of extreme weather exposure is highly dependent on participants’ political affiliation.\nbeta_p_e_inx: Fixed two-way interaction effect of political affiliation and extreme weather exposure. We set this initial value to the SESOI derived above, but we investigate how changing this effect size impacts statistical power, as we are conducting effect-size sensitivity analyses for interaction effects.\n\nThe function FUN_sim_2wayInt is defined below:\n\n\nShow the code\n# define data simulation function\nFUN_sim_2wayInt &lt;- function(\n  n_subj         =        1000, # number of subjects\n  n_subj_prop_p  =   c(.5, .5), # proportion of republican and democrat subjects\n  n_subj_prop_e  =   c(.5, .5), # proportion of subjects without and with extreme weather exposure\n  n_trial        =          25, # number of trials\n  beta_0         =           0, # intercept (grand mean) for deltaDuration\n  beta_p         =     0.4/3.5, # main effect of political affiliation (polAff)\n  beta_e         =           0, # main effect of extreme weather exposure (ewe)\n  beta_p_e_inx   =     0.4/3.5, # two-way interaction effect of polAff and ewe\n  subj_0         =         .29, # by-subject random intercept sd for dt carbon\n  trial_0        =         .04, # by-trial random intercept sd\n  sigma          = 1*(.29+.04), # residual (error) sd\n  \n  truncNums      =        TRUE, # should impossible numbers be truncuated?\n  setSeed        =        NULL  # seed number to achieve reproducible results. Set to NULL for simulations!\n) {\n  \n  # set seed to achieve reproducible results for demonstration purposes\n  set.seed(setSeed)\n  \n  # simulate data for dwell time on carbon information\n  dataSim &lt;- \n    # add random factor subject\n    add_random(subj = n_subj) %&gt;% \n    # add random factor trial\n    add_random(trial = n_trial) %&gt;% \n    # add between-subject factor political affiliation (with anova contrast)\n    add_between(\"subj\", polAff = c(\"rep\", \"dem\"), .prob = n_subj_prop_p*n_subj, .shuffle = TRUE) %&gt;% \n    add_contrast(\"polAff\", colnames = \"X_p\", contrast = \"anova\") %&gt;% \n    # add between-subject factor extreme weather exposure (with anova contrast)\n    add_between(\"subj\", ewe = c(FALSE, TRUE), .prob = n_subj_prop_e*n_subj, .shuffle = TRUE) %&gt;% \n    add_contrast(\"ewe\", colnames = \"X_e\", contrast = \"anova\") %&gt;% \n    # add by-subject random intercept\n    add_ranef(\"subj\", S_0 = subj_0) %&gt;% \n    # add by-trial random intercept\n    add_ranef(\"trial\", T_0 = trial_0) %&gt;% \n    # add error term\n    add_ranef(e_st = sigma) %&gt;% \n    # add response values\n    mutate(\n      # add together fixed and random effects for each effect\n      B_0 = beta_0 + S_0 + T_0,\n      B_p = beta_p,\n      B_e = beta_e,\n      B_p_e_inx = beta_p_e_inx,\n      # calculate dv by adding each effect term multiplied by the relevant\n      # effect-coded factors and adding the error term\n      deltaDuration = \n        B_0 + e_st +\n        (X_p * B_p) +\n        (X_e * B_e) +\n        (X_p * X_e * B_p_e_inx)\n    )\n  \n  # truncuate impossible deltaDurations\n  if(truncNums) {\n    dataSim &lt;- dataSim %&gt;% \n      mutate(deltaDuration = if_else(deltaDuration &lt; -1, -1,\n        if_else(deltaDuration &gt; 1, 1, deltaDuration)))\n  }\n  \n  # run a linear mixed effects model and check summary\n  mod &lt;- lmer(\n    deltaDuration ~ polAff*ewe + (1 | subj) + (1 | trial),\n    data = dataSim\n  )\n  mod.sum &lt;- summary(mod)\n  \n  # get results in tidy format\n  mod.broom &lt;- broom.mixed::tidy(mod)\n  \n  return(list(\n    dataSim = dataSim,\n    modelLmer = mod,\n    modelResults = mod.broom\n  ))\n  \n}\n\n\nWe call the function once and extract the results of this single simulation:\n\n\nShow the code\nout &lt;- FUN_sim_2wayInt(\n  n_subj         =        1000, # number of subjects\n  n_subj_prop_p  =   c(.5, .5), # proportion of republican and democrat subjects\n  n_subj_prop_e  =   c(.5, .5), # proportion of subjects without and with extreme weather exposure\n  n_trial        =          25, # number of trials\n  beta_0         =           0, # intercept (grand mean) for deltaDuration\n  beta_p         =     0.4/3.5, # main effect of political affiliation (polAff)\n  beta_e         =           0, # main effect of extreme weather exposure (ewe)\n  beta_p_e_inx   =     0.4/3.5, # two-way interaction effect of polAff and ewe\n  subj_0         =         .29, # by-subject random intercept sd for dt carbon\n  trial_0        =         .04, # by-trial random intercept sd\n  sigma          = 1*(.29+.04), # residual (error) sd\n  \n  truncNums      =        TRUE, # should impossible numbers be truncuated?\n  setSeed        =        1234  # seed number to achieve reproducible results. Set to NULL for simulations!\n)\n\n# Get results table\nresultsTable &lt;- out$modelResults %&gt;% \n  select(-c(std.error, statistic, df)) %&gt;% \n  mutate(across(where(is_double), ~ round(.x, 4))) %&gt;% \n  knitr::kable()\nformulaUsedForFit &lt;- paste(as.character(formula(out$modelLmer))[c(2,1,3)], collapse = \" \")\n\n# Create plot\np.demo.2wayInt &lt;-  out$dataSim %&gt;% \n  ggplot(aes(x = ewe, y = deltaDuration, color = polAff)) +\n  geom_hline(yintercept = 0) +\n  geom_violin(alpha = 0.3) +\n  geom_point(\n    data = polAff_ewe_trueEffects,\n    mapping = aes(x = ewe, y = trueDeltaDuration, fill = polAff),\n    shape = \"circle open\",\n    size = 3.5,\n    stroke = 2,\n    color = \"black\",\n    position = position_dodge(width = .9),\n    show.legend = FALSE\n  ) +\n  stat_summary(\n    fun = mean,\n    fun.min = \\(x){mean(x) - sd(x)},\n    fun.max = \\(x){mean(x) + sd(x)},\n    position = position_dodge(width = .9)\n  ) +\n  ggrepel::geom_label_repel(\n    data = polAff_ewe_trueEffects,\n    mapping = aes(x = ewe, y = trueDeltaDuration, fill = polAff, label = round(trueDeltaDuration, 4)),\n    color = \"black\",\n    box.padding = 1,\n    position = position_dodge(width = .9),\n    show.legend = FALSE\n  ) +\n  scale_color_manual(values = c(\"red\", \"dodgerblue\")) +\n  scale_fill_manual(values = c(\"white\", \"white\")) +\n  scale_y_continuous(breaks = seq(-1, 1, .2)) +\n  labs(title = \"Demo Output of One Simulation for Two-Way Interaction\") +\n  theme_bw()\n\n\nFigure 5 visualizes the results of this single simulation and Table 2 summarizes the statistical results of fitting the actual model used in data generation to the simulated data.\n\n\n\n\n\n\n\n\nFigure 5: Visual representation of results of one simulation created using FUN_sim_2wayInt. Violin plots display the full distribution of the data. Points and surrounding lines indicate the mean ± 1 SD. The black horizontal line displays the true sample mean and the black open circles indicate the true means for each cell.\n\n\n\n\n\n\n\n\nTable 2: Statistical results of one simulation created using FUN_sim_2wayInt. Data was fit using deltaDuration ~ polAff * ewe + (1 | subj) + (1 | trial).\n\n\n\n\n\n\n\neffect\ngroup\nterm\nestimate\np.value\n\n\n\n\nfixed\nNA\n(Intercept)\n-0.0006\n0.9625\n\n\nfixed\nNA\npolAff.dem-rep\n0.1290\n0.0000\n\n\nfixed\nNA\newe.TRUE-FALSE\n-0.0139\n0.4516\n\n\nfixed\nNA\npolAff.dem-rep:ewe.TRUE-FALSE\n0.1398\n0.0002\n\n\nran_pars\nsubj\nsd__(Intercept)\n0.2855\nNA\n\n\nran_pars\ntrial\nsd__(Intercept)\n0.0382\nNA\n\n\nran_pars\nResidual\nsd__Observation\n0.3232\nNA"
  },
  {
    "objectID": "scripts/powerSimulations.html#power-simulation-1",
    "href": "scripts/powerSimulations.html#power-simulation-1",
    "title": "Power Simulations for Registered Report",
    "section": "5.3 Power Simulation",
    "text": "5.3 Power Simulation\nIn the following code, the simulations are calculated. We do not recommend executing this code junk as it takes several hours to run.\n\n\nShow the code\nFUN_sim_2wayInt_pwr &lt;- function(sim, ...){\n  out &lt;- FUN_sim_2wayInt(...)\n  modelResults &lt;- out$modelResults %&gt;% \n    mutate(sim = sim) %&gt;% \n    relocate(sim)\n  return(modelResults)\n}\n\n# How many simulations should be run?\nn_sims &lt;- 1000\n\n# What are the breaks for number of subjects we would like to calculate power for?\nbreaks_subj &lt;- c(900, 950, 1000)\n\n# What are the breaks for SESOI?\nbreaks_sesoi &lt;- (0.4/3.5)*seq(1, 2, .25)\n\n# What are the breaks for different error SDs?\nbreaks_sigma &lt;- c((.29+.04), 2*(.29+.04))\n\nres_2wayInt &lt;- tibble()\nfor (s in seq_along(breaks_sigma)) {\n  \n  res_sesoi &lt;- tibble()\n  for (sesoi in seq_along(breaks_sesoi)) {\n    \n    res_nSubj &lt;- tibble()\n    for (nSubj in seq_along(breaks_subj)) {\n      \n      # Give feedback regarding which model is simulated\n      cat(paste0(\n        \"Simulation:\\n\",\n        \"  sigma = \", round(breaks_sigma[s], 4), \"\\n\",\n        \"  sesoi = \", round(breaks_sesoi[sesoi], 4), \"\\n\",\n        \"  nSubject = \", breaks_subj[nSubj], \"\\n\"\n      ))\n      \n      # Start timer\n      cat(paste0(\"Start date time: \", lubridate::now(), \"\\n\"))\n      tic()\n      \n      # Loop over simulations\n      pwr &lt;- map_df(\n        1:n_sims, \n        FUN_sim_2wayInt_pwr,\n        n_subj = breaks_subj[nSubj],\n        beta_p_e_inx = breaks_sesoi[sesoi],\n        sigma = breaks_sigma[s]\n      )\n      \n      # Stop timer and calculate elapsed time\n      elapsed_time &lt;- toc(quiet = TRUE)\n      elapsed_seconds &lt;- elapsed_time$toc - elapsed_time$tic\n      elapsed_minutes &lt;- elapsed_seconds / 60\n      cat(paste0(\"End date time: \", lubridate::now(), \"\\n\"))\n      cat(\"Elapsed time: \", elapsed_minutes, \" minutes\\n\\n\")\n      \n      # Add number of subjects to pwr\n      pwr &lt;- pwr %&gt;% \n        mutate(\n          nSubjects = breaks_subj[nSubj],\n          sesoi = breaks_sesoi[sesoi],\n          sigma = breaks_sigma[s]\n        )\n      \n      # Add results to the results table\n      res_nSubj &lt;- res_nSubj %&gt;%\n        rbind(pwr)\n    }\n    \n    # Add results to the results table\n    res_sesoi &lt;- res_sesoi %&gt;% \n      rbind(res_nSubj)\n  }\n  \n  # Add results to the results table\n  res_2wayInt &lt;- res_2wayInt %&gt;% \n    rbind(res_sesoi)\n  \n}\n\nres_2wayInt.summary &lt;- res_2wayInt %&gt;% \n  filter(term == \"polAff.dem-rep:ewe.TRUE-FALSE\") %&gt;% \n  group_by(sigma, sesoi, nSubjects) %&gt;% \n  summarise(\n    power = mean(p.value &lt; 0.05),\n    ci.lower = binom.confint(power*n_sims, n_sims, methods = \"exact\")$lower,\n    ci.upper = binom.confint(power*n_sims, n_sims, methods = \"exact\")$upper,\n    .groups = 'drop'\n  ) %&gt;% \n  mutate(\n    sigma_fact = factor(format(round(sigma, 4), nsmall = 4)),\n    sigma_level = match(sigma_fact, levels(sigma_fact)),\n    sesoi_fact = factor(format(round(sesoi, 4), nsmall = 4)),\n    sesoi_level = match(sesoi_fact, levels(sesoi_fact))\n  )\n\n# Save results in a list object\ntime &lt;- format(Sys.time(), \"%Y%m%d_%H%M\")\nfileName &lt;- paste0(\"res_2wayInt\", \"_\", time, \".RDS\")\nsaveRDS(\n  list(\n    res_2wayInt = res_2wayInt,\n    res_2wayInt.summary = res_2wayInt.summary\n  ),\n  file = file.path(\"../powerSimulationsOutput\", fileName)\n)\n\n\nWe retrieve pre-run results:\n\n\nShow the code\n# Load power simulation data\nresList_2wayInt &lt;- readRDS(file.path(\"../powerSimulationsOutput\", \"res_2wayInt_20240814_1052.RDS\"))\nresList_2wayInt.summary &lt;- resList_2wayInt$res_2wayInt.summary\n\n# Extract power values for some specific assumptions\nchosenN &lt;- 950\nchosenSigma &lt;- c(\"0.3300\", \"0.6600\")\nchosenSESOI &lt;- c(\"0.1429\", \"0.1714\")\npowerValues &lt;- resList_2wayInt.summary %&gt;% \n  filter(sigma_fact %in% chosenSigma) %&gt;% \n  filter(sesoi_fact %in% chosenSESOI) %&gt;% \n  filter(nSubjects %in% chosenN) %&gt;% \n  mutate(power_str = paste0(round(power*100, 2), \"%\")) %&gt;% \n  pull(power_str)\n\n# Extract number of simulations\nlabel_nSimulations &lt;- resList_2wayInt$res_2wayInt$sim %&gt;% n_distinct()\n\n# Repeat breaks_sesoi\nbreaks_sesoi &lt;- (0.4/3.5)*seq(1, 2, .25)\n\n\nFigure 6 displays the distribution of estimated fixed effects across all simulations. The figure shows that the estimated fixed effects are close to the true ones provided as input in the data simulation function, validating that simulations worked as expected.\n\nShow the code\n# Define some filters \nfilter_nSubjects &lt;- 1000\nfilter_sesoi &lt;- unique(resList_2wayInt$res_2wayInt$sesoi)[1]\nfilter_sigma &lt;- unique(resList_2wayInt$res_2wayInt$sigma)[1]\n\n# Prepare data for plot\nfixedEstimates &lt;- resList_2wayInt$res_2wayInt %&gt;% \n  mutate(\n    group = ifelse(is.na(group), \"\", group),\n    group_term = str_remove(str_c(group, term, sep = \"_\"), \"^_\")\n  ) %&gt;% \n  filter(effect == \"fixed\") %&gt;% \n  filter(nSubjects == filter_nSubjects) %&gt;% \n  filter(sesoi == filter_sesoi) %&gt;% \n  filter(sigma == filter_sigma)\nfixedEstimates_medians &lt;- fixedEstimates %&gt;% \n  group_by(group_term) %&gt;% \n  summarise(\n    median = median(estimate, na.rm = TRUE),\n    median_rounded = format(round(median, 4), nsmall = 4, scientific = FALSE),\n    .groups = 'drop'\n  )\n\n# Create plot\np.checkSims.2wayInt &lt;-fixedEstimates %&gt;% \n  ggplot(aes(x = estimate, y = group_term)) +\n  ggdist::stat_halfeye() +\n  ggrepel::geom_label_repel(\n    data = fixedEstimates_medians,\n    mapping = aes(x = median, y = group_term, label = median_rounded),\n    box.padding = .5\n  ) +\n  labs(\n    title = \"Distribution of Estimated Fixed Effects\",\n    subtitle = paste0(\n      \"SESOI = \", round(filter_sesoi, 4), \", \",\n      \"σ = \", round(filter_sigma, 4), \", \",\n      \"N = \", filter_nSubjects, \", \",\n      \"Number of Simulations = \", label_nSimulations\n    ),\n    x = \"Estimate\",\n    y = \"Term\"\n  ) +\n  theme_bw()\n\nprint(p.checkSims.2wayInt)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 6: Distribution of estimated fixed effects resulting from 1000 simulations for the model deltaDuration ~ polAff * ewe + (1 | subj) + (1 | trial). Shaded area represent densities, annotated points indicate medians, and thick and thin lines represent 66% and 95% quantiles.\n\n\n\nFigure 7 shows results of our effect-size sensitivity analyses. We plot statistical power (y-axis) for different effect sizes (x-axis), taking into account different assumptions for the error SD (color) and sample size (panel). Regarding the latter, we report results not only for the full sample size we aim for (N = 1000), but also for sample sizes taking into account different participant exclusion-rates due to exclusion criteria defined in the Registered Report.\n\n\n\n\n\n\n\n\nFigure 7: Power curves for the two-way interaction polAff × ewe. Points represent simulated power surrounded by a 95%-CI based on 1000 simulations with α = 0.05. Note that, in contrast to Figure 4, the x-axsis represents different effect sizes, starting from the defined SESOI, while the panels represent different sample sizes, taking into account participant exclusion-rates of 10% (N = 900), 5% (N = 950), and 0% (N = 1000). Note that estimates are displayed with a slight shift along the x-axis to reduce overlap.\n\n\n\n\n\n\n\nShow the code\n# Get power values of interest\nchosenN &lt;- 950\nchosenSigma &lt;- c(\"0.3300\", \"0.6600\")\nchosenSESOI &lt;- c(\"0.1429\", \"0.1714\")\npowerValues &lt;- resList_2wayInt.summary %&gt;% \n  filter(sigma_fact %in% chosenSigma) %&gt;% \n  filter(sesoi_fact %in% chosenSESOI) %&gt;% \n  filter(nSubjects %in% chosenN)\n\n# Get lower CI for power values for more liberal and more conservative sigma assumptions\npowerValues_sigmaLib &lt;- powerValues %&gt;% \n  filter(sigma_fact == \"0.3300\")\npowerValues_sigmaCons &lt;- powerValues %&gt;% \n  filter(sigma_fact == \"0.6600\")\n\n# Interpolate the effect sizes at which we achieve 95% power\neff_sigmaLib &lt;- approx(powerValues_sigmaLib$ci.lower, powerValues_sigmaLib$sesoi, xout = 0.95)$y\neff_sigmaCons &lt;- approx(powerValues_sigmaCons$ci.lower, powerValues_sigmaCons$sesoi, xout = 0.95)$y\n# Round results for display in text\neff_sigmaLib_txt &lt;- format(round(eff_sigmaLib, 4), nsmall = 4)\neff_sigmaCons_txt &lt;- format(round(eff_sigmaCons, 4), nsmall = 4)\n\n\nTo assess the smallest effect size that can be detected with 95% statistical power, we inspect the lower bounds of the 95%-CI power estimates in Figure 7. Specifically, we focus on the power simulation results for N = 950, which takes into account a participant exclusion-rate of 5%. There, we interpolate between the two point estimates that lie just below and above the 95% power line, i.e., between the power estimates for effect sizes 0.1429 and 0.1714. Assuming an error SD of 0.3300, we achieve 95% statistical power to detect a two-way interaction effect of at least 0.1530. For a more conservative error SD of 0.6600, this smallest detectable effect size is only marginally higher (0.1619)."
  },
  {
    "objectID": "scripts/powerSimulations.html#sesoi-for-three-way-interaction",
    "href": "scripts/powerSimulations.html#sesoi-for-three-way-interaction",
    "title": "Power Simulations for Registered Report",
    "section": "6.1 SESOI for Three-way Interaction",
    "text": "6.1 SESOI for Three-way Interaction\nIn the sections above, we derived the SESOI used for the main effect sample-size determination analysis and for the two-way interaction effect-size sensitivity analysis for the binary variables polAff (dem vs. rep) and ewe (TRUE vs. FALSE). subjAttr, however, is a continuous variable that ranges from 1 to 5. Fortunately, in finding a theoretically sound SESOI for the three-way interaction, the same considerations apply as for the main effect and two-way interaction before. We just need to translate these considerations into the continuous metric of subjAttr.\nWe start by noticing that the complete fixed three-way interaction polAff × ewe × subjAttr is modeled as:\n\\[\n\\begin{split}\n\\Delta Duration = \\beta_{0} + \\\\\n\\beta_{1} \\cdot polAff + \\beta_{2} \\cdot ewe + \\beta_{3} \\cdot subjAttr + \\\\\n\\beta_{4} \\cdot (polAff \\times ewe) + \\beta_{5} \\cdot (polAff \\times subjAttr) + \\beta_{6} \\cdot (ewe \\times subjAttr) + \\\\\n\\beta_{7} \\cdot (polAff \\times ewe \\times subjAttr)\n\\end{split}\n\\]\nBy rearranging terms, one can show that the two-way interaction polAff × ewe is given by:\n\\[\nTwo{-}way\\ Interaction_{polAff \\times ewe} = \\beta_{4} + \\beta_{7} \\cdot subjAttr\n\\]\nNow, let’s calculate this two-way interaction for two individuals who differ in their level of subjective attribution of extreme weather events to climate change. First, an individual who has an average score on subjAttr will show the following two-way interaction effect, with \\(\\mu_{subjAttr}\\) being the sample average of the variable subjAttr:\n\\[\nEffect_{Avg} = \\beta_{4} + \\beta_{7} \\cdot \\mu_{subjAttr}\n\\]\nSecond, we define an individual with a low score on subjAttr as one that shows a subjective attribution of one SD bellow the average. This individual will show the following two-way interaction effect, with \\(\\sigma_{subjAttr}\\) being the SD of subjAttr:\n\\[\nEffect_{Low} = \\beta_{4} + \\beta_{7} \\cdot (\\mu_{subjAttr} - \\sigma_{subjAttr})\n\\]\nThe difference in the two-way interaction effect polAff × ewe between these two individuals is given by:\n\\[\n\\begin{split}\nEffect_{Avg} - Effect_{Low} = \\\\\n\\beta_{4} + \\beta_{7} \\cdot \\mu_{subjAttr} - (\\beta_{4} + \\beta_{7} \\cdot (\\mu_{subjAttr} - \\sigma_{subjAttr})) = \\\\\n\\beta_{7} \\cdot [\\mu_{subjAttr} - (\\mu_{subjAttr} - \\sigma_{subjAttr})] = \\\\\n\\beta_{7} \\cdot \\sigma_{subjAttr}\n\\end{split}\n\\]\nAs outlined above in Section Section 5.1, we assume that the SESOI for the two-way interaction polAff × ewe is 0.1143 for an average individual (with respect to subjAttr). If the same two-way interaction polAff × ewe shrinks to zero for an individual low in subjAttr, we would consider this interaction effect difference as theoretically relevant (see Figure 8). These assumptions translate to:\n\\[\nEffect_{Avg} - Effect_{Low} = 0.1143 = \\beta_{7} \\cdot \\sigma_{subjAttr}\n\\]\nDivision by \\(\\sigma_{subjAttr}\\) gives us the SESOI for the three-way interaction in the suitable metric of subjAttr:\n\\[\nSESOI_{polAff \\times ewe \\times subjAttr} = \\frac{0.1143}{\\sigma_{subjAttr}}\n\\]\nWe will assess subjective attribution of extreme weather events to climate change using the same questions, response options, and aggregation as Ogunbode et al. (2019). These authors reported \\(\\mu_{subjAttr}\\) = 3.67 and \\(\\sigma_{subjAttr}\\) = 0.85, resulting in:\n\\[\nSESOI_{polAff \\times ewe \\times subjAttr} = \\frac{0.1143}{0.85} = 0.1345\n\\]\n\n\n\n\n\n\n\n\nFigure 8: Assumed ΔDuration values for individuals scoring low (-SD) and average (M) on subjAttr. While individuals scoring average on subjAttr show a two-way interaction effect of polAff × ewe of 0.1143, this effect shrinks to zero for individuals scoring low on subjAttr. These individuals only show the predicted main effect of polAff (whis is 0.1143)."
  },
  {
    "objectID": "scripts/powerSimulations.html#data-simulation-function-2",
    "href": "scripts/powerSimulations.html#data-simulation-function-2",
    "title": "Power Simulations for Registered Report",
    "section": "6.2 Data Simulation Function",
    "text": "6.2 Data Simulation Function\nWe finally define a function that simulates data for the three-way interaction effect of political affiliation with extreme weather exposure and attribution of extreme weather events to climate change on ΔDuration: FUN_sim_3wayInt. The function will simulate data according to the following model, expressed in lme4-lingo:\ndeltaDuration ~ polAff * ewe * subjAttr + (1|subj) + (1|trial)\nThe function FUN_sim_3wayInt takes, among others, the following important arguments (in addition to the arguments discussed for FUN_sim_2wayInt):\n\ns_mean: Sample mean of subjective attribution. Based on results reported by Ogunbode et al. (2019), we set this value to 3.67.\ns_sd: Sample SD of subjective attribution. Based on results reported by Ogunbode et al. (2019), we set this value to 0.85.\nbeta_s: Fixed main effect of subjective attribution. As we are interested in the moderating role of subjective attribution of extreme weather events to climate change, we set this main effect to zero.\nbeta_p_s_inx Fixed two-way interaction effect of political affiliation and subjective attribution. In order to accurately model a three-way interaction, one needs to include all two-way interactions in statistical models. Therefore, we include this two-way interaction, but we assume it to be zero.\nbeta_e_s_inx Fixed two-way interaction effect of extreme weather exposure and subjective attribution. As before, we include this interaction for accurately modelling the three-way interaction of interest, but we assume this two-way interaction to be zero.\nbeta_p_e_s_inx Fixed three-way interaction effect of political affiliation, extreme weather exposure, and subjective attribution. We set this initial value to the SESOI derived above, i.e. 0.1345. We investigate how changing this effect size impacts statistical power, as we are conducting effect-size sensitivity analyses for interaction effects.\n\nThe function is defined below:\n\n\nShow the code\n# define data simulation function\nFUN_sim_3wayInt &lt;- function(\n  n_subj         =                1000, # number of subjects\n  n_subj_prop_p  =           c(.5, .5), # proportion of republican and democrat subjects\n  n_subj_prop_e  =           c(.5, .5), # proportion of subjects without and with extreme weather exposure\n  n_subj_prop_s  =           c(.5, .5), # proportion of subjects with low and high subjective attribution of EWE to CC\n  n_trial        =                  25, # number of trials\n  s_mean         =                3.67, # mean of subjAttr, see Ogunbode et al. (2019)\n  s_sd           =                0.85, # sd of subjAttr, see Ogunbode et al. (2019)\n  beta_0         =                   0, # intercept (grand mean) for deltaDuration\n  beta_p         =             0.4/3.5, # main effect of political affiliation (polAff)\n  beta_e         =                   0, # main effect of extreme weather exposure (ewe)\n  beta_s         =                   0, # main effect of subjective attribution of ewe to climate change (subjAttr)\n  beta_p_e_inx   =             0.4/3.5, # two-way interaction effect of polAff and ewe\n  beta_p_s_inx   =                   0, # two-way interaction effect of polAff and subjAttr\n  beta_e_s_inx   =                   0, # two-way interaction effect of ewe and subjAttr\n  beta_p_e_s_inx =      (0.4/3.5)/0.85, # three-way interaction effect of polAff, ewe, and subjAttr\n  subj_0         =                 .29, # by-subject random intercept sd for dt carbon\n  trial_0        =                 .04, # by-trial random intercept sd\n  sigma          =         1*(.29+.04), # residual (error) sd\n  \n  truncNums      =                TRUE, # should impossible numbers be truncuated?\n  setSeed        =                NULL  # seed number to achieve reproducible results. Set to NULL for simulations!\n) {\n  \n  # set seed to achieve reproducible results for demonstration purposes\n  set.seed(setSeed)\n  \n  # simulate data for dwell time on carbon information\n  dataSim &lt;- \n    # add random factor subject\n    add_random(subj = n_subj) %&gt;% \n    # add random factor trial\n    add_random(trial = n_trial) %&gt;% \n    # add between-subject factor political affiliation (with anova contrast)\n    add_between(\"subj\", polAff = c(\"rep\", \"dem\"), .prob = n_subj_prop_p*n_subj, .shuffle = TRUE) %&gt;% \n    add_contrast(\"polAff\", colnames = \"X_p\", contrast = \"anova\") %&gt;% \n    # add between-subject factor extreme weather exposure (with anova contrast)\n    add_between(\"subj\", ewe = c(FALSE, TRUE), .prob = n_subj_prop_e*n_subj, .shuffle = TRUE) %&gt;% \n    add_contrast(\"ewe\", colnames = \"X_e\", contrast = \"anova\") %&gt;% \n    # add between-subject variable subjective attribution of EWE to climate change\n    mutate(\n      subjAttr = rep(rnorm(n = n_subj, mean = s_mean, sd = s_sd), each = n_trial),\n      subjAttr_c = scale(subjAttr, center = TRUE, scale = FALSE)[,1]\n    ) %&gt;% \n    # add by-subject random intercept\n    add_ranef(\"subj\", S_0 = subj_0) %&gt;% \n    # add by-trial random intercept\n    add_ranef(\"trial\", T_0 = trial_0) %&gt;% \n    # add error term\n    add_ranef(e_st = sigma) %&gt;% \n    # add response values\n    mutate(\n      # add together fixed and random effects for each effect\n      B_0 = beta_0 + S_0 + T_0,\n      B_p = beta_p,\n      B_e = beta_e,\n      B_s = beta_s,\n      B_p_e_inx = beta_p_e_inx,\n      B_p_s_inx = beta_p_s_inx,\n      B_e_s_inx = beta_e_s_inx,\n      B_p_e_s_inx = beta_p_e_s_inx,\n      # calculate dv by adding each effect term multiplied by the relevant\n      # effect-coded factors and adding the error term\n      deltaDuration = \n        B_0 + e_st +\n        (X_p * B_p) +\n        (X_e * B_e) +\n        (subjAttr_c * B_s) +\n        (X_p * X_e * B_p_e_inx) +\n        (X_p * subjAttr_c * B_p_s_inx) +\n        (X_e * subjAttr_c * B_e_s_inx) +\n        (X_p * X_e * subjAttr_c * B_p_e_s_inx)\n    )\n  \n  # unset seed\n  set.seed(NULL)\n  \n  # truncuate impossible deltaDurations\n  if(truncNums) {\n    dataSim &lt;- dataSim %&gt;% \n      mutate(deltaDuration = if_else(deltaDuration &lt; -1, -1,\n        if_else(deltaDuration &gt; 1, 1, deltaDuration)))\n  }\n  \n  # run a linear mixed effects model and check summary\n  mod &lt;- lmer(\n    deltaDuration ~ polAff*ewe*subjAttr_c + (1 | subj) + (1 | trial),\n    data = dataSim\n  )\n  mod.sum &lt;- summary(mod)\n\n  # get results in tidy format\n  mod.broom &lt;- broom.mixed::tidy(mod)\n\n  return(list(\n    dataSim = dataSim,\n    modelLmer = mod,\n    modelResults = mod.broom\n  ))\n  \n}\n\n\nWe call the function once and extract the results of this single simulation:\n\n\nShow the code\n# Note to myself: Consider setting beta_p = 0.4/3.5, beta_p_e_inx = 0.4/3.5,\n# and beta_p_e_s_inx to 2 * 0.4/3.5/(2*.85).\n# This way, the interaction effect polAff:ewe is 0.4/3.5 for individuals\n# with an average subjAttr (subjAttr_c = 0). For individuals with\n# subjAttr = mean - SD, polAff:ewe is 0. For individuals with subjAttr = mean + SD,\n# polAff:ewe is  2 * 0.4/3.5.\n\nout &lt;- FUN_sim_3wayInt(\n  n_subj         =                1000, # number of subjects\n  n_subj_prop_p  =           c(.5, .5), # proportion of republican and democrat subjects\n  n_subj_prop_e  =           c(.5, .5), # proportion of subjects without and with extreme weather exposure\n  n_subj_prop_s  =           c(.5, .5), # proportion of subjects with low and high subjective attribution of EWE to CC\n  n_trial        =                  25, # number of trials\n  s_mean         =                3.67, # mean of subjAttr, see Ogunbode et al. (2019)\n  s_sd           =                0.85, # sd of subjAttr, see Ogunbode et al. (2019)\n  beta_0         =                   0, # intercept (grand mean) for deltaDuration\n  beta_p         =             0.4/3.5, # main effect of political affiliation (polAff)\n  beta_e         =                   0, # main effect of extreme weather exposure (ewe)\n  beta_s         =                   0, # main effect of subjective attribution of ewe to climate change (subjAttr)\n  beta_p_e_inx   =             0.4/3.5, # two-way interaction effect of polAff and ewe\n  beta_p_s_inx   =                   0, # two-way interaction effect of polAff and subjAttr\n  beta_e_s_inx   =                   0, # two-way interaction effect of ewe and subjAttr\n  beta_p_e_s_inx =      (0.4/3.5)/0.85, # three-way interaction effect of polAff, ewe, and subjAttr\n  subj_0         =                 .29, # by-subject random intercept sd for dt carbon\n  trial_0        =                 .04, # by-trial random intercept sd\n  sigma          =         1*(.29+.04), # residual (error) sd\n  \n  truncNums      =                TRUE, # should impossible numbers be truncuated?\n  setSeed        =                 123  # seed number to achieve reproducible results. Set to NULL for simulations!\n)\n\n# Get results table\nresultsTable &lt;- out$modelResults %&gt;% \n  select(-c(std.error, statistic, df)) %&gt;% \n  mutate(across(where(is_double), ~ round(.x, 4))) %&gt;% \n  knitr::kable()\nformulaUsedForFit &lt;- paste(as.character(formula(out$modelLmer))[c(2,1,3)], collapse = \" \")\n\n# Create predictions plot\n\n# refit model to dispaly subjAttr levels in original metric (not mean centered)\nm &lt;- lmer(\n  deltaDuration ~ polAff*ewe*subjAttr + (1 | subj) + (1 | trial),\n  data = out$dataSim\n)\n# define spotlights for spotlight analysis\nspotlights &lt;- c(3.67 - 0.85, 3.67, 3.67 + 0.85)\n\n# create plot showing predictions\np.demo.3wayInt.pred &lt;- predict_response(m, terms = c(\"ewe\", \"polAff\", \"subjAttr[spotlights]\"))\np.demo.3wayInt &lt;- p.demo.3wayInt.pred %&gt;% \n  plot(colors = c(\"red\", \"dodgerblue\")) +\n  coord_cartesian(ylim = c(-.25, .25)) +\n  theme_bw()\n\n\nFigure 9 visualizes predictions based on this single simulation and Table 3 summarizes the statistical results of fitting the actual model used in data generation to the simulated data.\n\n\n\n\n\n\n\n\nFigure 9: Visual representation of results of one simulation created using FUN_sim_3wayInt. Points indicate the predicted means surrounded by 95% Confidence Intervals. Panels indicate predictions for different values of subjAttr (Mean - SD, Mean, and Mean + SD).\n\n\n\n\n\n\n\n\nTable 3: Statistical results of one simulation created using FUN_sim_3wayInt. Data was fit using deltaDuration ~ polAff * ewe * subjAttr_c + (1 | subj) + (1 | trial). Note that subjAttr is mean centered to ease interpretation of lower-level interactions and main effects.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\neffect\ngroup\nterm\nestimate\np.value\n\n\n\n\nfixed\nNA\n(Intercept)\n-0.0022\n0.8478\n\n\nfixed\nNA\npolAff.dem-rep\n0.1149\n0.0000\n\n\nfixed\nNA\newe.TRUE-FALSE\n-0.0023\n0.9031\n\n\nfixed\nNA\nsubjAttr_c\n0.0091\n0.4141\n\n\nfixed\nNA\npolAff.dem-rep:ewe.TRUE-FALSE\n0.1426\n0.0001\n\n\nfixed\nNA\npolAff.dem-rep:subjAttr_c\n0.0187\n0.4025\n\n\nfixed\nNA\newe.TRUE-FALSE:subjAttr_c\n0.0142\n0.5239\n\n\nfixed\nNA\npolAff.dem-rep:ewe.TRUE-FALSE:subjAttr_c\n0.1111\n0.0130\n\n\nran_pars\nsubj\nsd__(Intercept)\n0.2849\nNA\n\n\nran_pars\ntrial\nsd__(Intercept)\n0.0323\nNA\n\n\nran_pars\nResidual\nsd__Observation\n0.3240\nNA"
  },
  {
    "objectID": "scripts/powerSimulations.html#power-simulation-2",
    "href": "scripts/powerSimulations.html#power-simulation-2",
    "title": "Power Simulations for Registered Report",
    "section": "6.3 Power Simulation",
    "text": "6.3 Power Simulation\nIn the following code, the simulations are calculated. We do not recommend executing this code junk as it takes several hours to run.\n\n\nShow the code\nFUN_sim_3wayInt_pwr &lt;- function(sim, ...){\n  out &lt;- FUN_sim_3wayInt(...)\n  modelResults &lt;- out$modelResults %&gt;% \n    mutate(sim = sim) %&gt;% \n    relocate(sim)\n  return(modelResults)\n}\n\n# How many simulations should be run?\nn_sims &lt;- 1000\n\n# What are the breaks for number of subjects we would like to calculate power for?\nbreaks_subj &lt;- c(900, 950, 1000)\n\n# What are the breaks for SESOI?\nbreaks_sesoi &lt;- (0.4/3.5)/0.85 * seq(1, 2, .25)\n\n# What are the breaks for different error SDs?\nbreaks_sigma &lt;- c((.29+.04), 2*(.29+.04))\n\nres_3wayInt &lt;- tibble()\nfor (s in seq_along(breaks_sigma)) {\n  \n  res_sesoi &lt;- tibble()\n  for (sesoi in seq_along(breaks_sesoi)) {\n    \n    res_nSubj &lt;- tibble()\n    for (nSubj in seq_along(breaks_subj)) {\n      \n      # Give feedback regarding which model is simulated\n      cat(paste0(\n        \"Simulation:\\n\",\n        \"  sigma = \", round(breaks_sigma[s], 4), \"\\n\",\n        \"  sesoi = \", round(breaks_sesoi[sesoi], 4), \"\\n\",\n        \"  nSubject = \", breaks_subj[nSubj], \"\\n\"\n      ))\n      \n      # Start timer\n      cat(paste0(\"Start date time: \", lubridate::now(), \"\\n\"))\n      tic()\n      \n      # Loop over simulations\n      pwr &lt;- map_df(\n        1:n_sims, \n        FUN_sim_3wayInt_pwr,\n        n_subj = breaks_subj[nSubj],\n        beta_p_e_s_inx = breaks_sesoi[sesoi],\n        sigma = breaks_sigma[s]\n      )\n      \n      # Stop timer and calculate elapsed time\n      elapsed_time &lt;- toc(quiet = TRUE)\n      elapsed_seconds &lt;- elapsed_time$toc - elapsed_time$tic\n      elapsed_minutes &lt;- elapsed_seconds / 60\n      cat(paste0(\"End date time: \", lubridate::now(), \"\\n\"))\n      cat(\"Elapsed time: \", elapsed_minutes, \" minutes\\n\\n\")\n      \n      # Add number of subjects to pwr\n      pwr &lt;- pwr %&gt;% \n        mutate(\n          nSubjects = breaks_subj[nSubj],\n          sesoi = breaks_sesoi[sesoi],\n          sigma = breaks_sigma[s]\n        )\n      \n      # Add results to the results table\n      res_nSubj &lt;- res_nSubj %&gt;%\n        rbind(pwr)\n    }\n    \n    # Add results to the results table\n    res_sesoi &lt;- res_sesoi %&gt;% \n      rbind(res_nSubj)\n  }\n  \n  # Add results to the results table\n  res_3wayInt &lt;- res_3wayInt %&gt;% \n    rbind(res_sesoi)\n  \n}\n\nres_3wayInt.summary &lt;- res_3wayInt %&gt;% \n  filter(term == \"polAff.dem-rep:ewe.TRUE-FALSE:subjAttr_c\") %&gt;% \n  group_by(sigma, sesoi, nSubjects) %&gt;% \n  summarise(\n    power = mean(p.value &lt; 0.05),\n    ci.lower = binom.confint(power*n_sims, n_sims, methods = \"exact\")$lower,\n    ci.upper = binom.confint(power*n_sims, n_sims, methods = \"exact\")$upper,\n    .groups = 'drop'\n  ) %&gt;% \n  mutate(\n    sigma_fact = factor(format(round(sigma, 4), nsmall = 4)),\n    sigma_level = match(sigma_fact, levels(sigma_fact)),\n    sesoi_fact = factor(format(round(sesoi, 4), nsmall = 4)),\n    sesoi_level = match(sesoi_fact, levels(sesoi_fact))\n  )\n\n# Save results in a list object\ntime &lt;- format(Sys.time(), \"%Y%m%d_%H%M\")\nfileName &lt;- paste0(\"res_3wayInt\", \"_\", time, \".RDS\")\nsaveRDS(\n  list(\n    res_3wayInt = res_3wayInt,\n    res_3wayInt.summary = res_3wayInt.summary\n  ),\n  file = file.path(\"../powerSimulationsOutput\", fileName)\n)\n\n\nWe retrieve pre-run results:\n\n\nShow the code\n# Load power simulation data\nresList_3wayInt &lt;- readRDS(file.path(\"../powerSimulationsOutput\", \"res_3wayInt_20240814_1612.RDS\")) \nresList_3wayInt.summary &lt;- resList_3wayInt$res_3wayInt.summary\n\n# Extract power values for some specific effect sizes at N = 1000\npowerValues &lt;- resList_3wayInt.summary %&gt;% \n  filter(sigma_fact == \"0.3300\") %&gt;% \n  filter(sesoi_fact == \"0.1345\") %&gt;% \n  filter(nSubjects == 950) %&gt;% \n  mutate(power_str = paste0(round(power*100, 2), \"%\")) %&gt;% \n  pull(power_str)\n\n# Extract number of simulations\nlabel_nSimulations &lt;- resList_3wayInt$res_3wayInt$sim %&gt;% n_distinct()\n\n# Repeat breaks_sesoi\nbreaks_sesoi &lt;- (0.4/3.5)/(0.85) * seq(1, 2, .25)\n\n\nFigure 10 displays the distribution of estimated fixed effects across all simulations. The figure shows that the estimated fixed effects are close to the true ones provided as input in the data simulation function, validating that simulations worked as expected.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 10: Distribution of estimated fixed effects resulting from 1000 simulations for the model deltaDuration ~ polAff * ewe * subjAttr_c + (1 | subj) + (1 | trial). Shaded area represent densities, annotated points indicate medians, and thick and thin lines represent 66% and 95% quantiles.\n\n\n\nFigure 11 shows results of our effect-size sensitivity analyses. We plot statistical power (y-axis) for different effect sizes (x-axis), taking into account different assumptions for the error SD (color) and sample size (panel). Regarding the latter, we report results not only for the full sample size we aim for (N = 1000), but also for sample sizes taking into account different participant exclusion-rates due to exclusion criteria defined in the Registered Report.\n\n\n\n\n\n\n\n\nFigure 11: Power curves for the three-way interaction polAff × ewe × subjAttr. Points represent simulated power surrounded by a 95%-CI based on 1000 simulations with α = 0.05. Note that, in contrast to Figure 4, the x-axsis represents different effect sizes, starting from the defined SESOI, while the panels represent different sample sizes, taking into account participant exclusion-rates of 10% (N = 900), 5% (N = 950), and 0% (N = 1000). Note that estimates are displayed with a slight shift along the x-axis to reduce overlap.\n\n\n\n\n\n\n\nShow the code\n# Get power values of interest\nchosenN &lt;- 950\nchosenSigma &lt;- c(\"0.3300\", \"0.6600\")\nchosenSESOI &lt;- c(\"0.1681\", \"0.2017\")\npowerValues &lt;- resList_3wayInt.summary %&gt;% \n  filter(sigma_fact %in% chosenSigma) %&gt;% \n  filter(sesoi_fact %in% chosenSESOI) %&gt;% \n  filter(nSubjects %in% chosenN)\n\n# Get lower CI for power values for more liberal and more conservative sigma assumptions\npowerValues_sigmaLib &lt;- powerValues %&gt;% \n  filter(sigma_fact == \"0.3300\")\npowerValues_sigmaCons &lt;- powerValues %&gt;% \n  filter(sigma_fact == \"0.6600\")\n\n# Interpolate the effect sizes at which we achieve 95% power\neff_sigmaLib &lt;- approx(powerValues_sigmaLib$ci.lower, powerValues_sigmaLib$sesoi, xout = 0.95)$y\neff_sigmaCons &lt;- approx(powerValues_sigmaCons$ci.lower, powerValues_sigmaCons$sesoi, xout = 0.95)$y\n# Round results for display in text\neff_sigmaLib_txt_3way &lt;- format(round(eff_sigmaLib, 4), nsmall = 4)\neff_sigmaCons_txt_3way &lt;- format(round(eff_sigmaCons, 4), nsmall = 4)\n\n\nTo assess the smallest effect size that can be detected with 95% statistical power, we inspect the lower bounds of the 95%-CI power estimates in Figure 11. Specifically, we focus on the power simulation results for N = 950, which takes into account a participant exclusion rate of 5%. There, we interpolate between the two point estimates that lie just below and above the 95% power line, i.e., between the power estimates for effect sizes 0.1681 and 0.2017. Assuming an error SD of 0.3300, we achieve 95% statistical power to detect a three-way interaction effect of at least 0.1728. For a more conservative error SD of 0.6600, this smallest detectable effect size is only marginally higher (0.1890)."
  }
]